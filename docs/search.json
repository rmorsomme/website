[
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "If this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you‚Äôll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you‚Äôll use for the course."
  },
  {
    "objectID": "computing-pipelines.html",
    "href": "computing-pipelines.html",
    "title": "Pipelines",
    "section": "",
    "text": "library(palmerpenguins)\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.1.6     v dplyr   1.0.9\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\n-- Attaching packages -------------------------------------- tidymodels 0.2.0 --\n\n\nv broom        0.8.0     v rsample      0.1.1\nv dials        0.1.1     v tune         0.2.0\nv infer        1.0.0     v workflows    0.2.6\nv modeldata    0.1.1     v workflowsets 0.2.1\nv parsnip      0.2.1     v yardstick    0.0.9\nv recipes      0.2.0     \n\n\n-- Conflicts ----------------------------------------- tidymodels_conflicts() --\nx scales::discard() masks purrr::discard()\nx dplyr::filter()   masks stats::filter()\nx recipes::fixed()  masks stringr::fixed()\nx dplyr::lag()      masks stats::lag()\nx yardstick::spec() masks readr::spec()\nx recipes::step()   masks stats::step()\n* Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(knitr)"
  },
  {
    "objectID": "computing-pipelines.html#simple-linear-regression",
    "href": "computing-pipelines.html#simple-linear-regression",
    "title": "Pipelines",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nModel fitting\nFit model:\n\npenguins_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\nTidy model output:\n\ntidy(penguins_fit)\n\n# A tibble: 2 x 5\n  term              estimate std.error statistic   p.value\n  <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\nFormat model output as table:\n\ntidy(penguins_fit) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5780.831\n305.815\n-18.903\n0\n\n\nflipper_length_mm\n49.686\n1.518\n32.722\n0\n\n\n\n\n\nAugment data with model:\n\naugment(penguins_fit$fit)\n\n# A tibble: 342 x 9\n   .rownames body_mass_g flipper_length_~ .fitted  .resid    .hat .sigma .cooksd\n   <chr>           <int>            <int>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>\n 1 1                3750              181   3212.  538.   0.00881   394. 8.34e-3\n 2 2                3800              186   3461.  339.   0.00622   394. 2.33e-3\n 3 3                3250              195   3908. -658.   0.00344   393. 4.83e-3\n 4 5                3450              193   3808. -358.   0.00385   394. 1.60e-3\n 5 6                3650              190   3659.   -9.43 0.00469   395. 1.35e-6\n 6 7                3625              181   3212.  413.   0.00881   394. 4.91e-3\n 7 8                4675              195   3908.  767.   0.00344   393. 6.56e-3\n 8 9                3475              193   3808. -333.   0.00385   394. 1.39e-3\n 9 10               4250              190   3659.  591.   0.00469   394. 5.31e-3\n10 11               3300              186   3461. -161.   0.00622   395. 5.23e-4\n# ... with 332 more rows, and 1 more variable: .std.resid <dbl>\n\n\n\n\nStatistical inference"
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it‚Äôs been resolved. If there‚Äôs a deadline coming up soon, post on the course forum to let us know that there‚Äôs an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don‚Äôt anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you‚Äôve tried and the errors you see (including verbatim errors and/or screenshots).\nEither way you can also fill out the form here, which will notify our the R TA for the department as well as our undergraduate coordinator. They‚Äôll be able to help diagnose the issue."
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Here are the webpages to install the two pieces of software R and RStudio:\n\nDownload and install R 4.1.3 or 4.2.0: https://cran.r-project.org/\nDownload and install RStudio Desktop: https://www.rstudio.com/products/rstudio/. The Open Source Edition version is sufficient.\n\nThe teaching team is always happy to provide help with any computational question."
  },
  {
    "objectID": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you‚Äôll upload your PDF and them mark the page(s) where each question can be found. It‚Äôs OK if a question spans multiple pages, just mark them all. It‚Äôs also OK if a page includes multiple questions."
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "The R and RStudio software\nüîó on R and RStudio\n\n\n\n\nAssignment submission and feedback\nüîó on Gradescope\n\n\nIntroduction to Modern Statistics\nüîó on Openintro\n\n\nR for Data Science\nüîó on R4DS\n\n\nRStudi Cheatsheets\nüîóRStudio, RMarkdown, ggplot2, dplyr"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "STA 101L: Data Analysis and Statistical Inference",
    "section": "",
    "text": "Did you know that statistics was first used in agriculture and that data science has probably revolutionized your favorite sport? Check out these slides to learn more about the impact that statistics and data sciences have had on various fields through short videos."
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you feel comfortable seeking help and can identify where to find what you need without getting too frustrated. This is especially important in a summer class."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once a week. You can find a list of everyone‚Äôs office hours here."
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nYou can email Dr.¬†Raphael Morsomme at rnm16@duke.edu. please include ‚ÄúSTA 101‚Äù in the subject line. Barring extenuating circumstances, I will respond to STA101L emails within 24 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. ARC services are available free to any Duke undergraduate student, in any year, studying in any discipline. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact theARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nStudent mental health and wellness is of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below:\n\nThe Academic Resource Center: (919) 684-5917, theARC@duke.edu, or arc.duke.edu,\nDuWell: (919) 681-8421, duwell@studentaffairs.duke.edu, or studentaffairs.duke.edu/duwell\n\nIf your mental health concerns you and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach. Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student‚Äôs behavior or health visit the website for resources and assistance. studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS). CAPS helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000. studentaffairs.duke.edu/caps\nBlue Devils Care. A convenient and cost-effective way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu\nTwo-Click Support. Duke Student Government and DukeReach partnership that connects students to help in just two clicks. bit.ly/TwoClickSupport\nWellTrack. Sign up for WellTrack at app.welltrack.com."
  },
  {
    "objectID": "course-support.html#technology-accommodations",
    "href": "course-support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nStudents with demonstrated high financial need who have limited access to computers may request assistance in the form of loaner laptops. For technology assistance requests, please go here. Please note that supplies are limited.\nNote that all software we use in this course is open-source and/or freely available."
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbook, journal articles, etc.)."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-sakai",
    "href": "course-support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission will take place on Gradescope.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "course-syllabus.html#course-info",
    "href": "course-syllabus.html#course-info",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Course info",
    "text": "Course info\n\n\n\n\n\n\n\n\n\n\nDay\nTime\nLocation\n\n\n\n\nLectures\nMon, Tue & Thu\n3:30 pm - 5:35 pm\nOld Chemistry Building 003\n\n\nLabs\nWed & Fri\n3:30 pm - 4:45 pm\nOld Chemistry Building 003"
  },
  {
    "objectID": "course-syllabus.html#overview",
    "href": "course-syllabus.html#overview",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Overview",
    "text": "Overview\nWelcome to STA101L Data Analysis and Statistical Inference. The goal of this class is to prepare you to be critical consumers of statistical analyses in your scientific fields of practice and future professions. Our point of departure will be to think about data collection: how to (not) collect data, and how the way in which data are collected impacts the analysis that we conduct. We will then quickly delve into data visualization. Ever heard of a mozaic plot or an inter-quartile range? This is an area of data analysis where creativity and an eye for good design can make a difference. Once we have good grasp of how to visualize data, we will construct statistical models to make predictions and to understand the relations that exist between variables.\nWhile models can be useful (especially if their predictions are accurate!), all models are inherently wrong. The statistical tests that we will learn in the second half of the course will help us quantify how (un)certain we are that the models we construct pick up real patterns in the data and not just background noise.\nThroughout the class, you will attend hands-on labs in which you will learn to implement all these techniques in the statistical computing software R."
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the term you will be able to‚Ä¶\n\nvisualize and summarize data sets with numerical and categorical variables;\nconstruct and investigate linear regression models for forecasting; this includes fitting, evaluating, comparing and selecting models, as well as interpreting their output;\nconduct hypothesis tests and construct confidence intervals for proportions, differences between proportions, means, differences between means and regression coefficients;\nimplement these techniques in R, and use RMarkdown to write reproducible reports;\nplan and complete a statistical analysis of a real-world phenomenon using visual and numerical summaries, hypothesis tests, confidence intervals and regression models."
  },
  {
    "objectID": "course-syllabus.html#prerequisite",
    "href": "course-syllabus.html#prerequisite",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Prerequisite",
    "text": "Prerequisite\nThere is no prerequisite for this class."
  },
  {
    "objectID": "course-syllabus.html#community",
    "href": "course-syllabus.html#community",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Community",
    "text": "Community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and organize activities that are respectful of diversity and in alignment with Duke‚Äôs Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nif you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me; if you prefer to speak with someone outside of the course, your academic dean is an excellent resource;\nI (like many people) am still in the process of learning about diverse perspectives and identities; if something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website at rmorsomme.github.io/website.\nI will regularly send course announcements via email, make sure to check your mail box regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course forum Conversations. There is a chance another student has already asked a similar question, so please check the other posts in Conversations before adding a new question. If you know the answer to a question posted in the discussion forum, I encourage you to respond!\nEmails should be reserved for questions not appropriate for the public forum. If you email me, please include ‚ÄúSTA 101‚Äù in the subject line. Barring extenuating circumstances, I will respond to STA 101 emails within 24 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\n\nCheck out the Support page for more resources."
  },
  {
    "objectID": "course-syllabus.html#textbook",
    "href": "course-syllabus.html#textbook",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Textbook",
    "text": "Textbook\nThe class will closely follow the book Introduction to Modern Statistics (first edition) by Mine √áetinkaya-Rundel and Johanna Hardin. This is an open-source book freely available online. You‚Äôre welcomed to read on screen or print it out. If you prefer a paperback version you can buy it at the cost of printing (around $20) on Amazon. The textbook store will not carry copies of this text.\nChapters 1-7 of the book R for Data Science by Garret Grolemund and Hadley Wickham (also open-source and freely available) will also be useful."
  },
  {
    "objectID": "course-syllabus.html#lectures-and-labs",
    "href": "course-syllabus.html#lectures-and-labs",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nThe goal of both the lectures and the labs is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and lab sessions and meaningfully contribute to in-class exercises and discussion.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom may not be sufficient to accommodate everyone. More information on loaner laptops can be found here."
  },
  {
    "objectID": "course-syllabus.html#assessment",
    "href": "course-syllabus.html#assessment",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Assessment",
    "text": "Assessment\nAssessment for the course is comprised of three components: regular homework assignments, a prediction group project and an inference group project.\n\nHomework assignments\nTo reduce the number of assignments during the summer session, problem sets and lab exercises will be merged. In these homework assignments, you will apply what you‚Äôve learned during lectures and labs to show conceptual understanding of the content and complete data analysis tasks in R. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Homework must be typed up using RMarkdown and submitted as a PDF on Gradescope.\nThe homework assignment with the lowest grade will be dropped at the end of the term.\n\n\nProjects\nThere will be two group projects. Through these, you have the opportunity to demonstrate what you‚Äôve learned in the course thus far. The projects will focus on the two pillars of statistics and data science: prediction and inference. In the first project, you will construct a regression model for prediction. The goal will be to build a model that provides predictions that are as accurate as possible. In the second project, you will analyze a phenomenon that interests you using real-world data. More detail about the projects will be given during the term."
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nAssessment\nPercentage\n\n\n\n\nHomework\n50%\n\n\nPrediction project\n20%\n\n\nInference project\n30%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60\n\n\n\nNote that the final grade may be curved."
  },
  {
    "objectID": "course-syllabus.html#five-tips-for-success",
    "href": "course-syllabus.html#five-tips-for-success",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TA and I will help you by providing you with materials and answering questions, but for this to work you need to do the following:\n\ncomplete the assigned reading before the lectures;\nask questions quickly; don‚Äôt let a day pass by with lingering questions;\ndo the homework assignments thoroughly;\npractice, practice, practice;\ndon‚Äôt procrastinate; start on the homework assignments and the projects early."
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic integrity\nDon‚Äôt cheat!\nAll students must adhere to the Duke Community Standard (DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard:\nStudents affirm their commitment to uphold the values of the Duke University community by signing a pledge that states:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;\nI will act if the Standard is compromised\n\nRegardless of course delivery format, it is your responsibility to understand and follow Duke policies regarding academic integrity, including doing one‚Äôs own work, following proper citation of sources, and adhering to guidance around group work projects. Ignoring these requirements is a violation of the Duke Community Standard. If you have any questions about how to follow these requirements, please contact Jeanna McCullers (jeanna.mccullers@duke.edu), Director of the Office of Student Conduct.\n\n\nCollaboration policy\nOnly work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what‚Äôs the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the TA.\nFor the projects, collaboration between teams at a high level is also allowed; however, you may not share code or components of the project with other teams.\n\n\n\nPolicy on sharing and reusing code\nI am well aware that a huge volume of code is available on the web to solve any number of problems. You may make use of any online resources (e.g.¬†RStudio Community, StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. On homework assignments you may not directly share code with another student in this class, and on the projects you may not directly share code with another team.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. Given the fast pace of a summer class, any assignment submitted after the deadline will not be graded. The homework assignments will be published early to give you ample time to work on them. Note that the lowest homework will be dropped.\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email Raphael Morsomme and our TA Rohit Roy before the deadline to obtain a 24-hour extension. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let a member of the instruction team know if you need help contacting your academic dean.\n\n\nRegrade request policy\nRegrade requests must be submitted on Gradescope within 48 hours of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the inference project report is due.\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Trinity attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this term. Lab time is dedicated to working on your lab assignments and collaborating with your teammates on your project. If you miss a lab session, make sure to communicate with your team about how you can make up your contribution. If you know you‚Äôre going to miss a lab session and you‚Äôre feeling well enough to do so, notify your teammates ahead of time. Overall these policies are put in place to ensure communication between team members, respect for each others‚Äô time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university‚Äôs top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have symptoms related to COVID-19, have had a known exposure to COVID-19, or have tested positive for COVID-19. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health at 919-681-9355. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\nPlease read and follow university guidance here. The current guidelines are for students and instructors to wear masks during class.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously or watching a recording of the class.\n\n\nPolicy on video recording course content\nIf you feel that you need record the lectures, you must get permission from the instructor ahead of time and these recordings should be used for personal study only, no for distribution. The full policy on recording of lectures falls under the Duke University Policy on Intellectual Property Rights, available at provost.duke.edu/sites/default/files/FHB_App_P.pdf. Unauthorized distribution is a cause for disciplinary action by the Judicial Board."
  },
  {
    "objectID": "course-syllabus.html#learning-during-a-pandemic",
    "href": "course-syllabus.html#learning-during-a-pandemic",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don‚Äôt hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you‚Äôre always welcome to talk to me. If I can‚Äôt help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this health crisis.\n\nNote: If you‚Äôve read this far in the syllabus, email me a picture of your pet if you have one or your favourite meme!"
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Important dates",
    "text": "Important dates\n\nMay 11: Classes begin (Monday meeting schedule)\nMay 13: Drop/add ends\nMay 16: Regular class meeting schedule begins\nMay 30: Memorial Day holiday, no class is held\nMay 31: Prediction project\nJune 8: Last day to withdraw with W\nJune 16: Inference project presentation\nJune 17: Classes end\nJune 20: Juneteenth holiday\nJune 21: Reading period\nJune 23: Last assignment: inference project report\n\nClick here for the full Duke academic calendar."
  },
  {
    "objectID": "course-syllabus.html#attribution",
    "href": "course-syllabus.html#attribution",
    "title": "Syllabus - STA101L Summer I 2022",
    "section": "Attribution",
    "text": "Attribution\nSome portions of this syllabus are based on the syllabus of STA 210 - Spring 2022 by Prof.¬†Mine √áetinkaya-Rundel."
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Raphael Morsomme (he/him/his) is a Ph.D.¬†candidate at the Department of Statistical Science at Duke University. Raphael‚Äôs work focuses on the development of flexible and scalable stochastic epidemic models along with efficient Markov Chain Monte Carlo algorithms to fit these models. In addition, he uses data augmentation to study the overdiagnosis rate of breast cancer.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMonday, 10:00-11:00am\nZoom\n\n\nWednesday, 10:00-11:00am\nZoom\n\n\n\nIf these times don‚Äôt work for you or you‚Äôd like to schedule a one-on-one meeting, simply send an email to raphael.morsomme@duke.edu."
  },
  {
    "objectID": "course-team.html#teaching-assistant",
    "href": "course-team.html#teaching-assistant",
    "title": "Teaching team",
    "section": "Teaching assistant",
    "text": "Teaching assistant\n\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\n\nRohit Roy - rohit.roy@duke.edu\nWed, 4:45-5:45pm\nFri, 4:45-5:45pm\nHybrid (Zoom and room 119 [TBC] )\nHybrid (Zoom and room 119 [TBC])"
  },
  {
    "objectID": "exams/exam-1.html",
    "href": "exams/exam-1.html",
    "title": "Exam 1",
    "section": "",
    "text": "Grading (50 pts)\n\n\n\nPart\nPoints\n\n\n\n\nPart 1 - Conceptual (on Sakai)\n10\n\n\nPart 2 - Applied (on Gradescope)\n40\n\n\nTotal\n50"
  },
  {
    "objectID": "exams/exam-2.html",
    "href": "exams/exam-2.html",
    "title": "Exam 2",
    "section": "",
    "text": "Grading (50 pts)\n\n\n\nPart\nPoints\n\n\n\n\nPart 1 - Conceptual (on Sakai)\n10\n\n\nPart 2 - Applied (on Gradescope)\n40\n\n\nTotal\n50"
  },
  {
    "objectID": "exams/exam-3.html",
    "href": "exams/exam-3.html",
    "title": "Exam 2",
    "section": "",
    "text": "Grading (50 pts)\n\n\n\nPart\nPoints\n\n\n\n\nPart 1 - Conceptual (on Sakai)\n10\n\n\nPart 2 - Applied (on Gradescope)\n40\n\n\nTotal\n50"
  },
  {
    "objectID": "hw/hw-1.html",
    "href": "hw/hw-1.html",
    "title": "HW 1 - Introduction to data",
    "section": "",
    "text": "This assignment needs to be completed with RMarkdown and submitted as a pdf on Gradescope. Feel free to use the template that has been provided."
  },
  {
    "objectID": "hw/hw-1.html#problem-set-25-points",
    "href": "hw/hw-1.html#problem-set-25-points",
    "title": "HW 1 - Introduction to data",
    "section": "Problem set (25 points)",
    "text": "Problem set (25 points)\n\nExercise 1.2 (2 points)\nExercise 1.8 (5 points)\nExercise 1.12 (5 points)\nExercise 1.20 (2 points)\nExercise 2.8 (2 points)\nExercise 2.12 (3 points)\nExercise 2.14 (1 point)\nExercise 2.22 (2 points)\nExercise 2.22 - follow-up (3 points)\n\nIs your study blind?\nIs it double-bind?\nIf it is not blind, can you make it blind?"
  },
  {
    "objectID": "hw/hw-1.html#lab-exercises---dr.-arbuthnots-baptism-records-25-points",
    "href": "hw/hw-1.html#lab-exercises---dr.-arbuthnots-baptism-records-25-points",
    "title": "HW 1 - Introduction to data",
    "section": "Lab exercises - Dr.¬†Arbuthnot‚Äôs baptism records (25 points)",
    "text": "Lab exercises - Dr.¬†Arbuthnot‚Äôs baptism records (25 points)\nYou can find the lab here\n\nExercise 1 (2 points)\nExercise 2 (3 points)\nExercise 3 (4 points)\nExercise 4 (4 points)\nExercise 5 (2 points)\nExercise 6 (5 points)\nExercise 7 (5 points)"
  },
  {
    "objectID": "hw/hw-2.html",
    "href": "hw/hw-2.html",
    "title": "HW 2 - Data visualization and summary",
    "section": "",
    "text": "This assignment needs to be completed with RMarkdown and submitted as a PDF on Gradescope. Feel free to re-use the template provided for HW1.\nWhen submitting your work on Gradescope, please assign a page for each question."
  },
  {
    "objectID": "hw/hw-2.html#problem-set-25-points",
    "href": "hw/hw-2.html#problem-set-25-points",
    "title": "HW 2 - Data visualization and summary",
    "section": "Problem set (25 points)",
    "text": "Problem set (25 points)\n\nExercise 5.2 (2 points)\nExercise 5.4 (2 points) ‚Äì instead of drawing, you may describe the relationship in words.\nExercise 5.6 (3 points)\nExercise 5.10 (3 points)\nExercise 5.16 (5 points)\nExercise 5.20 (1 points)\nExercise 5.20 follow up (1 points)\n\nWould side-by-side boxplots have been suitable to visualize these data? Briefly explain.\n\nExercise 5.22 (2 points)\nExercise 5.26 (2 points)\nExercise 4.6 (4 points)"
  },
  {
    "objectID": "hw/hw-2.html#lab-exercises---new-york-flights-25-points",
    "href": "hw/hw-2.html#lab-exercises---new-york-flights-25-points",
    "title": "HW 2 - Data visualization and summary",
    "section": "Lab exercises - New York flights (25 points)",
    "text": "Lab exercises - New York flights (25 points)\nYou can find the lab here\n\nExercise 1 (2 points)\nExercise 2 (3 points)\nExercise 3 (3 points)\nExercise 4 (3 points)\nExercise 5 (2 points)\nExercise 6 (2 points)\nExercise 7 (2 points)\nExercise 8 (3 points)\nExercise 9 (5 points)"
  },
  {
    "objectID": "hw/hw-3.html",
    "href": "hw/hw-3.html",
    "title": "HW 3 - Simple linear regression",
    "section": "",
    "text": "This assignment needs to be completed with RMarkdown and submitted as a PDF on Gradescope. Feel free to re-use the template provided for HW1.\nWhen submitting your work on Gradescope, please assign a page for each question."
  },
  {
    "objectID": "hw/hw-3.html#problem-set-25-points",
    "href": "hw/hw-3.html#problem-set-25-points",
    "title": "HW 3 - Simple linear regression",
    "section": "Problem set (25 points)",
    "text": "Problem set (25 points)\n\n7.6, a-c (3 points)\n7.18 (2 points)\n7.20 (4 points)\n7.22 (7 points)\n\nfit the model in R; the variables sho_gi and hgt respectively correspond to shoulder girth and height.\n\nd <- openintro::bdims\n\ndo parts a-f\n\n7.24 (5 points)\n\nfit the model in R\n\nd <- MASS::cats\n\ndo parts a-d\n\n7.26 (3 points)\n7.28 (1 point)"
  },
  {
    "objectID": "hw/hw-3.html#lab-exercises---the-human-freedom-index-25-points",
    "href": "hw/hw-3.html#lab-exercises---the-human-freedom-index-25-points",
    "title": "HW 3 - Simple linear regression",
    "section": "Lab exercises - the Human Freedom Index (25 points)",
    "text": "Lab exercises - the Human Freedom Index (25 points)\nYou can find the lab here\n\nExercise 1 (2 points)\nExercise 2 (2 points)\nExercise 3 (3 points)\nExercise 4 (2 points)\nExercise 5 (2 points)\nExercise 6 (3 points)\nExercise 7 (2 points)\nExercise 8 (2 points)\n\nSkip exercises 9-10.\n\nPractice 1 (2 points)\nPractice 2 (2 points)\nPractice 3 (1 points) ‚Äì only evaluate linearity\nPractice 4 (2 points)"
  },
  {
    "objectID": "hw/hw-4.html",
    "href": "hw/hw-4.html",
    "title": "HW 4 - Multiple linear regression",
    "section": "",
    "text": "This assignment needs to be completed with RMarkdown and submitted as a PDF on Gradescope. Feel free to re-use the template provided for HW1.\nWhen submitting your work on Gradescope, please assign a page for each question."
  },
  {
    "objectID": "hw/hw-4.html#problem-set-25-points",
    "href": "hw/hw-4.html#problem-set-25-points",
    "title": "HW 4 - Multiple linear regression",
    "section": "Problem set (25 points)",
    "text": "Problem set (25 points)\n\n8.6 (2 points)\n8.10 (8 points)\n\nfit the model in R\n\nd <- palmerpenguins::penguins\n\nidentify the type of each variable\nidentify the baseline level of the categorical predictors\ndo parts a-d"
  },
  {
    "objectID": "hw/hw-4.html#lab-exercises---the-human-freedom-index-25-points",
    "href": "hw/hw-4.html#lab-exercises---the-human-freedom-index-25-points",
    "title": "HW 4 - Multiple linear regression",
    "section": "Lab exercises - the Human Freedom Index (25 points)",
    "text": "Lab exercises - the Human Freedom Index (25 points)\nYou can find the lab here\n\nExercise 1 (2 points)\nExercise 2 (2 points)\nExercise 3 (3 points)\nExercise 4 (2 points)\nExercise 5 (2 points)\nExercise 6 (3 points)\nExercise 7 (2 points)\nExercise 8 (2 points)\n\nSkip exercises 9-10.\n\nPractice 1 (2 points)\nPractice 2 (2 points)\nPractice 3 (1 points) ‚Äì only evaluate linearity\nPractice 4 (2 points)"
  },
  {
    "objectID": "hw/hw1_lab_answers.html",
    "href": "hw/hw1_lab_answers.html",
    "title": "HW 1 - Introduction to data",
    "section": "",
    "text": "Lab exercises - Dr.¬†Arbuthnot‚Äôs baptism records (25 points)\nYou can find the lab here\n\nlibrary(tidyverse)\nlibrary(openintro)\n\n\nExercise 1 (2 points)\nInsert any text here.\n\narbuthnot$girls\n\n [1] 4683 4457 4102 4590 4839 4820 4928 4605 4457 4952 4784 5332 5200 4910 4617\n[16] 3997 3919 3395 3536 3181 2746 2722 2840 2908 2959 3179 3349 3382 3289 3013\n[31] 2781 3247 4107 4803 4881 5681 4858 4319 5322 5560 5829 5719 6061 6120 5822\n[46] 5738 5717 5847 6203 6033 6041 6299 6533 6744 7158 7127 7246 7119 7214 7101\n[61] 7167 7302 7392 7316 7483 6647 6713 7229 7767 7626 7452 7061 7514 7656 7683\n[76] 5738 7779 7417 7687 7623 7380 7288\n\n\n\n\nExercise 2 (3 points)\nInsert any text here.\n\narbuthnot %>%\n  ggplot(aes(x = year, y = girls)) +\n  geom_point() +\n  geom_line()\n\n\n\narbuthnot %>%\n  ggplot() +\n  geom_line(aes(x = year, y = girls))\n\n\n\n\n\n\nExercise 3 (4 points)\nInsert any text here.\n\narbuthnot %>%\n  mutate(prop_boys = boys / (boys + girls)) %>%\n  ggplot() +\n  geom_line(aes(year, prop_boys))\n\n\n\n\n\n\nExercise 4 (4 points)\nInsert any text here.\n\npresent\n\n# A tibble: 63 x 3\n    year    boys   girls\n   <dbl>   <dbl>   <dbl>\n 1  1940 1211684 1148715\n 2  1941 1289734 1223693\n 3  1942 1444365 1364631\n 4  1943 1508959 1427901\n 5  1944 1435301 1359499\n 6  1945 1404587 1330869\n 7  1946 1691220 1597452\n 8  1947 1899876 1800064\n 9  1948 1813852 1721216\n10  1949 1826352 1733177\n# ... with 53 more rows\n\npresent$year\n\n [1] 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954\n[16] 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969\n[31] 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984\n[46] 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999\n[61] 2000 2001 2002\n\nmin(present$year)\n\n[1] 1940\n\nmax(present$year)\n\n[1] 2002\n\nnrow(present)\n\n[1] 63\n\nncol(present)\n\n[1] 3\n\ndim(present)\n\n[1] 63  3\n\npresent\n\n# A tibble: 63 x 3\n    year    boys   girls\n   <dbl>   <dbl>   <dbl>\n 1  1940 1211684 1148715\n 2  1941 1289734 1223693\n 3  1942 1444365 1364631\n 4  1943 1508959 1427901\n 5  1944 1435301 1359499\n 6  1945 1404587 1330869\n 7  1946 1691220 1597452\n 8  1947 1899876 1800064\n 9  1948 1813852 1721216\n10  1949 1826352 1733177\n# ... with 53 more rows\n\n\n\n\nExercise 5 (2 points)\nInsert any text here.\n\n# Insert code for Exercise 5 here\n\n\n\nExercise 6 (5 points)\nInsert any text here.\n\npresent %>%\n  mutate(prop_boys = boys / (boys + girls)) %>%\n  ggplot() +\n  geom_line(aes(year, prop_boys))\n\n\n\n\n\n\nExercise 7 (5 points)\nInsert any text here.\n\npresent %>%\n  mutate(total = boys + girls) %>%\n  arrange(desc(total))\n\n# A tibble: 63 x 4\n    year    boys   girls   total\n   <dbl>   <dbl>   <dbl>   <dbl>\n 1  1961 2186274 2082052 4268326\n 2  1960 2179708 2078142 4257850\n 3  1957 2179960 2074824 4254784\n 4  1959 2173638 2071158 4244796\n 5  1958 2152546 2051266 4203812\n 6  1962 2132466 2034896 4167362\n 7  1956 2133588 2029502 4163090\n 8  1990 2129495 2028717 4158212\n 9  1991 2101518 2009389 4110907\n10  1963 2101632 1996388 4098020\n# ... with 53 more rows"
  },
  {
    "objectID": "hw/template.html",
    "href": "hw/template.html",
    "title": "HW 1 - Introduction to data",
    "section": "",
    "text": "Lab exercises - Dr.¬†Arbuthnot‚Äôs baptism records (25 points)\nYou can find the lab here\n\nlibrary(tidyverse)\nlibrary(openintro)\n\n\nExercise 1 (2 points)\nInsert any text here.\n\n# Insert code for Exercise 1 here\n\n\n\nExercise 2 (3 points)\nInsert any text here.\n\n# Insert code for Exercise 2 here\n\n\n\nExercise 3 (4 points)\nInsert any text here.\n\n# Insert code for Exercise 3 here\n\n\n\nExercise 4 (4 points)\nInsert any text here.\n\n# Insert code for Exercise 4 here\n\n\n\nExercise 5 (2 points)\nInsert any text here.\n\n# Insert code for Exercise 5 here\n\n\n\nExercise 6 (5 points)\nInsert any text here.\n\n# Insert code for Exercise 6 here\n\n\n\nExercise 7 (5 points)\nInsert any text here.\n\n# Insert code for Exercise 7 here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 101L: Data Analysis and Statistical Inference",
    "section": "",
    "text": "Week\nDate\nTopic\nReading\nSlides\nLab\nHW\nProject\n\n\n\n\n0.5\nWed, May 11\nWelcome to STA 101!\nTypes of data and studies\n(1.2; 2.2-3)\nüñ•Ô∏è\nüñ•Ô∏è\n\n\n\n\n\n\nThu, May 12\nVisualization I\n5.1-5.6\nüñ•Ô∏è\n\n\n\n\n\n\nFri, May 13\nLab 1 - Introduction to R and RStudio\n\n\nüíª\n\n\n\n\n\nSun, May 15\nDue: homework 1\n\n\n\n‚úçÔ∏è\n\n\n\n1\nMon, May 16\nVisualization II\n4.1-4.5\nüñ•Ô∏è\n\n\n\n\n\n\nTue, May 17\nSimple linear regression\n7.1-7.3\nüñ•Ô∏è\n\n\n\n\n\n\nWed, May 18\nLab 2 - Visualization\nDue: Homework 2\n\n\nüíª\n‚úçÔ∏è\n\n\n\n\nThu, May 19\nMultiple linear regression\n8.1-8.2\nüñ•Ô∏è\n\n\n\n\n\n\nFri, May 20\nLab 3 - Linear regression\n\n\nüíª\n\n\n\n\n2\nMon, May 23\nModel selection\n8.3-8.4; 25.2-25.3\n\n\n\n\n\n\n\nTue, May 24\nLogistic regression\n9.1-9.3\n\n\n\n\n\n\n\nWed, May 25\nLab 4 - functions, loops\n\n\n\n\n\n\n\n\nThu, May 26\nPrinciples of inference\nWork on project\n11.0; 11.3; 12.0; 12.3; 13.1-13.3\n\n\n\n\n\n\n\nFri, May 27\nLab 5 - work on prediction project [PP]\n\n\n\n\n\n\n\n3\nMon, May 30\nMemorial Day holiday\n\n\n\n\n\n\n\n\nTue, May 31\nDue: PP model\nPP discussion\nInference for proportions I\n16.1-16.2\n\n\n\nPP model (9am)\nPP presentation\n\n\n\nWed, June 1\nLab 6 - work on PP\nDue: PP report\n\n\n\n\nPP report\n\n\n\nThu, June 2\nInference for proportions II\n17.1-17.3\n\n\n\n\n\n\n\nFri, June 3\nLab 7 - Inference for proportions\n\n\n\n\n\n\n\n4\nMon, June 6\nInference for means I\n19.1-19.2\n\n\n\n\n\n\n\nTue, June 7\nInference for means II\n20.1-20.4; 21.1-21.3\n\n\n\n\n\n\n\nWed, June 8\nLab 8 - Inference for means\n\n\n\n\n\n\n\n\nThu, June 9\nInference for regression\n24.2-24.6; 25.1; 26.1-26.2\n\n\n\n\n\n\n\nFri, June 10\nLab 9 - inference for regression\n\n\n\n\n\n\n\n5\nMon, June 13\nANOVA and \\(\\chi^2\\) tests\n18.1-18.2; 22.2-22.3\n\n\n\n\n\n\n\nTue, June 14\nWork on inference project (IP)\n\n\n\n\n\n\n\n\nWed, June 15\nLab 10 - work on IP\n\n\n\n\n\n\n\n\nThu, June 16\nIP presentations\nWrap up\n\n\n\n\nIP presentation\n\n\n\nFri, June 17\nLab 11 - work on IP\n\n\n\n\n\n\n\n6\nMon, June 20\nJuneteenth holiday\n\n\n\n\n\n\n\n\nTue, June 21\nReading period\n\n\n\n\n\n\n\n\nWed, June 22\n\n\n\n\n\n\n\n\n\nThu, June 23\nDue: IP report\n\n\n\n\nIP report"
  },
  {
    "objectID": "labs/lab-0x.html",
    "href": "labs/lab-0x.html",
    "title": "Lab 0 - Meet + greet",
    "section": "",
    "text": "Your answers can be brief. Some of your answers will be used to guide what application examples might be of interest to a majority of students in the course and some of your answers will be used to help guide team formation. We expect this will take you ~10 minutes."
  },
  {
    "objectID": "labs/lab-1x.html",
    "href": "labs/lab-1x.html",
    "title": "Lab 1 - Meet the toolkit",
    "section": "",
    "text": "This lab will go through much of the same workflow we‚Äôve demonstrated in class. The main goal is to reinforce our understanding of R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\n\n\n\n\n\n\nNote\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface.\n\n\nAn additional goal is to reinforce git and GitHub, the collaboration and version control system that we will be using throughout the course.\n\n\n\n\n\n\nNote\n\n\n\nGit is a version control system (like ‚ÄúTrack Changes‚Äù features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nTo make versioning simpler, this is a solo lab. In the future, you‚Äôll learn about collaborating on GitHub and producing a single lab report for your lab team, but for now, concentrate on getting the basics down.\n\n\nBy the end of the lab, you will‚Ä¶\n\nBe familiar with the workflow using R, RStudio, Git, and GitHub\nGain practice writing a reproducible report using RMarkdown\nPractice version control using GitHub\nBe able to create data visualizations using ggplot2\nBe able to describe variable distributions and the relationship between multiple variables"
  },
  {
    "objectID": "labs/lab-1x.html#getting-started",
    "href": "labs/lab-1x.html#getting-started",
    "title": "Lab 1 - Meet the toolkit",
    "section": "Getting started",
    "text": "Getting started\n\n\n\n\n\n\nImportant\n\n\n\nYour lab TA will lead you through the Getting Started section.\n\n\n\nLog in to RStudio\n\nGo to https://vm-manage.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA210 to log into the Docker container. You should now see the RStudio environment.\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you haven‚Äôt yet done so, you will need to reserve a container for STA210 first.\n\n\n\n\nSet up your SSH key\nYou will authenticate GitHub using SSH. Below are an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nType credentials::ssh_setup_github() into your console.\nR will ask ‚ÄúNo SSH key found. Generate one now?‚Äù You should click 1 for yes.\nYou will generate a key. It will begin with ‚Äússh-rsa‚Ä¶.‚Äù R will then ask ‚ÄúWould you like to open a browser now?‚Äù You should click 1 for yes.\nYou may be asked to provide your GitHub username and password to log into GitHub. After entering this information, you should paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta210).\n\nYou can find more detailed instructions here if you‚Äôre interested.\n\n\nConfigure Git\nThere is one more thing we need to do before getting started on the assignment. Specifically, we need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"GitHub username\", \n  user.email = \"Email associated with your GitHub account\"\n  )\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"mine-cetinkaya-rundel\", \n  user.email = \"cetinkaya.mine@gmail.com\"\n  )\n\nYou are now ready interact with GitHub via RStudio!\n\n\nClone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta210-s22 organization on GitHub. Click on the repo with the prefix lab-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-1-ikea.qmd to open the template R Markdown file. This is where you will write up your code and narrative for the lab.\n\n\n\nR and R Studio\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file.\n\n\n\nYAML\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for ‚ÄúYAML Ain‚Äôt Markup Language‚Äù. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (`.qmd`) file in your project, change the author name to your name, and render the document. Examine the rendered document.\n\n\n\n\nCommitting changes\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Rmd file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you‚Äôre happy with these changes, we‚Äôll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, ‚Äúupdated author name‚Äù) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don‚Äôt have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let‚Äôs make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you‚Äôre good to go!\n\n\nPush changes\nNow that you have made an update and committed this change, it‚Äôs time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push."
  },
  {
    "objectID": "labs/lab-1x.html#packages",
    "href": "labs/lab-1x.html#packages",
    "title": "Lab 1 - Meet the toolkit",
    "section": "Packages",
    "text": "Packages\nWe will use the following package in today‚Äôs lab.\n\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.1.6     v dplyr   1.0.9\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\nThe tidyverse is a meta-package. When you load it you get eight packages loaded for you:\n\nggplot2: for data visualization\ndplyr: for data wrangling\ntidyr: for data tidying and rectangling\nreadr: for reading and writing data\ntibble: for modern, tidy data frames\nstringr: for string manipulation\nforcats: for dealing with factors\npurrr: for iteration with functional programming\n\nThe message that‚Äôs printed when you load the package tells you which versions of these packages are loaded as well as any conflicts they may have introduced, e.g., the filter() function from dplyr has now masked (overwritten) the filter() function available in base R (and that‚Äôs ok, we‚Äôll use dplyr::filter() anyway).\nWe‚Äôll be using functionality from all of these packages throughout the semester, though we‚Äôll always load them all at once with library(tidyverse). You can find out more about the tidyverse and each of the packages that make it up here."
  },
  {
    "objectID": "labs/lab-1x.html#data-ikea-furniture",
    "href": "labs/lab-1x.html#data-ikea-furniture",
    "title": "Lab 1 - Meet the toolkit",
    "section": "Data: Ikea furniture",
    "text": "Data: Ikea furniture\nToday‚Äôs data is all about Ikea furniture. The data was obtained from the TidyTuesday data collection.\nUse the code below to read in the data.\n\nikea <- read_csv(\"data/ikea.csv\")\n\n\nData dictionary\nThe variable definitions are as follows:\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nitem_id\ndouble\nitem id which can be used later to merge with other IKEA data frames\n\n\nname\ncharacter\nthe commercial name of items\n\n\ncategory\ncharacter\nthe furniture category that the item belongs to (Sofas, beds, chairs, Trolleys,‚Ä¶)\n\n\nsellable_online\nlogical\nSellable online TRUE or FALSE\n\n\nlink\ncharacter\nthe web link of the item\n\n\nother_colors\ncharacter\nif other colors are available for the item, or just one color as displayed in the website (Boolean)\n\n\nshort_description\ncharacter\na brief description of the item\n\n\ndesigner\ncharacter\nThe name of the designer who designed the item. this is extracted from the full_description column.\n\n\ndepth\ndouble\nDepth of the item in Centimeter\n\n\nheight\ndouble\nHeight of the item in Centimeter\n\n\nwidth\ndouble\nWidth of the item in Centimeter\n\n\nprice_usd\ndouble\nthe current price in US dollars as it is shown in the website by 4/20/2020\n\n\n\n\n\nView the data\nBefore doing any analysis, you may want to get quick view of the data. This is useful when you‚Äôve imported data to see if your data imported correctly. We can use the view() function to see the entire data set in RStudio. Type the code below in the Console to view the entire dataset.\n\nview(ikea)"
  },
  {
    "objectID": "labs/lab-1x.html#exercises",
    "href": "labs/lab-1x.html#exercises",
    "title": "Lab 1 - Meet the toolkit",
    "section": "Exercises",
    "text": "Exercises\nWrite all code and narrative in your R Markdown file. Write all narrative in complete sentences. Throughout the assignment, you should periodically Render your Quarto document to produce the updated PDF, commit the changes in the Git pane, and push the updated files to GitHub.\n\n\n\n\n\n\nTip\n\n\n\nMake sure we can read all or your code in your PDF document. This means you will need to break up long lines of code. One way to help avoid long lines of code is is start a new line after every pipe (%>%) and plus sign (+).\n\n\n\nExercise 1\nThe view() function helped us get a quick view of the dataset, but let‚Äôs get more detail about its structure. Viewing a summary of the data is a useful starting point for data analysis, especially if the dataset has a large number of observations (rows) or variables (columns). Run the code below to use the glimpse() function to see a summary of the ikea dataset.\nHow many observations are in the ikea dataset? How many variables?\n\nglimpse(ikea)\n\n\n\n\n\n\n\nNote\n\n\n\nIn your lab-1-ikea.qmd document you‚Äôll see that we already added the code required for the exercise as well as a sentence where you can fill in the blanks to report the answer. Use this format for the remaining exercises.\nAlso note that the code chunk as a label: glimpse-data. It‚Äôs not required, but good practice and highly encouraged to label your code chunks in this way.\n\n\n\n\nExercise 2\nWe begin each regression analysis with exploratory data analysis (EDA) to help us ‚Äúget to know‚Äù the data and examine the variable distributions and relationships between variables. We do this by visualizing the data and calculating summary statistics to describe the variables in our dataset. In this lab, we will focus on data visualizations.\nLet‚Äôs begin by looking at the price of Ikea furniture. Use the code below to visualize the distribution of price_usd, the price in US dollars.\n\nggplot(data = ikea, aes(x = price_usd)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nUse the visualization to describe the distribution of price. In your narrative, include description of the shape, approximate center, approximate spread, and any presence of outliers. Briefly explain why the median is more representative of the center of this distribution than the mean.\n\n\n\n\n\n\nTip\n\n\n\nWhen using the visual editor you can insert a code chunk using the Insert menu on top or by using the catch-all ‚åò / shortcut to insert just about anything. Just execute the shortcut then type what you want to insert. If you are at the beginning of a line you can also enter plain / to invoke the shortcut.\n\n\n\n\nExercise 3\nWhen we make visualizations, we want them to be clear and suitable for a professional audience. This means that, at a minimum, each visualization should have an informative title and informative axis labels. Let‚Äôs modify the plot from the previous question to make it suitable for a professional audience. Complete the code below to include an informative title and informative axis labels.\n\nggplot(data = ikea, aes(x = price_usd)) +\n  geom_histogram() +\n  labs(\n    x = \"_____\",\n    y = \"_____\",\n    title = \"_____\"\n  )\n\n\nThis is a good place to fender, commit, and push changes to your remote lab-1 repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message (e.g.,¬†‚ÄúCompleted exercises 1 - 3‚Äù), and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 4\nAnother way to visualize numeric data is using density plots. Make a density plot to visualize the distribution of price_usd. Be sure to include an informative title and informative axis labels.\nIn this course, we‚Äôll be most interested in the relationship between two or more variables, so let‚Äôs begin by looking at the distribution of price by category. We‚Äôll focus on the five categories in the code below, since these include commonly purchased types of furniture.\nUse the code below to create a new data frame that only includes the furniture categories of interest. We‚Äôre assigning this data frame to an object with a new name, so we don‚Äôt overwrite the original data.\nHow many observations are in the ikea_sub dataset? How many variables?\n\nikea_sub <- ikea %>%\n  filter(category %in% c(\n    \"Tables & desks\", \"Beds\",\n    \"Bookcases & shelving units\",\n    \"Sofas & armchairs\", \"Children's furniture\"\n  ))\n\n\n\n\n\n\n\nImportant\n\n\n\nYou will use this newly constructed data frame, ikea_sub, for the remainder of the lab.\n\n\n\n\nExercise 5\nLet‚Äôs make a new visualization with the density curves colored by category, so we can compare the distribution of price for each category.\n\nggplot(data = ikea_sub, aes(x = price_usd, fill = category)) +\n  geom_density()\n\n\n\n\nThe overlapping colors make it difficult to tell what‚Äôs happening with the distributions for the categories plotted first and hence covered by categories plotted over them. We can change the transparency level of the fill color to help with this. The alpha argument takes values between 0 and 1: 0 is completely transparent and 1 is completely opaque. There is no way to tell what value will work best, so it‚Äôs best to try a few.\nRecreate the density plot using a more suitable alpha level, so we can more easily see the distribution of all the categories. Include an informative title and informative axis labels.\n\nggplot(data = ikea_sub, aes(x = price_usd, fill = category)) +\n  geom_density(alpha = 0.8)\n\n\n\n\n\nThis is a good place to render, commit, and push changes to your remote lab-1 repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message (e.g.,¬†‚ÄúCompleted exercises 4 and 5‚Äù), and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 6\nBriefly describe why we defined the fill of the curves by mapping aesthetics of the plot (inside the aes function) but we defined the alpha level as a characteristic of the plotting geom.\n\n\nExercise 7\nOverlapping density plots are not the only way to visualize the relationship between a quantitative and categorical variable.\nUse a different type of plot to visualize the relationship between price_usd and category. Include an informative title and informative axis labels.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the ggplot2 cheatsheet and from Data to Viz for inspiration.\n\n\n\n\nExercise 8\nCompare and contrast your plots from the previous exercise to the overlapping density plots from Exercise 5. What features are apparent in the plot from the previous exercise that aren‚Äôt in the overlapping density plots? What features are apparent in the overlapping density plots that aren‚Äôt in the plot from the previous exercise? What features are apparent in both?\n\nThis is a good place to render, commit, and push changes to your remote lab-1 repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message (e.g.,¬†‚ÄúCompleted exercises 6 - 8‚Äù), and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 9\nNext, let‚Äôs look at the relationship between the price and width of Ikea furniture. Fill in the code below to visualize the relationship between the two variables using a scatterplot.\nThen, use your visualization to describe the relationship between the width and price of Ikea furniture.\n\nggplot(data = _____, aes(x = width, y = _____)) +\n  geom_point() + \n  labs(\n    x = \"_____\", \n    y = \"_____\", \n    title = \"_____\"\n    )\n\n\n\nExercise 10\nColor the points of the scatterplot by category. Describe how the relationship between price and width of Ikea furniture differs by category, if at all.\n\nYou‚Äôre done and ready to submit your work! Render, commit, and push all remaining changes. You can use the commit message ‚ÄúDone with Lab 1!‚Äù , and make sure you have committed and pushed all changed files to GitHub (your Git pane in RStudio should be empty) and that all documents are updated in your repo on GitHub. The PDF document you submit to Gradescope should be identical to the one in your GitHub repo."
  },
  {
    "objectID": "labs/lab-1x.html#submission",
    "href": "labs/lab-1x.html#submission",
    "title": "Lab 1 - Meet the toolkit",
    "section": "Submission",
    "text": "Submission\nIn this class, we‚Äôll be submitting PDF documents to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "labs/lab-1x.html#grading",
    "href": "labs/lab-1x.html#grading",
    "title": "Lab 1 - Meet the toolkit",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51\n\n\n\n1¬†The ‚ÄúWorkflow & formatting‚Äù grade is to assess the reproducible workflow. This includes having at least 3 informative commit messages and updating the name and date in the YAML."
  },
  {
    "objectID": "labs/lab-1x.html#resources-for-additional-practice-optional",
    "href": "labs/lab-1x.html#resources-for-additional-practice-optional",
    "title": "Lab 1 - Meet the toolkit",
    "section": "Resources for additional practice (optional)",
    "text": "Resources for additional practice (optional)\n\nChapter 2: Get Started Data Visualization by Kieran Healy\nChapter 3: Data visualization in R for Data Science by Hadley Wickham\nRStudio Cloud Primers\n\nVisualization Basics: https://rstudio.cloud/learn/primers/1.1\nWork with Data: https://rstudio.cloud/learn/primers/2\nVisualize Data: https://rstudio.cloud/learn/primers/3"
  },
  {
    "objectID": "labs/lab-2x.html",
    "href": "labs/lab-2x.html",
    "title": "Lab 2 - College scorecard",
    "section": "",
    "text": "In today‚Äôs lab, you‚Äôll use simple linear regression to analyze the relationship between the admissions rate and total cost for colleges and universities in the United States.\n\n\nBy the end of the lab you will‚Ä¶\n\nBe able to fit a simple linear regression model using R.\nBe able to interpret the slope and intercept for the model.\nBe able to use statistical inference to draw conclusions about the slope.\nContinue developing a workflow for reproducible data analysis."
  },
  {
    "objectID": "labs/lab-2x.html#getting-started",
    "href": "labs/lab-2x.html#getting-started",
    "title": "Lab 2 - College scorecard",
    "section": "Getting started",
    "text": "Getting started\n\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClone the repo and start a new project in RStudio. See the Lab 1 instructions for details on cloning a repo, starting a new R project and configuring git."
  },
  {
    "objectID": "labs/lab-2x.html#packages",
    "href": "labs/lab-2x.html#packages",
    "title": "Lab 2 - College scorecard",
    "section": "Packages",
    "text": "Packages\nWe will use the following package in today‚Äôs lab.\n\nlibrary(tidyverse)  # for data wrangling + visualization\nlibrary(tidymodels) # for modeling\nlibrary(knitr)      # for pretty printing of tables"
  },
  {
    "objectID": "labs/lab-2x.html#data-college-scorecard",
    "href": "labs/lab-2x.html#data-college-scorecard",
    "title": "Lab 2 - College scorecard",
    "section": "Data: College scorecard",
    "text": "Data: College scorecard\nThe data for this lab is from the scorecard data set in the rcfss R package. It includes information originally obtained from the U.S. Department of Education‚Äôs College Scorecard for 1753 colleges and universities during the 2018 - 2019 academic year.\nThe lab focuses on the following variables:\n\nadmrate: Undergraduate admissions rate (from 0-100%)\ncost: The average annual total cost of attendance, including tuition and fees, books and supplies, and living expenses\ntype: Type of college (Public; Private, nonprofit; Private, for-profit)\n\nClick here to see a full list of variables and definitions.\nUse the code below to load the data set.\n\nscorecard <- read_csv(\"data/scorecard.csv\")"
  },
  {
    "objectID": "labs/lab-2x.html#exercises",
    "href": "labs/lab-2x.html#exercises",
    "title": "Lab 2 - College scorecard",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nNote\n\n\n\nInclude axis labels and an informative title for all plots. Use the kable() function to neatly print tables and regression output.\n\n\n\nExercise 1\nCreate a histogram to examine the distribution of admrate and calculate summary statistics for the center (mean and median) and the spread (standard deviation and IQR).\n\n\nExercise 2\nUse the results from the previous exercise to describe the distribution of admrate. Include the shape, center, spread, and if there are potential outliers.\n\n\nExercise 3\nPlot the distribution of cost and calculate the appropriate summary statistics. Describe the distribution of cost (shape, center, and spread, and outliers) using the plot and appropriate summary statistics.\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 4\nThe goal of this analysis is to fit a regression model that can be used to understand the variability in the cost of college based on the admission rate. Before fitting the model, let‚Äôs look at the relationship between the two variables. Create a scatterplot to display the relationship between cost and admissions rate. Describe the relationship between the two variables based on the plot.\n\n\nExercise 5\nDoes the relationship between cost and admissions rate differ by type of college? Modify the plot from the previous exercise visualize the relationship by type of college.\n\n\nExercise 6\nDescribe two new observations from the scatterplot in Exercise 5 that you didn‚Äôt see in the scatterplot from Exercise 4.\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 7\nFit the linear regression model. Use the kable function to neatly display the results with a reasonable number of decimals.\n\n\nExercise 8\nConsider the model from the previous exercise.\n\nInterpret the slope in the context of the problem.\nDoes the intercept have a meaningful interpretation? If so, write the interpretation in the context of the problem. Otherwise, explain why the interpretation is not meaningful.\n\n\n\nExercise 9\nConstruct a 95% confidence interval for the slope using bootstrapping. Follow these steps to accomplish this:\n\nFirst set a seed for simulating reproducibly.\nThen, simulate the bootstrap distribution of the slope using 1,000 bootstrap samples.\nThen, visually estimate the bounds of the bootstrap interval based on a histogram of the distribution of the bootstrapped slopes, using the percentile method.\nAnd then, use the get_confidence_interval() function to explicitly calculate the bounds of the confidence interval using the percentile method.\nFinally, interpret the confidence interval in the context of the data.\n\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\n\n\n\nExercise 10\nFinally, we want to answer the question ‚ÄúDo the data provide sufficient evidence of a linear relationship between cost and admissions rate, i.e.¬†\\(\\beta_1\\) is different from 0?‚Äù\nTo answer this question we will use a hypothesis test. We can conduct a hypothesis test via simulation (what we‚Äôll do in this lab) or using mathematical models (what we‚Äôll do in the next class).\nBefore we can conduct the hypothesis test, let‚Äôs first set our hypotheses. Remember that the null hypothesis represents the status quo (nothing going on, i.e.¬†there is no relationship) and the alternative hypothesis represents our research question (there is something going on, i.e.¬†there is a relationship).\n\n\\(H_0\\): There is no linear relationship between the admissions rate and cost of colleges in the United States, \\(\\beta_1 = 0\\)\n\\(H_A\\): There is a linear relationship between the admissions rate and cost of colleges in the United States, \\(\\beta_1 \\ne 0\\)\n\nTo test these hypotheses, we will use a permutation test, where we\n\nSimulate new samples from the original sample via permutation under the assumption that the null hypothesis is true\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to calculate the p-value for the hypothesis test\n\nThe major difference between constructing a confidence interval and conducting a hypothesis test is that for the hypothesis test we assume that the null hypothesis is true. This requires a simulation scheme that will allow us to measure the natural variability in the data due to sampling but not due to cost and admission rate being correlated by permuting permute one variable to eliminate any existing relationship between the variables. To do so, we randomly assign each admrate value to cost of a given university, i.e.¬†cost and admrate are no longer matched for a given university.\nIn the following code chunk we\n\nFirst set a seed for simulating reproducibly.\nThen, we start with our data frame and specify our model as cost vs.¬†admrate.\nThen, we set our null hypothesis (cost and admrate are independent)\nAnd then we generate 1000 replicates of our data where, for each replicate, we permute values of admrate to randomly assign them to values of cost\nFinally, we fit our model to each of our 1000 permuted datasets\n\n\nset.seed(1234)\n\nperm_fits <- scorecard %>%\n  specify(cost ~ admrate) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 1000, type = \"permute\") %>%\n  fit()\n\nThe resulting dataset perm_fits has nrow(perm_fits) and ncol(perm_fits) columns. The first column, replicate indicates the replicate number of the dataset the models were fit to; the values in this column range between 1 and 1000. The second column, term, tells us which term (intercept of the model or slope of admrate) the estimate value in the third column is for.\n\nperm_fits\n\n# A tibble: 2,000 x 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       <int> <chr>        <dbl>\n 1         1 intercept  36857. \n 2         1 admrate     -781. \n 3         2 intercept  35901. \n 4         2 admrate      643. \n 5         3 intercept  36608. \n 6         3 admrate     -411. \n 7         4 intercept  35831. \n 8         4 admrate      746. \n 9         5 intercept  36367. \n10         5 admrate      -51.7\n# ... with 1,990 more rows\n\n\n\nCreate a histogram of the slope estimates in perm_fits. (Hint: Filter the dataset for just the slope values, term == \"admrate\".)\nEstimate the p-value of the hypothesis test based on this distribution.\nState your conclusion for the test in context.\nIndicate whether or not it is consistent with the results of the hypothesis test from the previous exercise. Briefly explain your response.\n\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty."
  },
  {
    "objectID": "labs/lab-2x.html#submission",
    "href": "labs/lab-2x.html#submission",
    "title": "Lab 2 - College scorecard",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "labs/lab-2x.html#grading",
    "href": "labs/lab-2x.html#grading",
    "title": "Lab 2 - College scorecard",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51\n\n\n\n\n\n\n1¬†The ‚ÄúWorkflow & formatting‚Äù grade is to assess the reproducible workflow. This includes having at least 3 informative commit messages and updating the name and date in the YAML."
  },
  {
    "objectID": "labs/lab-3x.html",
    "href": "labs/lab-3x.html",
    "title": "Lab 3 - Coffee ratings",
    "section": "",
    "text": "In today‚Äôs lab you will analyze data from over 1,000 different coffees to explore the relationship between a coffee‚Äôs aroma and it‚Äôs overall quality. You will also begin working with your team and practicing a collaborative data analysis workflow.\n\n\nBy the end of the lab you will‚Ä¶\n\nCreate plots and calculate associated statistics to assess model diagnostics.\nPractice collaborating with others using a single Github repo."
  },
  {
    "objectID": "labs/lab-3x.html#meet-your-team",
    "href": "labs/lab-3x.html#meet-your-team",
    "title": "Lab 3 - Coffee ratings",
    "section": "Meet your team!",
    "text": "Meet your team!\nClick here to see the team assignments for STA 210. This will be your team for labs and the final project.\nBefore you get started on the lab, your TA will walk you through the following:\n\nIcebreaker activity to get to know your teammates.\nCome up with a team name. You can‚Äôt use the same name as another team, so I encourage you to be creative! Your TA will get your team name by the end of lab.\nFill out the team agreement. This will help you figure out a plan for communication and working together during labs and outside of lab times. You can find the team agreement in the GitHub repo team-agreement-[github_team_name].\nHave one person from the team clone the repo and start a new RStudio project. This person will type the team‚Äôs responses as you discuss the sections of the agreement. No one else in the team should type at this point but should be contributing to the discussion.\nBe sure to push the completed agreement to GitHub. Each team member can refer to the document in this repo or download the PDF of the agreement for future reference. You do not need to submit the agreement on Gradescope."
  },
  {
    "objectID": "labs/lab-3x.html#getting-started",
    "href": "labs/lab-3x.html#getting-started",
    "title": "Lab 3 - Coffee ratings",
    "section": "Getting started",
    "text": "Getting started\n\nA repository has already been created for you and your teammates. Everyone in your team has access to the same repo.\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nEach person on the team should clone the repository and open a new project in RStudio. Do not make any changes to the .qmd file until the instructions tell you do to so."
  },
  {
    "objectID": "labs/lab-3x.html#workflow-using-git-and-github-as-a-team",
    "href": "labs/lab-3x.html#workflow-using-git-and-github-as-a-team",
    "title": "Lab 3 - Coffee ratings",
    "section": "Workflow: Using Git and GitHub as a team",
    "text": "Workflow: Using Git and GitHub as a team\n\n\n\n\n\n\nImportant\n\n\n\nAssign each person on your team a number 1 through 4. For teams of three, Team Member 1 can take on the role of Team Member 4.\n\n\nThe following exercises must be done in order. Only one person should type in the .qmd file, commit, and push updates at a time. When it is not your turn to type, you should still share ideas and contribute to the team‚Äôs discussion.\n\n\n\n\n\n\n‚å®Ô∏è Team Member 1: Hands on the keyboard.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!1\n\n\n\nChange the author to your team name and include each team member‚Äôs name in the author field of the YAML in the following format: Team Name: Member 1, Member 2, Member 3, Member 4.\n\nTeam Member 1: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub.\n\n\nTeam Members 2, 3, 4: Once Team Member 1 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the updated name in your .qmd file."
  },
  {
    "objectID": "labs/lab-3x.html#packages",
    "href": "labs/lab-3x.html#packages",
    "title": "Lab 3 - Coffee ratings",
    "section": "Packages",
    "text": "Packages\nThe following packages are used in the lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(ggfortify)"
  },
  {
    "objectID": "labs/lab-3x.html#data-coffee-ratings",
    "href": "labs/lab-3x.html#data-coffee-ratings",
    "title": "Lab 3 - Coffee ratings",
    "section": "Data: Coffee ratings",
    "text": "Data: Coffee ratings\nThe dataset for this lab comes from the Coffee Quality Database and was obtained from the #TidyTuesday GitHub repo. It includes information about the origin, producer, measures of various characteristics, and the quality measure for over 1000 coffees.\nThis lab will focus on the following variables:\n\naroma: Aroma grade, 0 - 10 scale\ntotal_cup_points: Measure of quality, 0 - 100 scale\n\nYou can find the definitions for all variables in the data set here. Click here for more details about how these measures are obtained.\n\ncoffee_ratings <- read_csv(\"data/coffee_ratings.csv\")"
  },
  {
    "objectID": "labs/lab-3x.html#exercises",
    "href": "labs/lab-3x.html#exercises",
    "title": "Lab 3 - Coffee ratings",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nNote\n\n\n\n\nInclude axis labels and an informative title for all plots.\nUse the kable function to neatly print tables and regression output. Write all interpretations in the context of the data.\nDo the following exercises in order, following each step carefully.\nOnly one person at a time should type in the .qmd file and push updates.\nIf you are working on any portion of the lab virtually, the person working should share their screen and the others should follow along.\n\n\n\n\n\n\n\n\n\n‚å®Ô∏è Team Member 1: Hands still on the keyboard. Write the answers to Exercises 1 and 2.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\n\nExercise 1\nVisualize the relationship between aroma and the total cup points. What do you observe from the plot? Use the plot the describe the relationship between the two variables.\n\n\nExercise 2\nFit the linear model and neatly display the results using 3 digits. Interpret the slope in context of the data.\n\nTeam Member 1: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 2, 3, 4: Once Team Member 1 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the responses to Exercises 1 and 2 in your .qmd file.\n\n\nNow it‚Äôs time for a hand off‚Ä¶\n\n\n\n\n\n\n‚å®Ô∏è Team Member 2: Hands on the keyboard. Write the answers to Exercises 3 and 4.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\n\n\nExercise 3\nWould the members of your group drink a coffee represented by the intercept? Why or why not? Discuss as a group and write the group‚Äôs consensus.\n\n\nExercise 4\nLeverage is the measure of the distance between an observation‚Äôs values of the predictor variables and the average values of the predictor variables for the entire data set. An observation s set if have high leverage if its combination of values for the predictor variables is very far from the typical combination of values in the data.An observation has high leverage if its combination of values for the predictor variables is very far from the typical combination of values in the data. Observations with high leverage should be considered as potential influential points.\nWe will proceed assuming the model conditions hold, so let‚Äôs focus on the model diagnostics. We‚Äôll start by examining if there are any points with high leverage in the data.\nTheoretically, the leverage of the \\(i^{th}\\) observation as follows:\n\\[\nh_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j = 1}^n (x_j - \\bar{x})^2}\n\\]\nNote that leverage only depends on values of the predictor variable(s).\nThe sum of the leverages for all points is \\(p + 1\\), where\n\n\\(p\\) is the number of predictors\nIn the case of SLR, \\(\\sum_{i = 1}^n h_i = 2\\)\nThe ‚Äútypical‚Äù leverage is \\(\\frac{(p + 1)}{n}\\)\n\nTherefore, an observation is said to have high leverage if\n\\[\nh_i > \\frac{2(p + 1)}{n}\n\\]\nIn addition to comparing the leverage of points to a threshold, we also generally visualize standard residuals vs.¬†leverage values our data. The autoplot() function from the ggfortify package is very useful for drawing these standard plots easily.\n\nautoplot(coffee_fit$fit, which = 5)\n\n\nWhat threshold will you use to determine if there are points with high leverage for this dataset?\nAre there any observations with high leverage? If so, how many? Briefly explain, including any output, graphs, etc. you used to determine the response. Improve your plot by adding a new year to draw a vertical line (with geom_vline()) at the value of the threshold you‚Äôre using to determine which points have high leverage.\n\n\nTeam Member 2: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 1, 3, 4: Once Team Member 2 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the responses to Exercises 3 and 4 in your .qmd file.\n\n\nNow it‚Äôs time for another hand off‚Ä¶\n\n\n\n\n\n\n‚å®Ô∏è Team Member 3: Hands on the keyboard. Write the answers to Exercises 5.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\n\n\nExercise 5\nAnother standard model diagnostic involves identifying points that don‚Äôt fit the pattern from the regression line. We do this by determining which points have large standardized residuals (residual divided by the standard error of residuals).\n\\[\nStd.~res_i = \\frac{y_i - \\hat{y}_1}{\\hat{\\sigma}_\\epsilon ~ \\sqrt{1 - h_i}},\n\\]\nwhere \\(\\hat{\\sigma}_\\epsilon\\) is the regression standard error.\n\n\n\n\n\n\nNote\n\n\n\nThese values are already calculated in the output of augment().\n\n\nObservations that have standardized residuals of large magnitude (usually beyond \\(\\pm\\) 3) are potential outliers, since they don‚Äôt fit the pattern determined by the regression model. Therefore, a common practice is to plot standardized residuals vs.¬†fitted values, to make it easier to identify outliers.\nWe can obtain this plot with the following:\n\nautoplot(coffee_fit$fit, which = 3)\n\nCreate this visualization and horizontal lines (with geom_hline()) at the cutoff values for ‚Äúlarge‚Äù standardized residuals (\\(\\pm\\) 3). Are there any such points in the data? If so, how many? Briefly explain, including any output, graphs, etc. you used to determine the response.\n\nTeam Member 3: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 1, 2, 4: Once Team Member 3 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the responses to Exercise 5 and 4 in your .qmd file.\n\n\nNow it‚Äôs time for another hand off‚Ä¶\n\n\n\n\n\n\n‚å®Ô∏è Team Member 4: Hands on the keyboard. Write the answers to Exercises 6.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\n\n\nExercise 6\nFinally, we‚Äôll examine Cook‚Äôs Distance. An observation‚Äôs influence on the regression line depends on how close it lies to the general trend of the data (i.e., its standardized residual) and it‚Äôs leverage (\\(h_i\\)). Cook‚Äôs Distance is a statistic that includes both of these components to measure an observation‚Äôs overall impact on the model. Cook‚Äôs Distance for the \\(i^{th}\\) observation is defined as the follows:\n\\[\nD_i = \\frac{(std.~res)^2}{p + 1} (\\frac{h_i}{1-\\frac{h_i})\n\\]\nAn observation with large \\(D_i\\) is said to have a strong influence on the predicted values. On that scale,\n\n\\(D_i\\) > 0.5 is moderately influential\n\\(D_i\\) > 1 is very influential\n\nWe can plot of Cook‚Äôs distances vs.¬†the observation number with the following:\n\nautoplot(coffee_fit$fit, which = 4, ncol = 1)\n\n\n\n\nStandardized residuals, leverage, and Cook‚Äôs Distance should all be examined together. So what do we do with observations identified as outliers or leverage points?\nIt is OK to drop an observation based on the predictor variables if‚Ä¶\n\nIt is meaningful to drop the observation given the context of the problem\nYou intended to build a model on a smaller range of the predictor variables. You should mention this in the write up of the results and be careful to avoid extrapolation when making predictions.\n\nIt is not OK to drop an observation based on the response variable if‚Ä¶\n\nThese are legitimate observations and should be in the model.\nYou can try transformations or increasing the sample size by collecting more data.\n\nSo lastly, let‚Äôs analyze Cook‚Äôs D to determine if there are influential points in the data.\n\nBased on Cook‚Äôs D, are there any influential points in our data? Briefly explain, including any output, graphs, etc. you used to determine the response.\nIf there are influential points, briefly explain why they are outliers, i.e., not in the trend of the rest of the data.\nIf there are influential points, remove those points from the data and refit the model. How do the model coefficients change, if at all?\nIf there are influential points, would you recommend using the model fit with or without these points for inferential conclusions and predictions? Briefly explain why or why not. Additionally, briefly explain potential impacts your choice has on inferential conclusions and/or predictions.\n\n\nTeam Member 4: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 1, 2, 3: Once Team Member 4 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the responses to Exercise 6 and 4 in your .qmd file.\n\n\nNow it‚Äôs time for one last hand off‚Ä¶"
  },
  {
    "objectID": "labs/lab-3x.html#wrapping-up",
    "href": "labs/lab-3x.html#wrapping-up",
    "title": "Lab 3 - Coffee ratings",
    "section": "Wrapping up",
    "text": "Wrapping up\n\n\n\n\n\n\nImportant\n\n\n\n‚å®Ô∏è Team Member 2: Hands on the keyboard. Make any edits as needed.\nüôÖüèΩ All other team members: Hands off the keyboard until otherwise instructed!\n\n\n\nTeam Member 2: Render the document and confirm that the changes are visible in the PDF. Then, commit (with an informative commit message) both the .qmd and PDF documents, and finally push the changes to GitHub. Make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\nTeam Members 1, 3, 4: Once Team Member 2 is done rendering, committing, and pushing, confirm that the changes are visible on GitHub in your team‚Äôs lab repo. Then, in RStudio, click the Pull button in the Git pane to get the updated document. You should see the final version of your .qmd file."
  },
  {
    "objectID": "labs/lab-3x.html#submission",
    "href": "labs/lab-3x.html#submission",
    "title": "Lab 3 - Coffee ratings",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nSelect one team member to upload the team‚Äôs PDF submission to Gradescope.\nBe sure to include every team member‚Äôs name in the Gradescope submission.\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù). If any answer spans multiple pages, then mark all pages.\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section.\n\n\n\n\n\n\n\nImportant\n\n\n\nThere should only be one submission per team on Gradescope."
  },
  {
    "objectID": "labs/lab-3x.html#grading",
    "href": "labs/lab-3x.html#grading",
    "title": "Lab 3 - Coffee ratings",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 6\n42\n\n\nWorkflow & formatting\n52\n\n\nComplete team contract\n3"
  },
  {
    "objectID": "labs/lab-4x.html",
    "href": "labs/lab-4x.html",
    "title": "Lab 4 - The Office",
    "section": "",
    "text": "In today‚Äôs lab you will analyze data from the schrute package to predict IMDB scores for episodes of The Office.\n\n\n\n\n\n\nNote\n\n\n\nThis is a different data source than the one we‚Äôve used in class last week.\n\n\n\n\nBy the end of the lab you will‚Ä¶\n\nengineer features based on episode scripts\ntrain a model\ninterpret model coefficients\nmake predictions\nevaluate model performance on training and testing data"
  },
  {
    "objectID": "labs/lab-4x.html#getting-started",
    "href": "labs/lab-4x.html#getting-started",
    "title": "Lab 4 - The Office",
    "section": "Getting started",
    "text": "Getting started\n\nA repository has already been created for you and your teammates. Everyone in your team has access to the same repo.\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-4. It contains the starter documents you need to complete the lab.\nEach person on the team should clone the repository and open a new project in RStudio. Throughout the lab, each person should get a chance to make commits and push to the repo."
  },
  {
    "objectID": "labs/lab-4x.html#packages",
    "href": "labs/lab-4x.html#packages",
    "title": "Lab 4 - The Office",
    "section": "Packages",
    "text": "Packages\nThe following packages are used in the lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(schrute)\nlibrary(lubridate)\nlibrary(knitr)"
  },
  {
    "objectID": "labs/lab-4x.html#data-the-office",
    "href": "labs/lab-4x.html#data-the-office",
    "title": "Lab 4 - The Office",
    "section": "Data: The Office",
    "text": "Data: The Office\nThe dataset for this lab comes from the schrute package and it‚Äôs called theoffice. This dataset contains the entire script transcriptions from The Office.\nLet‚Äôs start by taking a peek at the data.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16~\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",~\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis~\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky~\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha~\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How ~\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How ~\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6~\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,~\n$ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005-~\n\n\nThere are 55130 observations and 12 columns in this dataset. The variable names are as follows.\n\nnames(theoffice)\n\n [1] \"index\"            \"season\"           \"episode\"          \"episode_name\"    \n [5] \"director\"         \"writer\"           \"character\"        \"text\"            \n [9] \"text_w_direction\" \"imdb_rating\"      \"total_votes\"      \"air_date\"        \n\n\nEach row in the dataset is a line spoken by a character in a given episode of the show. This means some information at the episode level (e.g., imdb_rating, air_date, etc. are repeated across the rows that belong to a single episode.\nThe air_date variable is coded as a factor, which is undesirable. We‚Äôll want to parse that variable later into its components during feature engineering. So, for now, let‚Äôs convert it to date.\n\ntheoffice <- theoffice %>%\n  mutate(air_date = ymd(as.character(air_date)))\n\nLet‚Äôs take a look at the data to confirm we‚Äôre happy with how each of the variables are encoded.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16~\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",~\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis~\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky~\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha~\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How ~\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How ~\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6~\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,~\n$ air_date         <date> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005~"
  },
  {
    "objectID": "labs/lab-4x.html#exercises",
    "href": "labs/lab-4x.html#exercises",
    "title": "Lab 4 - The Office",
    "section": "Exercises",
    "text": "Exercises\n\nData prep\n\nExercise 1\nIdentify episodes that touch on Halloween, Valentine‚Äôs Day, and Christmas.\n\nFirst, convert all text to lowercase with str_to_lower().\nThen, create three new variables (halloween_mention, valentine_mention, and christmas_mention) where that take on the value 1 if the character string \"halloween\", \"valentine\", or \"christmas\" appears in the text, respectively, and 0 otherwise.\n\nSome code is provided below to help you get started.\n\ntheoffice <- theoffice %>%\n  mutate(\n    text = ___(text),\n    halloween_mention = if_else(str_detect(text, \"___\"), ___, ___),\n    valentine_mention = ___,\n    ___ = ___\n  )\n\n\n\nExercise 2\nIn this exercise we‚Äôll accomplish two separate tasks. And there‚Äôs a good reason why we‚Äôre doing it all at once; we‚Äôre going to drastically change our data frame, from one row per line spoken to one row per episode. We‚Äôll call the resulting data frame office_episodes.\nThe two tasks are as follows:\n\nTask 1. Identify episodes where the word ‚Äúhalloween‚Äù, ‚Äúvalentine‚Äù, or ‚Äúchristmas‚Äù were ever mentioned, using variables you created above.\nTask 2. Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\nBelow are some instructions and starter code to get you started with these tasks.\n\nStart by grouping theoffice data by season, episode, episode_name, imdb_rating, total_votes, and air_date. (These variables, except for season have the same value for each given episode, hence grouping by them allows us to make sure they appear in the output of this pipeline.)\nUse summarize() to calculate the desired features at the season-episode level.\nTask 1:\n\nCalculate the number of lines per season per episode, you might name this new variable n_lines.\nThen, calculate the proportion of lines in that episode spoken by each of the four characters Jim, Pam, Michael, and Dwight. Name these new variables lines_jim, lines_pam, lines_michael, and lines_dwight, respectively.\n\nTask 2:\n\nCreate a variable called halloween that sums up the 1s in halloween_mention at the season-episode level and takes on the value \"yes\" if the sum is greater than or equal to 1, or \"no\" otherwise.\nDo something similar for new variables valentine and christmas as well based on values from valentine_mention and christmas_mention.\n\nFinish up your summarize() statement by dropping the groups, so the resulting data frame is no longer grouped and remove n_lines (we won‚Äôt use that variable in our analysis, we only calculated it as an intermediary step).\n\n\noffice_episodes <- theoffice %>%\n  group_by(___) %>%\n  summarize(\n    n_lines = n(),\n    lines_jim = sum(character == \"___\") / n_lines,\n    lines_pam = ___,\n    lines_michael = ___,\n    lines_dwight = ___,\n    halloween = if_else(sum(___) >= 1, \"yes\", \"no\"),\n    valentine = if_else(___, \"___\", \"___\"),\n    christmas = if_else(___, \"___\", \"___\"),\n    .groups = \"drop\"\n  ) %>%\n  select(-n_lines)\n\n\n\n\n\n\n\nNote\n\n\n\nWhy summarize() and not mutate()? We use mutate() to add / modify a column of a data frame. The output data frame always has the same number of rows as the input data frame. On the other hand, we use summarize() to reduce the data frame to either a single row (single summary statistic) or one row per each group (summary statistics at the group level).\nAnd what about that .groups argument in summarize? Try running your summarize() step without it first. You‚Äôll see that R print out a message saying ‚Äúsummarize() has grouped output by season, episode. You can override using the .groups argument.‚Äù summarize() will only drop the last group. So if you want a data frame that doesn‚Äôt have a grouping structure as a result of a summaerize(), you can explicitly ask for that with .groups = \"drop\". Before you proceed, read the documentation for summarize(), and specifically the explanation for the .groups argument to prepare yourself for future instances where you might see this type of message.\n\n\n\n\nExercise 3\nThe Michael Scott character (played by Steve Carrell) left the show at the end of Season 7. Add an indicator variable, michael, that takes on the value \"yes\" if Michael Scott (Steve Carrell) was in the show, and \"no\" if not.\n\noffice_episodes <- office_episodes %>%\n  mutate(michael = if_else(season > ___, \"___\", \"___\"))\n\n\n\nExercise 4\nPrint out the dimensions (dim()) of the new dataset you created as well as the names() of the columns in the dataset.\nYour new dataset, office_episodes, should have 186 rows and 14 columns. The column names should be season, episode, episode_name, imdb_rating, total_votes, air_date, lines_jim, lines_pam, lines_michael, lines_dwight, halloween, valentine, christmas, and michael. If you are not matching these numbers or columns, go back and try to figure out where you went wrong. Or ask your TA for help!\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\nIt‚Äôs also a good place to let another team member take over the keyboard! A team member who hasn‚Äôt done so yet should pull the changes and make the commits for the next few exercises.\n\n\n\n\nExploratory data analysis\nThis would be a good place to conduct some exploratory data analysis (EDA). For example, plot the proportion of lines spoken by each character over time. Or calculate the percentage of episodes that mention Halloween, or Valentine‚Äôs Day, or Christmas. Given we have limited time in the lab we‚Äôre not going to ask you to report EDA results as part of this lab, but we‚Äôre noting this here to provide suggestions for how you might go about structuring your project.\n\n\nModeling prep\n\nExercise 5\nSplit the data into training (75%) and testing (25%). Save the training and testing data as office_train and office_test respectively.\nNaming suggestion: Call the initial split office_split, the training data office_train, and testing data office_test.\n\nset.seed(123)\noffice_split <- ___(office_episodes)\noffice_train <- ___(office_split)\noffice_test <- ___(___)\n\n\n\nExercise 6\nSpecify a linear regression model with engine \"lm\" and call it office_spec.\nNaming suggestion: Call the model specification office_spec.\n\noffice_spec <- ___\n\n\n\nExercise 7\nCreate a recipe that performs feature engineering using the following steps (in the given order):\n\nupdate_role(): updates the role of episode_name to not be a predictor (be an ID)\nstep_rm(): removes air_date as a predictor\nstep_dummy(): creates dummy variables for all_nominal_predictors()\nstep_zv(): removes all zero variance predictors\n\nNaming suggestion: Call the recipe office_rec.\n\noffice_rec <- recipe(imdb_rating ~ ., data = office_train) %>%\n  ___\n\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\nIt‚Äôs also a good place to let another team member take over the keyboard! A team member who hasn‚Äôt done so yet should pull the changes and make the commits for the next few exercises.\n\n\n\nExercise 8\nBuild a model workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\nNaming suggestion: Call the model workflow office_wflow.\n\noffice_wflow <- workflow() %>%\n  add_model(___) %>%\n  add_recipe(___)\n\n\n\n\nModel fit and evaluation\n\nExercise 9\nFit the model to training data, neatly display the model output, and interpret two of the slope coefficients.\nNaming suggestion: Call the model fit office_fit.\n\noffice_fit <- office_wflow %>%\n  fit(data = ___)\n\n___\n\n\n\nExercise 10\nCalculate predicted imdb_rating for the training data using the predict() function. Then, bind two columns from the training data to this result: imdb_rating and episode_name. The resulting data frame should have three columns: .pred, imdb_rating, and episode_name. Then, using this data frame, create a scatterplot of predicted and observed IMDB ratings for the training data.\nNaming suggestion: Call the resulting data frame office_train_pred.\nStretch goal. Add episode names, using geom_text(), for episodes with much higher and much lower observed IMDB ratings compared to others.\n\n\nExercise 11\nCalculate the R-squared and RMSE for this model for predictions on the training data.\n\nThis is a good place to render, commit, and push changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you‚Äôve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty.\nIt‚Äôs also a good place to let another team member take over the keyboard! A team member who hasn‚Äôt done so yet should pull the changes and make the commits for the next few exercises.\n\n\n\nExercise 12\nRepeat Exercise 10, but with testing data.\nNaming suggestion: Call the resulting data frame office_test_pred.\n\n\nExercise 13\nBased on your visualization on Exercise 12, speculate on whether you expect the R-squared and RMSE for this model to be higher or lower for predictions on the testing data compared to those on the training data, or do you expect them to be the same? Explain your reasoning.\n\n\nExercise 14\nCheck your intuition in Exercise 13 by actually calculating the R-squared and RMSE for this model for predictions on the training data. Comment on whether your intuition is confirmed or not."
  },
  {
    "objectID": "labs/lab-4x.html#submission",
    "href": "labs/lab-4x.html#submission",
    "title": "Lab 4 - The Office",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "labs/lab-4x.html#grading",
    "href": "labs/lab-4x.html#grading",
    "title": "Lab 4 - The Office",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51"
  },
  {
    "objectID": "labs/lab-5x.html",
    "href": "labs/lab-5x.html",
    "title": "Lab 5 - General Social Survey",
    "section": "",
    "text": "In today‚Äôs lab you will analyze data from the General Social Survey.\n\n\nBy the end of the lab you will be able to‚Ä¶\n\nUse logistic regression to explore the relationship between a binary response variable and multiple predictor variables\nConduct exploratory data analysis for logistic regression\nInterpret coefficients of logistic regression model"
  },
  {
    "objectID": "labs/lab-5x.html#getting-started",
    "href": "labs/lab-5x.html#getting-started",
    "title": "Lab 5 - General Social Survey",
    "section": "Getting started",
    "text": "Getting started\n\nA repository has already been created for you and your teammates. Everyone in your team has access to the same repo.\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-5. It contains the starter documents you need to complete the lab.\nEach person on the team should clone the repository and open a new project in RStudio. Throughout the lab, each person should get a chance to make commits and push to the repo."
  },
  {
    "objectID": "labs/lab-5x.html#packages",
    "href": "labs/lab-5x.html#packages",
    "title": "Lab 5 - General Social Survey",
    "section": "Packages",
    "text": "Packages\nThe following packages are used in the lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "labs/lab-5x.html#data-general-social-survey",
    "href": "labs/lab-5x.html#data-general-social-survey",
    "title": "Lab 5 - General Social Survey",
    "section": "Data: General Social Survey",
    "text": "Data: General Social Survey\nThe General Social Survey (GSS) has been used to measure trends in attitudes and behaviors in American society since 1972. In addition to collecting demographic information, the survey includes questions used to gauge attitudes about government spending priorities, confidence in institutions, lifestyle, and many other topics. A full description of the survey may be found here.\nThe data for this lab are from the 2016 General Social Survey. The original data set contains 2867 observations and 935 variables. We will use and abbreviated data set that includes the following variables:\n\nnatmass: Respondent‚Äôs answer to the following prompt:\n‚ÄúWe are faced with many problems in this country, none of which can be solved easily or inexpensively. I‚Äôm going to name some of these problems, and for each one I‚Äôd like you to tell me whether you think we‚Äôre spending too much money on it, too little money, or about the right amount‚Ä¶are we spending too much, too little, or about the right amount on mass transportation?‚Äù\nage: Age in years.\nsex: Sex recorded as male or female\nsei10: Socioeconomic index from 0 to 100\nregion: Region where interview took place\npolviews: Respondent‚Äôs answer to the following prompt:\n‚ÄúWe hear a lot of talk these days about liberals and conservatives. I‚Äôm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal - point 1 - to extremely conservative - point 7. Where would you place yourself on this scale?‚Äù\n\nThe data are in gss2016.csv in the data folder."
  },
  {
    "objectID": "labs/lab-5x.html#exercises",
    "href": "labs/lab-5x.html#exercises",
    "title": "Lab 5 - General Social Survey",
    "section": "Exercises",
    "text": "Exercises\nThe goal of today‚Äôs lab is to use the GSS to examine the relationship between US adults‚Äô political views and attitudes towards government spending on mass transportation projects.\n\nPart I: Exploratory data analysis\n\nLet‚Äôs begin by making a binary variable for respondents‚Äô views on spending on mass transportation. Create a new variable that is equal to ‚Äú1‚Äù if a respondent said spending on mass transportation is about right and ‚Äú0‚Äù otherwise. Then make a plot of the new variable, using informative labels for each category.\nRecode polviews so it is a factor with levels that are in an order that is consistent with question on the survey. Note how the categories are spelled in the data.\n\nMake a plot of the distribution of polviews.\nWhich political view occurs most frequently in this data set?\n\nMake a plot displaying the relationship between satisfaction with mass transportation spending and political views. Use the plot to describe the relationship the two variables.\nWe‚Äôd like to use age as a quantitative variable in your model; however, it is currently a character data type because some observations are coded as \"89 or older\".\n\nRecode age so that is a numeric variable. Note: Before making the variable numeric, you will need to replace the values \"89 or older\" with a single value.\nThen plot the distribution of age.\n\n\n\n\nPart II: Logistic regression model\n\nBriefly explain why we should use a logistic regression model to predict the odds a randomly selected person is satisfied with spending on mass transportation.\nLet‚Äôs start by fitting a model using the demographic factors - age, sex, sei10, and region - to predict the odds a person is satisfied with spending on mass transportation. Make any necessary adjustments to the variables so the intercept will have a meaningful interpretation. Neatly display the model.\nInterpret the intercept in the context of the data.\nConsider the relationship between age and one‚Äôs opinion about spending on mass transportation. Interpret the coefficient of age in terms of the odds of being satisfied with spending on mass transportation."
  },
  {
    "objectID": "labs/lab-5x.html#submission",
    "href": "labs/lab-5x.html#submission",
    "title": "Lab 5 - General Social Survey",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "labs/lab-5x.html#grading",
    "href": "labs/lab-5x.html#grading",
    "title": "Lab 5 - General Social Survey",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51"
  },
  {
    "objectID": "labs/lab-6x.html",
    "href": "labs/lab-6x.html",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "",
    "text": "In today‚Äôs lab you will analyze data from an online Ipsos survey that was conducted for the FiveThirtyEight article ‚ÄúWhy Many Americans Don‚Äôt Vote‚Äù.\n\n\nBy the end of the lab you will be able to‚Ä¶\n\nConduct exploratory data analysis for multinomial logistic regression.\nFit and interpret coefficients of the multinomial logistic regression model.\nUse the multinomial logistic regression model for prediction."
  },
  {
    "objectID": "labs/lab-6x.html#getting-started",
    "href": "labs/lab-6x.html#getting-started",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Getting started",
    "text": "Getting started\n\nA repository has already been created for you and your teammates. Everyone in your team has access to the same repo.\nGo to the sta210-s22 organization on GitHub. Click on the repo with the prefix lab-6. It contains the starter documents you need to complete the lab.\nEach person on the team should clone the repository and open a new project in RStudio. Throughout the lab, each person should get a chance to make commits and push to the repo."
  },
  {
    "objectID": "labs/lab-6x.html#packages",
    "href": "labs/lab-6x.html#packages",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Packages",
    "text": "Packages\nThe following packages are used in the lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "labs/lab-6x.html#data-five-thirty-eight",
    "href": "labs/lab-6x.html#data-five-thirty-eight",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Data: Five Thirty Eight",
    "text": "Data: Five Thirty Eight\nThe data for this assignment comes from an online Ipsos survey that was conducted for the FiveThirtyEight article ‚ÄúWhy Many Americans Don‚Äôt Vote‚Äù. You can read more about the survey design and respondents in the README of the GitHub repo for the data.\nRespondents were asked a variety of questions about their political beliefs, thoughts on multiple issues, and voting behavior. We will focus on using the demographic variables and someone‚Äôs party identification to understand whether a person is a probable voter.\nThe variables we‚Äôll focus on are (definitions from the codebook in data set GitHub repo):\n\nppage: Age of respondent\neduc: Highest educational attainment category.\nrace: Race of respondent, census categories. Note: all categories except Hispanic are non-Hispanic.\ngender: Gender of respondent\nincome_cat: Household income category of respondent\nQ30: Response to the question ‚ÄúGenerally speaking, do you think of yourself as a‚Ä¶‚Äù\n\n1: Republican\n2: Democrat\n3: Independent\n4: Another party, please specify\n5: No preference\n-1: No response\n\nvoter_category: past voting behavior:\n\nalways: respondent voted in all or all-but-one of the elections they were eligible in\nsporadic: respondent voted in at least two, but fewer than all-but-one of the elections they were eligible in\nrarely/never: respondent voted in 0 or 1 of the elections they were eligible in\n\n\nYou can read in the data directly from the GitHub repo:\n\nvoters <- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/non-voters/nonvoters_data.csv\")\n\nNote that the authors use weighting to make the final sample more representative on the US population for their article. We will not use weighting in this assignment, so we should treat the sample as a convenience sample rather than a random sample of the population."
  },
  {
    "objectID": "labs/lab-6x.html#exercises",
    "href": "labs/lab-6x.html#exercises",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Exercises",
    "text": "Exercises\n\nWhy do you think the authors chose to only include data from people who were eligible to vote for at least four election cycles?\nLet‚Äôs prepare the data for analysis and modeling.\n\nThe variable Q30 contains the respondent‚Äôs political party identification. Make a new variable that simplifies Q30 into four categories: ‚ÄúDemocrat‚Äù, ‚ÄúRepublican‚Äù, ‚ÄúIndependent‚Äù, ‚ÄúOther‚Äù (‚ÄúOther‚Äù also includes respondents who did not answer the question).\nThe variable voter_category identifies the respondent‚Äôs past voter behavior. Relevel the variable to make rarely/never the baseline level, followed by sporadic, then always.\n\nIn the FiveThirtyEight article, the authors include visualizations of the relationship between the voter category and demographic variables such as race, age, education, etc. Select two demographic variables. For each variable, interpret the plot to describe its relationship with voter category.\nFit a model using mean-centered age, race, gender, income, and education to predict voter category. Show the code used to fit the model, but do not display the model output.\n\nNext, we want to determine whether party identification be added to the model. In order to do this we need to compare two nested models.\n\nThe reduced model is the one we fit so far, including the predictors mean-centered age, race, gender, income, and education.\nThe full model is the one that includes, in addition to these predictors, party identification.\n\n\nShould party identification be added to the model? Use a drop-in-deviance test to determine if party identification should be added to the model. Include the hypotheses in mathematical notation, the output from the test, and the conclusion in the context of the data. Then, neatly display the model you selected.\n\nUse the model you select for the remainder of the assignment.\n\nInterpret the following coefficients in the context of the data in terms of the odds of voting sporadically versus rarely/never.\n\nInterpret the intercept in the context of the data. Use actual values in the interpretation.\nInterpret the effect of age in the context of the data.\nInterpret the effect of party ID in the context of the data. Include discussion about which level(s) differ from the baseline.\n\nIn the article, the authors write\n\n‚ÄúNonvoters were more likely to have lower incomes; to be young; to have lower levels of education; and to say they don‚Äôt belong to either political party, which are all traits that square with what we know about people less likely to engage with the political system.‚Äù\n\nDoes your model support this statement? Briefly explain why or why not.\nLet‚Äôs use the model to predict the voting categories. Obtain the predicted voter category for each observation.\n\nCreate a table of the actual versus predicted voter categories and a visualization of the association between the two.\nHow well did the model perform? Briefly assess the model performance using 2 - 3 observations from the table and/or visualization to support your response."
  },
  {
    "objectID": "labs/lab-6x.html#submission",
    "href": "labs/lab-6x.html#submission",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember ‚Äì you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ‚û°Ô∏è Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\nSelect the first page of your PDF submission to be associated with the ‚ÄúWorkflow & formatting‚Äù section."
  },
  {
    "objectID": "labs/lab-6x.html#grading",
    "href": "labs/lab-6x.html#grading",
    "title": "Lab 6 - Why Many Americans Don‚Äôt Vote",
    "section": "Grading",
    "text": "Grading\nTotal points available: 50 points.\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1 - 10\n45\n\n\nWorkflow & formatting\n51"
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "STA 101L - Summer I 2022",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (‚ÄúPublic License‚Äù). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 ‚Äì Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter‚Äôs License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 ‚Äì Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor ‚Äì Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor ‚Äì Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter‚Äôs License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 ‚Äì License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter‚Äôs License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter‚Äôs License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter‚Äôs License You apply.\n\n\n\nSection 4 ‚Äì Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 ‚Äì Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 ‚Äì Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 ‚Äì Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 ‚Äì Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the ‚ÄúLicensor.‚Äù The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark ‚ÄúCreative Commons‚Äù or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group‚Äôs interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (with the exception of the presentation).\n\nLogistics\nYou will work on the project with your lab groups.\nThe four primary deliverables for the final project are\n\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides + a video presentation\nFormal peer review on another team‚Äôs project"
  },
  {
    "objectID": "project-description.html#topic-ideas",
    "href": "project-description.html#topic-ideas",
    "title": "Project description",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 data sets you‚Äôre interested in potentially using for the final project. If you‚Äôre unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. It may also help to think of topics you‚Äôre interested in investigating and find data sets on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by the teaching team.\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns\nAt least 6 of the columns must be useful and unique predictor variables.\n\nIdentifier variables such as ‚Äúname‚Äù, ‚Äúsocial security number‚Äù, etc. are not useful predictor variables.\nIf you have multiple columns with the same information (e.g.¬†‚Äústate abbreviation‚Äù and ‚Äústate name‚Äù), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you‚Äôre unsure whether your data set meets the criteria.\nFor each data set, include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data)\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you‚Äôre interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set\n\nSubmit the PDF of the topic ideas to Gradescope. Mark all pages associated with each data set."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is to help you think about your analysis strategy early.\nInclude the following in the proposal:\n\nSection 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you‚Äôre investigating\nthe motivation for your research question (citing any relevant literature)\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\nSection 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\nSection 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\nRegression model technique (multiple linear regression and logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of your project repo, in the data folder. Link to this file from your proposal writeup.\n\n\nSubmission\nPush all of your final changes to the GitHub repo, and submit the PDF of your proposal to Gradescope.\n\n\nProposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction\n3 pts\n\n\nData description\n2 pts\n\n\nAnalysis plan\n4 pts\n\n\nData dictionary\n1 pts\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting."
  },
  {
    "objectID": "project-description.html#draft-report",
    "href": "project-description.html#draft-report",
    "title": "Project description",
    "section": "Draft report",
    "text": "Draft report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model."
  },
  {
    "objectID": "project-description.html#peer-review",
    "href": "project-description.html#peer-review",
    "title": "Project description",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others‚Äô work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams‚Äôs projects to review. Each team should push their draft to their GitHub repo by the due date. One lab in the following week will be dedicated to the peer review, and all reviews will be due by the end of that lab session.\nDuring the peer review process, you will be provided read-only access to your partner teams‚Äô GitHub repos. Provide your review in the form of GitHub issues to your partner team‚Äôs GitHub repo using the issue template provided. The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team‚Äôs report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\n\nPairings\n\nSection 1 - M 1:45PM - 3:00PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\nchaa_chaa_chaa\nyay_stats\nstat_over_flow\n\n\ndekk\nchaa_chaa_chaa\nyay_stats\n\n\neight\ndekk\nchaa_chaa_chaa\n\n\nhousecats\neight\ndekk\n\n\nkrafthouse\nhousecats\neight\n\n\nrrawr\nkrafthouse\nhousecats\n\n\nstat_over_flow\nrrawr\nkrafthouse\n\n\nyay_stats\nstat_over_flow\nrrawr\n\n\n\n\n\nSection 2 - M 3:30PM - 4:45PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\na_plus_plus_plus\nwe_r\ntina\n\n\npredictors\na_plus_plus_plus\nwe_r\n\n\nsixers\npredictors\na_plus_plus_plus\n\n\nsoy_nuggets\nsixers\npredictors\n\n\ntina\nsoy_nuggets\nsixers\n\n\nwe_r\ntina\nsoy_nuggets\n\n\n\n\n\nSection 3 - M 5:15PM - 6:30PM\n\n\n\n\n\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\ndown_to_earth_goats\nthe_three_musketeers\nteam_five\n\n\nginger_and_stats\ndown_to_earth_goats\nthe_three_musketeers\n\n\npineapple_wedge_and_diced_papaya\nginger_and_stats\ndown_to_earth_goats\n\n\nstatchelorettes\npineapple_wedge_and_diced_papaya\nginger_and_stats\n\n\nstatisix\nstatchelorettes\npineapple_wedge_and_diced_papaya\n\n\nstats_squad\nstatisix\nstatchelorettes\n\n\nteam_five\nstats_squad\nstatisix\n\n\nthe_three_musketeers\nteam_five\nstats_squad\n\n\n\n\n\n\nProcess and questions\nSpend ~30 mins to review each team‚Äôs project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team‚Äôs repo.\nOpen the repo of the team you‚Äôre reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project-description.html#written-report",
    "href": "project-description.html#written-report",
    "title": "Project description",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo = FALSE.\nYou will submit the PDF of your final report on Gradescope.\nThe PDF you submit must match the files in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long. is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion + conclusion\n6 pts\n\n\nOrganization + formatting\n4 pts\n\n\n\nClick here for a PDF of the written report rubric.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model‚Äôs predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you‚Äôll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description.html#video-presentation-slides",
    "href": "project-description.html#video-presentation-slides",
    "title": "Project description",
    "section": "Video presentation + slides",
    "text": "Video presentation + slides\n\nSlides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nFor submission, convert these slides to a .pdf document, and submit the PDF of the slides on Gradescope.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nVideo presentation\nFor the video presentation, you can speak over your slide deck, similar to the lecture content videos. The video presentation must be no longer than 8 minutes. It is fine if the video is shorter than 8 minutes, but it cannot exceed 8 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Conversations.\n\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the ‚Äú+‚Äù and select ‚ÄúUpload files‚Äù.\nLocate the video on your computer and click to upload.\nOnce you‚Äôve uploaded the video to Warpwire, click to share the video and copy the video‚Äôs URL. You will need this when you post the video in the discussion forum.\n\n\n\nTo post the video to the discussion forum\n\nClick the Presentations tab in the course Sakai site.\nClick the Presentations topic.\nClick ‚ÄúStart a new conversation‚Äù.\nMake the title ‚ÄúYour Team Name: Project Title‚Äù. For example, ‚ÄúTeaching Team: Our Awesome Presentation‚Äù.\nClick the Warpwire icon (between the table and shopping cart icons).\nSelect your video, then click ‚ÄúInsert 1 item.‚Äù This will embed your video in the conversation.\nUnder the video, paste the URL to your video.\nYou‚Äôre done!"
  },
  {
    "objectID": "project-description.html#presentation-comments",
    "href": "project-description.html#presentation-comments",
    "title": "Project description",
    "section": "Presentation comments",
    "text": "Presentation comments\nEach student will be assigned 2 presentations to watch. Your viewing assignments will be posted later in the semester.\nWatch the group‚Äôs video, then click ‚ÄúReply‚Äù to post a question for the group. You may not post a question that‚Äôs already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e.¬†it shouldn‚Äôt be ‚ÄúWhy did you use a bar plot instead of a pie chart‚Äù?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group‚Äôs specific presentation, i.e demonstrating that you‚Äôve watched the presentation.\nThis portion of the project will be assessed individually.\n\nPairings\nFind your team name in the first column, watch videos from teams in the second column and leave comments.\n\n\n\n\n\n\n\n\nReviewer\nFirst video to review\nSecond video to review\n\n\n\n\nGinger and Stats\nEight\nWe R\n\n\nKrafthouse\nGinger and Stats\nEight\n\n\nSoy Nuggets\nKrafthouse\nGinger and Stats\n\n\nDown To Earth Goats\nSoy Nuggets\nKrafthouse\n\n\nA+++\nDown To Earth Goats\nSoy Nuggets\n\n\nTeam Five\nA+++\nDown To Earth Goats\n\n\nRrawr\nTeam Five\nA+++\n\n\nHousecats\nRrawr\nTeam Five\n\n\nDekk\nHousecats\nRrawr\n\n\nStat OverFlow\nDekk\nHousecats\n\n\nThe Three Musketeers\nStat OverFlow\nDekk\n\n\nPredictors\nThe Three Musketeers\nStat OverFlow\n\n\nStats Squad\nPredictors\nThe Three Musketeers\n\n\nStatisix\nStats Squad\nPredictors\n\n\nSixers\nStatisix\nStats Squad\n\n\nYay Stats\nSixers\nStatisix\n\n\nTINA\nYay Stats\nSixers\n\n\nStatchelorettes\nTINA\nYay Stats\n\n\nPineapple Wedge and Diced Papaya\nStatchelorettes\nTINA\n\n\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\nStatchelorettes\n\n\nWe R\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\n\n\nEight\nWe R\nChaa Chaa Chaa"
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description.html#peer-teamwork-evaluation",
    "href": "project-description.html#peer-teamwork-evaluation",
    "title": "Project description",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project video deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description.html#overall-grading",
    "href": "project-description.html#overall-grading",
    "title": "Project description",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n10 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\nVideo comments\n5 pts\n\n\nPeer teamwork evaluation\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-inference.html",
    "href": "project-inference.html",
    "title": "Inference project",
    "section": "",
    "text": "Details about the inference project will be provided during week 4."
  },
  {
    "objectID": "project-prediction.html",
    "href": "project-prediction.html",
    "title": "Prediction project",
    "section": "",
    "text": "In this prediction project, you will work in pairs to construct a regression model that will be used to make predictions. The prediction model is due on Tuesday, May 31, at 9:00 am, and the final report is due Wednesday, June 1 at 9:00pm.\nüçÄ Good luck! üçÄ"
  },
  {
    "objectID": "project-prediction.html#introduction",
    "href": "project-prediction.html#introduction",
    "title": "Prediction project",
    "section": "Introduction",
    "text": "Introduction\nThe goal of the prediction project is for you to use regression analysis to construct a linear regression model with good prediction accuracy, demonstrating proficiency in the techniques we have covered in class so far and applying them to a real data set in a meaningful way.\nAll analyses must be done in RMarkdown, and all components of the project must be reproducible (with the exception of the presentation)."
  },
  {
    "objectID": "project-prediction.html#academic-integrity",
    "href": "project-prediction.html#academic-integrity",
    "title": "Prediction project",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nBy participating in this project, you pledge to uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "project-prediction.html#data",
    "href": "project-prediction.html#data",
    "title": "Prediction project",
    "section": "Data",
    "text": "Data\nWe will work with the natality data for the U.S. in 2020. The response variable that we are interested in is newborn‚Äôs weight. This variable is important to medical professionals since a newborn with a low birth weight is more likely to require additional care. You have access to a random sample of 1,000 observations to construct your prediction model. I have kept a separate set of 20,000 observations to evaluate the prediction model that you select.\nHere is a detailed overview of the variable\n\nnewborn_birth_weight: newborn birth weight in grams (response)\nmonth: birth month (1 = January, ‚Ä¶, 12 = December)\nmother_age: age of the mother in years\n\nprenatal_care_starting_month: month in which prenatal care began; if 0, there was no prenatal care\n\ndaily_cigarette_prepregnancy: daily number of cigarettes smoked before the pregnancy\ndaily_cigarette_trimester_1: daily number of cigarettes smoked during the 1st trimester of the pregnancy\ndaily_cigarette_trimester_2: daily number of cigarettes smoked during the 2nd trimester of the pregnancy\ndaily_cigarette_trimester_3: daily number of cigarettes smoked during the 3rd trimester of the pregnancy\nmother_height: height of the mother in inches\nmother_bmi: body mass index of the mother\nmother_weight_prepregnancy: weight of the mother before the pregnancy in pounds\nmother_weight_delivery: weight of the mother at delivery in pounds\nmother_diabetes_gestational: whether the mother had diabetes during the pregnancy\nnewborn_sex: sex of the newborn\ngestation_week: number of gestational weeks\nmother_risk_factors: whether the mother had any risk factor (diabetes, hypertension, previous preterm birth, previous cesarean, infertility treatment used, etc)"
  },
  {
    "objectID": "project-prediction.html#submission",
    "href": "project-prediction.html#submission",
    "title": "Prediction project",
    "section": "Submission",
    "text": "Submission\nThe three primary deliverables for this project are:\n\nPrediction model: you need to submit a RDATA file that contains your prediction model. The prediction model must consist in a function that takes a test set (a dataframe with the same predictors as the training set, but no response variable) as an input and returns a prediction for each observation of the test set. The RDATA file should not contain anything else.\nInformal presentation: you will present your work orally to rest of the class. The presentation should be no longer than 5 minutes (aim for 2-6 slides). It is fine if the presentation is shorter than 5 minutes, but it cannot exceed 5 minutes. The two team members should speak roughly the same amount of time. Each presentation will be followed by a short QA session.\nFinal report: The final report details your work. It needs to be realized using RMarkdown and submitted on Gradescope as a PDF. The RMD file also needs to be sent via email to the instruction team (reproducibility). The page limit is 6 pages (including code chunks, but excluding the appendix). Figures should go in the appendix, along with any work that you wish to include. Grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report."
  },
  {
    "objectID": "project-prediction.html#final-report-content",
    "href": "project-prediction.html#final-report-content",
    "title": "Prediction project",
    "section": "Final report content",
    "text": "Final report content\nThe final report should include the following sections, though you should feel free to include additional sections as necessary.\n\nShort introduction: briefly mention the variables you have considered, those you have engineered, and the approach you have chosen for model selection.\nVariable selection and engineering: list the variables that you have chosen to consider; briefly explain your reasoning; describe new variables that you have engineered; visualize every variable that you create.\nOutliers: if there were outliers, explain how you treated them.\nModel fitting: you need to fit at least 5 models:\n\na simple linear regression model with gestation_week as the predictor\nthe full model with all 15 raw predictors\nat least 3 other models containing new variables that you have created\n\nModel selection: select the model that you will submit using\n\na model selection criterion,\nthe holdout method, and\ncross-validation\n\nDiscussion/conclusion: briefly discuss your result, any limitation to your work, and what predictor(s) you have liked to have in the dataset (e.g.¬†weight of father) to make the prediction model more accurate."
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you‚Äôre welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that‚Äôs fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called ‚ÄúReferences‚Äù at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called ‚ÄúAppendix‚Äù.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you‚Äôre using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n‚ùå NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n‚úÖ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %>%\n  count(manufacturer) %>%\n  mutate(manufacturer = str_to_title(manufacturer)) %>%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel <- lm(mpg ~ hp, data = mtcars)\ntidy(model) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon‚Äôt use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n‚ùå There is a negative linear relationship between mpg and hp.\n‚úÖ There is a negative linear relationship between a car‚Äôs fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don‚Äôt assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the ‚Äúso what‚Äù: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e.¬†what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n‚ùå For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n‚úÖ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it‚Äôs from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "projects/prediction-data.html",
    "href": "projects/prediction-data.html",
    "title": "Prediction Project - Data Prep",
    "section": "",
    "text": "The data can be found here and the help file here"
  },
  {
    "objectID": "projects/prediction-data.html#raw-data-import",
    "href": "projects/prediction-data.html#raw-data-import",
    "title": "Prediction Project - Data Prep",
    "section": "Raw Data import",
    "text": "Raw Data import\n\nknitr::opts_chunk$set(\n  eval = FALSE\n)\n\n\nset.seed(0)\nlibrary(tidyverse)\n\nd_sub <- read_csv(\n  \"../Nat2020us/Nat2020PublicUS.c20210506.r20210812.txt\",\n  col_names = FALSE, trim_ws = FALSE\n  ) %>%\n  slice_sample(n = 1e5)"
  },
  {
    "objectID": "projects/prediction-data.html#variable-extraction",
    "href": "projects/prediction-data.html#variable-extraction",
    "title": "Prediction Project - Data Prep",
    "section": "Variable extraction",
    "text": "Variable extraction\n\nclean_data <- function(data){\n  \n  data_clean <- data %>%\n    rename(string = X1) %>%\n    mutate(\n      month                            = str_sub(string, 13 , 14 ) %>% as.numeric,\n      mother_age                       = str_sub(string, 75 , 76 ) %>% as.numeric,\n      prenatal_care_starting_month     = str_sub(string, 224, 225) %>% as.numeric,\n      daily_cigarette_prepregnancy     = str_sub(string, 253, 254) %>% as.numeric,\n      daily_cigarette_trimester_1      = str_sub(string, 255, 256) %>% as.numeric,\n      daily_cigarette_trimester_2      = str_sub(string, 257, 258) %>% as.numeric,\n      daily_cigarette_trimester_3      = str_sub(string, 259, 260) %>% as.numeric,\n      mother_height                    = str_sub(string, 280, 281) %>% as.numeric,\n      mother_bmi                       = str_sub(string, 283, 286) %>% as.numeric,\n      mother_weight_prepregnancy       = str_sub(string, 292, 294) %>% as.numeric,\n      mother_weight_delivery           = str_sub(string, 299, 301) %>% as.numeric,\n      mother_diabetes_prepregnancy     = str_sub(string, 313, 313),\n      mother_diabetes_gestational      = str_sub(string, 314, 314),\n      mother_hypertension_prepregnancy = str_sub(string, 315, 315),\n      mother_hypertension_gestational  = str_sub(string, 316, 316),\n      mother_no_risk_factor            = str_sub(string, 337, 337) %>% as.numeric,\n      mother_gonorrhea                 = str_sub(string, 343, 343),\n      mother_syphilis                  = str_sub(string, 344, 344),\n      mother_chlamydia                 = str_sub(string, 345, 345),\n      mother_hepatitis_B               = str_sub(string, 346, 346),\n      mother_hepatitis_C               = str_sub(string, 347, 347),\n      number_newborns                  = str_sub(string, 454, 454) %>% as.numeric,\n      newborn_sex                      = str_sub(string, 475, 475),\n      gestation_week                   = str_sub(string, 490, 491) %>% as.numeric,\n      newborn_birth_weight             = str_sub(string, 504, 507) %>% as.numeric\n      ) %>%\n    filter(\n      gestation_week               <  99  ,\n      number_newborns              == 1   ,\n      mother_no_risk_factor        <= 1   ,\n      mother_weight_delivery       <  999 ,\n      mother_weight_prepregnancy   <  999 ,\n      mother_bmi                   <  99  ,\n      mother_height                <  99  ,\n      daily_cigarette_trimester_3  <  98  ,\n      daily_cigarette_trimester_2  <  98  ,\n      daily_cigarette_trimester_1  <  98  ,\n      daily_cigarette_prepregnancy <  98  ,\n      prenatal_care_starting_month <  99  ,\n      newborn_birth_weight         <  9999,\n      mother_diabetes_prepregnancy == \"N\",\n      mother_hypertension_gestational == \"N\",\n      mother_gonorrhea == \"N\",\n      mother_syphilis == \"N\",\n      mother_chlamydia == \"N\",\n      mother_hepatitis_B == \"N\",\n      mother_hepatitis_C == \"N\"\n      ) %>%\n  mutate(mother_risk_factor = !mother_no_risk_factor) %>%\n    select(\n      - string, - number_newborns,\n      - mother_diabetes_prepregnancy, - mother_hypertension_gestational, - mother_hypertension_prepregnancy, - mother_gonorrhea, - mother_syphilis, - mother_chlamydia, - mother_hepatitis_B, - mother_hepatitis_C, - mother_no_risk_factor\n      ) %>%\n    select(\n      newborn_birth_weight, everything()\n    )\n      \n  return(data_clean)\n  \n}\n\n\nd_sub_clean <- clean_data(d_sub)\n\nd_train <- slice(d_sub_clean, 1     : 1e3)\nd_test  <- slice(d_sub_clean, 1e4+1 : 2e4)\n\nwrite_csv(d_train, \"projects/training_set.csv\")\n#write_csv(d_test , \"projects/test_set.csv\"    )"
  },
  {
    "objectID": "projects/prediction-data.html#checking-subset",
    "href": "projects/prediction-data.html#checking-subset",
    "title": "Prediction Project - Data Prep",
    "section": "Checking subset",
    "text": "Checking subset\n\nd_num <- d_sub_clean %>% select_if(is.numeric)\nfor(i in 1 : ncol(d_num)){\n  hist(d_num[[i]], breaks = 30, xlab = names(d_num)[i], main = i)\n}\n\nd_cha <- d_sub_clean %>% select_if(is.character)\nfor(i in 1 : ncol(d_cha)){\n  print(names(d_cha)[i])\n  print(table(d_cha[[i]]))\n}\n\n\nm_simple <- lm(newborn_birth_weight ~ gestation_week, data = d_train)\nsummary(m_simple)\nm_full <- lm(newborn_birth_weight ~ ., data = d_train)\nsummary(m_full)\ny     <- d_test$newborn_birth_weight\nRMST <- sqrt(mean((y - mean(y))^2))\ny_hat <- predict.lm(m_full, d_test)\nsqrt(mean((y - y_hat  )^2))\ny_hat <- predict.lm(m_simple, d_test)\nsqrt(mean((y - y_hat  )^2))"
  },
  {
    "objectID": "slides/applications.html#outline",
    "href": "slides/applications.html#outline",
    "title": "Data science in action ‚Äì examples in various fields",
    "section": "Outline",
    "text": "Outline\n\n7 billion ‚Äì are you typical?\n200 years of history through health and wealth\nBuilding a better NBA team through data science\nWhen data seem to contradict widely held believes\nStatistics in psychiatry and agriculture\n10 steps to get started in sport analytics"
  },
  {
    "objectID": "slides/applications.html#billion-are-you-typical",
    "href": "slides/applications.html#billion-are-you-typical",
    "title": "Data science in action ‚Äì examples in various fields",
    "section": "7 billion ‚Äì are you typical?",
    "text": "7 billion ‚Äì are you typical?\nThis short video by National Geographic illustrates the various ways in which demographic variables can be summarized."
  },
  {
    "objectID": "slides/applications.html#years-of-history-through-health-and-wealth",
    "href": "slides/applications.html#years-of-history-through-health-and-wealth",
    "title": "Data science in action ‚Äì examples in various fields",
    "section": "200 years of history through health and wealth",
    "text": "200 years of history through health and wealth\n\n\nThis short video and this Ted talk show the work of the public health scientist Hans Rosling who uses data visualization with great skills to tell a story.\nCan you identify all 5 variables that were necessary to make the animation in the short video? Visit the Gapminder website to explore other variables."
  },
  {
    "objectID": "slides/applications.html#building-a-better-nba-team-through-data-science",
    "href": "slides/applications.html#building-a-better-nba-team-through-data-science",
    "title": "Data science in action ‚Äì examples in various fields",
    "section": "Building a better NBA team through data science",
    "text": "Building a better NBA team through data science\n\n\nLearn about Dr.¬†Ivana Seric‚Äôs work for the Philadelphia 76ers in this short video. She has used her mathematical background and passion for basketball to dive in the data and help the NBA team devise better strategies.\nNot interested in basketball, check this article in which the R blogger Bill K shares 10 tips for any fan of sports to become a sports data analyst."
  },
  {
    "objectID": "slides/applications.html#when-data-seem-to-contradict-widely-held-believes",
    "href": "slides/applications.html#when-data-seem-to-contradict-widely-held-believes",
    "title": "Data science in action ‚Äì examples in various fields",
    "section": "When data seem to contradict widely held believes",
    "text": "When data seem to contradict widely held believes\nIn this Ted talk, Prof.¬†Steven Levitt argues that the data do not seem to corroborate the idea that car seats are no more effective than seat belts in protecting kids from dying in cars."
  },
  {
    "objectID": "slides/applications.html#statistics-in-psychiatry-and-agriculture",
    "href": "slides/applications.html#statistics-in-psychiatry-and-agriculture",
    "title": "Data science in action ‚Äì examples in various fields",
    "section": "Statistics in psychiatry and agriculture",
    "text": "Statistics in psychiatry and agriculture\nHear about the work of the statistician Susan Murphy and agricultural ecologist David Lobell, both recipients of the prestigious MacArthur Fellowship.\nBelieve it or not, agriculture is where statistical methods (experiments, hypothesis tests, etc) were first used during the 1920s."
  },
  {
    "objectID": "slides/applications.html#estimating-the-effect-of-commute-time-on-rent-in-new-york",
    "href": "slides/applications.html#estimating-the-effect-of-commute-time-on-rent-in-new-york",
    "title": "Data science in action ‚Äì examples in various fields",
    "section": "Estimating the effect of commute time on rent in New York",
    "text": "Estimating the effect of commute time on rent in New York\n\n\nIn this article, Carl Bialik looked at more than 100,000 homes present on StreetEasy. He observed that, unsurprisingly, the distance to the nearest metro does impact rent prices, and he even managed to put a number on that effect: $56/minute.\n\n\n\n Source: FiverThirtyEight"
  },
  {
    "objectID": "slides/applications.html#section",
    "href": "slides/applications.html#section",
    "title": "Data science in action ‚Äì examples in various fields",
    "section": "",
    "text": "https://rmorsomme.github.io/website/"
  },
  {
    "objectID": "slides/hw-1-lab-answers.html#setup",
    "href": "slides/hw-1-lab-answers.html#setup",
    "title": "Homework 1 - lab answers",
    "section": "Setup",
    "text": "Setup\nYou can find the lab here.\n\nlibrary(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "slides/hw-1-lab-answers.html#exercise-1-2-points",
    "href": "slides/hw-1-lab-answers.html#exercise-1-2-points",
    "title": "Homework 1 - lab answers",
    "section": "Exercise 1 (2 points)",
    "text": "Exercise 1 (2 points)\n\narbuthnot$girls\n\n [1] 4683 4457 4102 4590 4839 4820 4928 4605 4457 4952 4784 5332 5200 4910 4617\n[16] 3997 3919 3395 3536 3181 2746 2722 2840 2908 2959 3179 3349 3382 3289 3013\n[31] 2781 3247 4107 4803 4881 5681 4858 4319 5322 5560 5829 5719 6061 6120 5822\n[46] 5738 5717 5847 6203 6033 6041 6299 6533 6744 7158 7127 7246 7119 7214 7101\n[61] 7167 7302 7392 7316 7483 6647 6713 7229 7767 7626 7452 7061 7514 7656 7683\n[76] 5738 7779 7417 7687 7623 7380 7288"
  },
  {
    "objectID": "slides/hw-1-lab-answers.html#exercise-2-3-points",
    "href": "slides/hw-1-lab-answers.html#exercise-2-3-points",
    "title": "Homework 1 - lab answers",
    "section": "Exercise 2 (3 points)",
    "text": "Exercise 2 (3 points)\n\narbuthnot %>%\n  ggplot(aes(x = year, y = girls)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\narbuthnot %>%\n  ggplot() +\n  geom_line(aes(x = year, y = girls))"
  },
  {
    "objectID": "slides/hw-1-lab-answers.html#exercise-3-4-points",
    "href": "slides/hw-1-lab-answers.html#exercise-3-4-points",
    "title": "Homework 1 - lab answers",
    "section": "Exercise 3 (4 points)",
    "text": "Exercise 3 (4 points)\n\narbuthnot %>%\n  mutate(prop_boys = boys / (boys + girls)) %>%\n  ggplot() +\n  geom_line(aes(year, prop_boys))"
  },
  {
    "objectID": "slides/hw-1-lab-answers.html#exercise-4-4-points",
    "href": "slides/hw-1-lab-answers.html#exercise-4-4-points",
    "title": "Homework 1 - lab answers",
    "section": "Exercise 4 (4 points)",
    "text": "Exercise 4 (4 points)\n\npresent\n\n# A tibble: 63 x 3\n    year    boys   girls\n   <dbl>   <dbl>   <dbl>\n 1  1940 1211684 1148715\n 2  1941 1289734 1223693\n 3  1942 1444365 1364631\n 4  1943 1508959 1427901\n 5  1944 1435301 1359499\n 6  1945 1404587 1330869\n 7  1946 1691220 1597452\n 8  1947 1899876 1800064\n 9  1948 1813852 1721216\n10  1949 1826352 1733177\n# ... with 53 more rows\n\npresent$year\n\n [1] 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954\n[16] 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969\n[31] 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984\n[46] 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999\n[61] 2000 2001 2002\n\nmin(present$year)\n\n[1] 1940\n\nmax(present$year)\n\n[1] 2002\n\nnrow(present)\n\n[1] 63\n\nncol(present)\n\n[1] 3\n\ndim(present)\n\n[1] 63  3\n\npresent\n\n# A tibble: 63 x 3\n    year    boys   girls\n   <dbl>   <dbl>   <dbl>\n 1  1940 1211684 1148715\n 2  1941 1289734 1223693\n 3  1942 1444365 1364631\n 4  1943 1508959 1427901\n 5  1944 1435301 1359499\n 6  1945 1404587 1330869\n 7  1946 1691220 1597452\n 8  1947 1899876 1800064\n 9  1948 1813852 1721216\n10  1949 1826352 1733177\n# ... with 53 more rows"
  },
  {
    "objectID": "slides/hw-1-lab-answers.html#exercise-5-2-points",
    "href": "slides/hw-1-lab-answers.html#exercise-5-2-points",
    "title": "Homework 1 - lab answers",
    "section": "Exercise 5 (2 points)",
    "text": "Exercise 5 (2 points)\n\n# Insert code for Exercise 5 here"
  },
  {
    "objectID": "slides/hw-1-lab-answers.html#exercise-6-5-points",
    "href": "slides/hw-1-lab-answers.html#exercise-6-5-points",
    "title": "Homework 1 - lab answers",
    "section": "Exercise 6 (5 points)",
    "text": "Exercise 6 (5 points)\n\npresent %>%\n  mutate(prop_boys = boys / (boys + girls)) %>%\n  ggplot() +\n  geom_line(aes(year, prop_boys))"
  },
  {
    "objectID": "slides/hw-1-lab-answers.html#exercise-7-5-points",
    "href": "slides/hw-1-lab-answers.html#exercise-7-5-points",
    "title": "Homework 1 - lab answers",
    "section": "Exercise 7 (5 points)",
    "text": "Exercise 7 (5 points)\n\npresent %>%\n  mutate(total = boys + girls) %>%\n  arrange(desc(total))\n\n# A tibble: 63 x 4\n    year    boys   girls   total\n   <dbl>   <dbl>   <dbl>   <dbl>\n 1  1961 2186274 2082052 4268326\n 2  1960 2179708 2078142 4257850\n 3  1957 2179960 2074824 4254784\n 4  1959 2173638 2071158 4244796\n 5  1958 2152546 2051266 4203812\n 6  1962 2132466 2034896 4167362\n 7  1956 2133588 2029502 4163090\n 8  1990 2129495 2028717 4158212\n 9  1991 2101518 2009389 4110907\n10  1963 2101632 1996388 4098020\n# ... with 53 more rows\n\n\n\n\n\nhttps://rmorsomme.github.io/website/"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-instructor",
    "href": "slides/lec-1.html#meet-the-instructor",
    "title": "Welcome to STA 101L!",
    "section": "Meet the instructor",
    "text": "Meet the instructor\n\n\n\n\n\nDr.¬†Raphael Morsomme (he/him/his)\n\n\n\n\nPh.D.¬†candidate at the Department of Statistical Science\nResearch focus: epidemic models and cancer overdiagnosis\nFan of Formula 1, model building and cooking"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-ta",
    "href": "slides/lec-1.html#meet-the-ta",
    "title": "Welcome to STA 101L!",
    "section": "Meet the TA",
    "text": "Meet the TA\n\n\n\n\n\nRohit Roy (he/him/his)\n\n\n\n\nPh.D.¬†student in biochemistry\nWorks at the Al-Hashimi Lab\nLikes traveling and cooking"
  },
  {
    "objectID": "slides/lec-1.html#meet-each-other",
    "href": "slides/lec-1.html#meet-each-other",
    "title": "Welcome to STA 101L!",
    "section": "Meet each other",
    "text": "Meet each other\n\n\n\nGroup activity - meeting each other\n\n\nIn groups of 2, ask your partner the following questions\n\npreferred name and pronouns\nfield of study, major\n(least) favorite thing about Durham\nfavorite food, song or artist\n\nYou will introduce your partner to the class.\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-1.html#what-is-data-analysis",
    "href": "slides/lec-1.html#what-is-data-analysis",
    "title": "Welcome to STA 101L!",
    "section": "What is data analysis?",
    "text": "What is data analysis?\n\n\n‚ÄúData analysis is a process of inspecting, cleaning, transforming, and modelling data with the goal of discovering useful information, informing conclusions, and supporting decision-making. (‚Ä¶) In today‚Äôs business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively.‚Äù\n\n\nSource: Wikipedia"
  },
  {
    "objectID": "slides/lec-1.html#statistics",
    "href": "slides/lec-1.html#statistics",
    "title": "Welcome to STA 101L!",
    "section": "Statistics",
    "text": "Statistics\n\n‚ÄúEvery field worth studying connects to one‚Äôs everyday life. Statistics is not an isolated field, it connects to everything.‚Äù ‚Äî Andrew Gelman\n\n\nStatistical inference: set of procedures for making rigorous claims about a population from a (small) sample in the presence of uncertainty."
  },
  {
    "objectID": "slides/lec-1.html#course-faq",
    "href": "slides/lec-1.html#course-faq",
    "title": "Welcome to STA 101L!",
    "section": "Course FAQ",
    "text": "Course FAQ\n\n\nWhat background is assumed for the course? There is no prerequisite.\nWill we be doing coding? Yes. We will use R.\nWhat if I have never coded? We do not expect students to have any experience with R or any other programming language.\nWill we learn the mathematical theory of statistics? Yes and no. The course is primarily focused on application; however, we will discuss some of the mathematics of hypothesis testing and simple linear regression."
  },
  {
    "objectID": "slides/lec-1.html#course-learning-objectives",
    "href": "slides/lec-1.html#course-learning-objectives",
    "title": "Welcome to STA 101L!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\n\nBecome a critical consumer of statistical analyses.\nSummarize and visualize categorical and continuous data.\nBuild and investigate linear regression models for forecasting.\nConduct hypothesis tests and construct confidence intervals for proportions, means, and regression coefficients\nPlan and complete a statistical analysis of a real-world phenomenon."
  },
  {
    "objectID": "slides/lec-1.html#examples-of-data-analyses-in-practice",
    "href": "slides/lec-1.html#examples-of-data-analyses-in-practice",
    "title": "Welcome to STA 101L!",
    "section": "Examples of data analyses in practice",
    "text": "Examples of data analyses in practice\n\n\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\nHow FiveThirtyEight‚Äôs 2020 Presidential Forecast Works ‚Äî And What‚Äôs Different Because Of COVID-19\nEffect of Forensic Evidence on Criminal Justice Case Processing\nWhy it‚Äôs so freaking hard to make a good COVID-19 model"
  },
  {
    "objectID": "slides/lec-1.html#homepage",
    "href": "slides/lec-1.html#homepage",
    "title": "Welcome to STA 101L!",
    "section": "Homepage",
    "text": "Homepage\nhttps://rmorsomme.github.io/website/\n\nAll course materials\nLinks to Sakai, Gradescope, the textbook, etc.\nLet‚Äôs take a tour!"
  },
  {
    "objectID": "slides/lec-1.html#course-toolkit",
    "href": "slides/lec-1.html#course-toolkit",
    "title": "Welcome to STA 101L!",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nAssignment submission and feedback: Gradescope\nComputing software: R and RStudio\nIntroduction to Modern Statistics (IMS): Openintro\n\n\n\n\n\n\n\nImportant\n\n\nInstall and download R and RStudio before Friday‚Äôs lab!"
  },
  {
    "objectID": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "href": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to STA 101L!",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\nPrepare: Prepare for lectures by completing the readings.\nParticipate: Attend and actively participate in lectures and labs, office hours, team meetings\nPractice: Solve plenty of exercises; this is the best way to learn statistics.\nPerform: Put together what you‚Äôve learned to analyze real-world data\n\nFrequent homework assignments\nPrediction group project\nInference group project\n\n\n\n\n\n\n\n\nTip for practicing\n\n\nIn the IMS book, the solutions of the odd-numbered exercises are provided in the appendix."
  },
  {
    "objectID": "slides/lec-1.html#cadence---homework",
    "href": "slides/lec-1.html#cadence---homework",
    "title": "Welcome to STA 101L!",
    "section": "Cadence - homework",
    "text": "Cadence - homework\n\ntwo sets of homework per week\ncombination of problems from IMS and lab exercises\ndue dates TBD\ntyped up using RMarkdown and submitted as a PDF on Gradescope\nlowest grade dropped\nyou may discuss homework with other students; however, your answers should be completed and submitted individually"
  },
  {
    "objectID": "slides/lec-1.html#cadence---two-group-projects",
    "href": "slides/lec-1.html#cadence---two-group-projects",
    "title": "Welcome to STA 101L!",
    "section": "Cadence - two group projects",
    "text": "Cadence - two group projects\n\nPrediction project:\n\ngroups of 2\ngoal: build a model that makes the most accurate predictions possible.\nsome lab and lecture time dedicated to working on it\n2-page write up and informal presentation (2 slides)\n\n\n\n\nInference project:\n\ngroups of 2\ngoal: analyze a phenomenon of your choice using real-world data\napply all the techniques learned in class (visualization, hypothesis test, confidence interval and linear regression)\nsome lab and lecture time dedicated to working on it\n5-page report and formal presentation (+-10 slides)"
  },
  {
    "objectID": "slides/lec-1.html#teams",
    "href": "slides/lec-1.html#teams",
    "title": "Welcome to STA 101L!",
    "section": "Teams",
    "text": "Teams\n\nTeam assignments\n\nassigned by me\nin-class exercises, and the two project\n\nExpectations and roles\n\neveryone is expected to contribute equal effort\neveryone is expected to understand all code turned in"
  },
  {
    "objectID": "slides/lec-1.html#grading",
    "href": "slides/lec-1.html#grading",
    "title": "Welcome to STA 101L!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework and Labs\n50%\n\n\nPrediction Project\n20%\n\n\nInference Project\n30%\n\n\n\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/lec-1.html#support",
    "href": "slides/lec-1.html#support",
    "title": "Welcome to STA 101L!",
    "section": "Support",
    "text": "Support\n\nAsk questions in class and labs quickly.\nAttend office hours.\nUse the course forum Conversations on Sakai.\nEmails should be reserved for questions not appropriate for the public forum..\nRead the course support page for more information."
  },
  {
    "objectID": "slides/lec-1.html#announcements",
    "href": "slides/lec-1.html#announcements",
    "title": "Welcome to STA 101L!",
    "section": "Announcements",
    "text": "Announcements\n\nSent via email, be sure to check your mail box regularly\nI‚Äôll assume that you‚Äôve read an announcement by the next ‚Äúbusiness‚Äù day"
  },
  {
    "objectID": "slides/lec-1.html#diversity-inclusion",
    "href": "slides/lec-1.html#diversity-inclusion",
    "title": "Welcome to STA 101L!",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official Duke records, please let us know!\nPlease let us know your preferred pronouns; correct us if necessary.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/lec-1.html#accessibility",
    "href": "slides/lec-1.html#accessibility",
    "title": "Welcome to STA 101L!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I‚Äôm always learning how to do this better. If any course component is not accessible to you in any way, please don‚Äôt hesitate to let me know."
  },
  {
    "objectID": "slides/lec-1.html#covid-policies",
    "href": "slides/lec-1.html#covid-policies",
    "title": "Welcome to STA 101L!",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask at all times!\nRead and follow university guidance here."
  },
  {
    "objectID": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "href": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "title": "Welcome to STA 101L!",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nto ensure timely feedback, assignments submitted after the deadline will not be graded\none waiver available for a 24-hour extension\nregrade requests within 48 hours\nRead the course syllabus for more details"
  },
  {
    "objectID": "slides/lec-1.html#collaboration-policy",
    "href": "slides/lec-1.html#collaboration-policy",
    "title": "Welcome to STA 101L!",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively.\nHomeworks must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice."
  },
  {
    "objectID": "slides/lec-1.html#sharing-reusing-code-policy",
    "href": "slides/lec-1.html#sharing-reusing-code-policy",
    "title": "Welcome to STA 101L!",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course‚Äôs policy is that you may use any online resources (e.g.¬†RStudio Community, StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/lec-1.html#academic-integrity",
    "href": "slides/lec-1.html#academic-integrity",
    "title": "Welcome to STA 101L!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/lec-1.html#most-importantly",
    "href": "slides/lec-1.html#most-importantly",
    "title": "Welcome to STA 101L!",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you‚Äôre not sure if something violates a policy!"
  },
  {
    "objectID": "slides/lec-1.html#five-tips-for-success",
    "href": "slides/lec-1.html#five-tips-for-success",
    "title": "Welcome to STA 101L!",
    "section": "Five tips for success",
    "text": "Five tips for success\n\ncomplete the reading before the lectures;\nask questions quickly; don‚Äôt let a day pass by with lingering questions;\ndo the homework assignments thoroughly;\npractice, practice, practice;\ndon‚Äôt procrastinate; start on the homework assignments and the projects early."
  },
  {
    "objectID": "slides/lec-1.html#section",
    "href": "slides/lec-1.html#section",
    "title": "Welcome to STA 101L!",
    "section": "",
    "text": "Tip for practicing\n\n\nRemember the odd-number exercises in IMS! The teaching team will always be happy to provide feedback on your work."
  },
  {
    "objectID": "slides/lec-1.html#learning-during-a-pandemic-learning-during-the-summer",
    "href": "slides/lec-1.html#learning-during-a-pandemic-learning-during-the-summer",
    "title": "Welcome to STA 101L!",
    "section": "Learning during a pandemic, learning during the summer",
    "text": "Learning during a pandemic, learning during the summer\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don‚Äôt hesitate to ask.\n\n\nYou never owe me personal information about your health (mental or physical) but you‚Äôre always welcome to talk to me. If I can‚Äôt help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this summer session"
  },
  {
    "objectID": "slides/lec-1.html#this-weeks-tasks",
    "href": "slides/lec-1.html#this-weeks-tasks",
    "title": "Welcome to STA 101L!",
    "section": "This week‚Äôs tasks",
    "text": "This week‚Äôs tasks\n\nDownload and install R and RStudio before Friday‚Äôs lab.\nRead the syllabus.\nComplete the assigned reading before tomorrow.\nWatch out for announcement emails."
  },
  {
    "objectID": "slides/lec-1.html#important-dates",
    "href": "slides/lec-1.html#important-dates",
    "title": "Welcome to STA 101L!",
    "section": "Important dates",
    "text": "Important dates\n\nMay 11: Classes begin (Monday meeting schedule)\nMay 13: Drop/add ends\nMay 16: Regular class meeting schedule begins\nMay 30: Memorial Day holiday, no class is held\nMay 31: Prediction project\nJune 8: Last day to withdraw with W\nJune 16: Inference project presentation\nJune 17: Classes end\nJune 20: Juneteenth holiday\nJune 21: Reading period\nJune 23: Last assignment: inference project report\n\nClick here for the full Duke academic calendar."
  },
  {
    "objectID": "slides/lec-1.html#kai-says",
    "href": "slides/lec-1.html#kai-says",
    "title": "Welcome to STA 101L!",
    "section": "Kai says‚Ä¶",
    "text": "Kai says‚Ä¶\n\n\n\n\n\n\n\n\nhttps://rmorsomme.github.io/website/"
  },
  {
    "objectID": "slides/lec-2.html#outline",
    "href": "slides/lec-2.html#outline",
    "title": "Introduction to Data",
    "section": "Outline",
    "text": "Outline\n\nMotivating example - stent and stroke\nPrinciples of statistical inference\nTypes of variable\nExperiments and observational studies"
  },
  {
    "objectID": "slides/lec-2.html#example---stents-and-strokes",
    "href": "slides/lec-2.html#example---stents-and-strokes",
    "title": "Introduction to Data",
    "section": "Example - Stents and strokes",
    "text": "Example - Stents and strokes\nStents are known to reduce the risk of an additional heart attack or death after a cardiac event.\n\nCould stents have similar benefits for patients at risk of stroke?\n\n\n\nIf so, we should use this well-known procedure to reduce the risk of stroke!\nIf not, the procedure (surgery) should be avoided."
  },
  {
    "objectID": "slides/lec-2.html#does-the-use-of-stents-reduce-the-risk-of-stroke",
    "href": "slides/lec-2.html#does-the-use-of-stents-reduce-the-risk-of-stroke",
    "title": "Introduction to Data",
    "section": "Does the use of stents reduce the risk of stroke?",
    "text": "Does the use of stents reduce the risk of stroke?\nWe have an experiment with 451 at-risk patients:\n\neach volunteer patient was randomly assigned to either the treatment (stent) or the control (no stent) group\ncheck with patients 30 days and 365 days later"
  },
  {
    "objectID": "slides/lec-2.html#dealing-with-randomness",
    "href": "slides/lec-2.html#dealing-with-randomness",
    "title": "Introduction to Data",
    "section": "Dealing with Randomness",
    "text": "Dealing with Randomness\nSuppose I flip a coin \\(100\\) times and count the number of times I obtain heads.\n\nI expect to observe about \\(50\\) heads.\n\n\n\nImagine that I observe \\(85\\) heads instead. That would be alarming; the coin is probably not fair.\n\n\n\n\nIf I had observed \\(55\\) heads then I would not be alarmed; this is a plausible result with a fair coin."
  },
  {
    "objectID": "slides/lec-2.html#intuition-about-randomness",
    "href": "slides/lec-2.html#intuition-about-randomness",
    "title": "Introduction to Data",
    "section": "Intuition about randomness",
    "text": "Intuition about randomness\n\n\n\nGroup exercise - gut feeling about randomness\n\n\n\nIn the coin example, what number of heads would start to make you doubt that the coin is fair?\nIn the stent study, is the difference large enough to make you doubt that the stents have no effect? In other words, do you think that the difference we observe between the two groups is plausible if stents have no effect?\n\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-2.html#observations-and-variables",
    "href": "slides/lec-2.html#observations-and-variables",
    "title": "Introduction to Data",
    "section": "Observations and variables",
    "text": "Observations and variables\n\n\n\nResults for three patients from the stent study.\n \n  \n    patient \n    group \n    30 days \n    365 days \n  \n \n\n  \n    1 \n    control \n    no event \n    no event \n  \n  \n    2 \n    control \n    no event \n    no event \n  \n  \n    3 \n    control \n    no event \n    no event \n  \n\n\n\n\n\n\n\nEach row represents an observation\nEach column represents a variable"
  },
  {
    "objectID": "slides/lec-2.html#some-examples",
    "href": "slides/lec-2.html#some-examples",
    "title": "Introduction to Data",
    "section": "Some examples",
    "text": "Some examples\n\nObservational units: individuals, families, student cohort, cities, counties, countries, cells (biology), animals, books, courses, apples\nVariables: height, weight, age, size, year, latitude, longitude, type, sex, diet, number of pages, genre, level, color"
  },
  {
    "objectID": "slides/lec-2.html#population",
    "href": "slides/lec-2.html#population",
    "title": "Introduction to Data",
    "section": "Population",
    "text": "Population\nWe are typically interested in the relation between variables in some population.\nThe population of interest is often large, but with well-defined limits\n\ne.g.¬†patients at risk of stroke, Duke students, trees in Duke Forest, US counties\nbut not the following: people, students, patients."
  },
  {
    "objectID": "slides/lec-2.html#census-and-sample",
    "href": "slides/lec-2.html#census-and-sample",
    "title": "Introduction to Data",
    "section": "Census and sample",
    "text": "Census and sample\nThere are two ways to learn about the relation between variables in a given population.\n\n\nCensus: collect data on the whole population\n\nideal\n‚Ä¶but typically impractical, expensive\n\n\n\n\n\nSample: small fraction of the population"
  },
  {
    "objectID": "slides/lec-2.html#statistical-inference",
    "href": "slides/lec-2.html#statistical-inference",
    "title": "Introduction to Data",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nPopulation parameter, e.g.¬†mean number of hours that Duke students sleep per night\n\nGreek letter: \\(\\mu\\), \\(\\beta\\), but also \\(p\\).\n\n\n\n\nSample statistic, e.g.¬†observed average number of hours Duke students sleep per night in some sample\n\nRoman letter: \\(\\bar{x}\\), \\(b\\), \\(\\hat{p}\\)\n\n\n\n\n\nHow to learn about the population from a sample?\n\n‚Ä¶from sample statistics to population parameters\nStatistical inference provides a rigorous framework to accomplish this."
  },
  {
    "objectID": "slides/lec-2.html#statistics-as-an-art-sampling",
    "href": "slides/lec-2.html#statistics-as-an-art-sampling",
    "title": "Introduction to Data",
    "section": "Statistics as an art ‚Äì sampling",
    "text": "Statistics as an art ‚Äì sampling\nWhen you make soup, there is no need to drink the whole pot (population) to know if the it is seasoned enough.\n\nTasting a spoonful (sample) is sufficient.\nIf the soup is well mixed, a spoonful is a representative sample of the population"
  },
  {
    "objectID": "slides/lec-2.html#section",
    "href": "slides/lec-2.html#section",
    "title": "Introduction to Data",
    "section": "",
    "text": "Group exercise - sampling\n\n\nBack to the study on the effect of diet on sleep among Duke students. How would you obtain a sample of student for your study if you had (i) 1 hour, (ii) 1 week to collect your data?\n\n\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lec-2.html#section-1",
    "href": "slides/lec-2.html#section-1",
    "title": "Introduction to Data",
    "section": "",
    "text": "Are all samples created equal? No!\n\nWhat can go wrong?\n\nsmall samples,\nconvenience sampling, e.g.¬†students on campus,\nblind spots, e.g.¬†voters with no phone,\n‚Ä¶\n\n\n\nSampling is an art."
  },
  {
    "objectID": "slides/lec-2.html#random-sample",
    "href": "slides/lec-2.html#random-sample",
    "title": "Introduction to Data",
    "section": "Random sample",
    "text": "Random sample\nThe gold standard is a random sample\n\nbut even then, we can have non-response bias\n\n\nüõë Obtaining a representative sample is difficult.\n\n\n‚úÖ But surprisingly small representative samples can do the job!\n\ne.g.¬†1,500 voters (later in class)"
  },
  {
    "objectID": "slides/lec-2.html#numerical-variables",
    "href": "slides/lec-2.html#numerical-variables",
    "title": "Introduction to Data",
    "section": "Numerical variables",
    "text": "Numerical variables\n\nTakes a numerical value\nExamples: age, height, number of children\n\n\n\n\n\n\n\n\nWarning\n\n\nNot all numbers are numerical variables, e.g.¬†zip code, phone number.\nHeuristic: is the average meaningful? Yes!\n\n\n\n\n\nNumerical variables are either\n\ndiscrete, e.g.¬†number of siblings\nor continuous, e.g.¬†a person‚Äôs height\n\n\n\n\nnot always clear cut, e.g.¬†GPA"
  },
  {
    "objectID": "slides/lec-2.html#categorical-variables",
    "href": "slides/lec-2.html#categorical-variables",
    "title": "Introduction to Data",
    "section": "Categorical variables",
    "text": "Categorical variables\n\nTakes a level (a category)\nExamples: eye color, place of birth, education level\n\n\n\n\n\n\n\nWarning\n\n\nSome numbers are categorical variables, e.g.¬†zip code, phone number.\nHeuristic: is the average meaningful? No!\n\n\n\n\nNumerical variables are either\n\nnominal, e.g.¬†eye color\nor ordinal, e.g.¬†education level"
  },
  {
    "objectID": "slides/lec-2.html#section-2",
    "href": "slides/lec-2.html#section-2",
    "title": "Introduction to Data",
    "section": "",
    "text": "Group exercise - types of variables\n\n\n\nExercise 1.13 b\nConsider the study you used in the previous group exercise. Can you identify a numerical and a categorical variable? What are they?\nDoes the study consider a variable of all four types? Can you come up with a variable of each type?\n\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-2.html#relationship-between-variables",
    "href": "slides/lec-2.html#relationship-between-variables",
    "title": "Introduction to Data",
    "section": "Relationship between variables",
    "text": "Relationship between variables\nTwo variables can either be independent or associated.\n\nIf two variables are associated, the association can be\n\nlinear (positive, or negative)\nor it can take any form, e.g.¬†U-shape, inverted-J-shape (like a square root)"
  },
  {
    "objectID": "slides/lec-2.html#section-3",
    "href": "slides/lec-2.html#section-3",
    "title": "Introduction to Data",
    "section": "",
    "text": "Group exercise - types of associations\n\n\nProvide two numerical variables which you expect to be\n\nlinearly associated; is the association positive or negative?\nassociated in a non linear way.\n\n\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lec-2.html#explanatory-and-response-variable",
    "href": "slides/lec-2.html#explanatory-and-response-variable",
    "title": "Introduction to Data",
    "section": "Explanatory and response variable",
    "text": "Explanatory and response variable\n\nWhen two variables are associated, we sometimes hypothesize that changes in one cause changes in the other.\n\n\n\nExplanatory variable \\(\\Rightarrow\\) response variable\n\n\n\n\n‚Ä¶but association \\(\\neq\\) causation; examples:\n\nice-cream and shark attacks; fire damage and firemen\ncounties and kidney cancer death rate; the best classrooms are small classrooms, but so are the worst classrooms."
  },
  {
    "objectID": "slides/lec-2.html#group-exercise---counties-and-kidney-cancer-death-rate",
    "href": "slides/lec-2.html#group-exercise---counties-and-kidney-cancer-death-rate",
    "title": "Introduction to Data",
    "section": "Group exercise - counties and kidney cancer death rate",
    "text": "Group exercise - counties and kidney cancer death rate\n\nInstructionsGroup 1Group 2Small sample effect\n\n\nWhy are most of the shaded counties in the middle of the country?\n\n\n\n04:00\n\n\n\n\n\nSource: Bayesian Data Analysis\n\n\n\n\n\nThe counties of the United Sates with the lowest 10% age-standardized death rates for cancer of kidney/ureter for U.S. white males, 1980‚Äì1989.\n\n\nSource: Bayesian Data Analysis\n\n\n\n\n\nThere is more variation in small counties.\n\n\nSource: Bayesian Data Analysis"
  },
  {
    "objectID": "slides/lec-2.html#experiments",
    "href": "slides/lec-2.html#experiments",
    "title": "Introduction to Data",
    "section": "Experiments",
    "text": "Experiments\n\nThe value of the explanatory variable is assigned by the researcher\nRandomized experiment: the value of the explanatory variable is randomly assigned\n\nremoves any counfounding (lurking) variable, e.g.¬†air temperature\n\nBlind, or even double-blind, to avoid biases\n\nplacebo\ncan go wrong, e.g.¬†vitamins in prison"
  },
  {
    "objectID": "slides/lec-2.html#observational-studies",
    "href": "slides/lec-2.html#observational-studies",
    "title": "Introduction to Data",
    "section": "Observational Studies",
    "text": "Observational Studies\n\nThe value of the explanatory variable is not assigned by the researcher\n\nthere is no interference\n\nExample: survey"
  },
  {
    "objectID": "slides/lec-2.html#section-4",
    "href": "slides/lec-2.html#section-4",
    "title": "Introduction to Data",
    "section": "",
    "text": "üõë Does not easily lead to causal claims due to the potential presence of counfounding variables\n\nSource: IMS\n\n‚Ä¶but they can lead to causal claims in certain cases!\n\nE.g. smoking causes cancer."
  },
  {
    "objectID": "slides/lec-2.html#section-5",
    "href": "slides/lec-2.html#section-5",
    "title": "Introduction to Data",
    "section": "",
    "text": "Group exercise - experiment and observational study\n\n\nYou want to investigate the effect of caffeine on class participation among Duke students\n\nDesign an observational study.\nDesign an experiment.\nIs your experiment double-blind? Can you make it double-blind?\nDo you have any ethical or practical concern with the experiment?\n\nProvide an example of an observational study that you would not turn into an experiment due to:\n\npractical considerations\nethical considerations\n\nExercise 2.12\n\n\n\n\n\n\n06:00"
  },
  {
    "objectID": "slides/lec-2.html#recap-1",
    "href": "slides/lec-2.html#recap-1",
    "title": "Introduction to Data",
    "section": "Recap",
    "text": "Recap\n\n\nobservations (row) and variables (column)\npopulation parameters and sample statistics\nstatistical inference\nsampling\nfour types of variables\n\nnumerical: continuous, discrete\ncategorical: nominal, ordinal\n\nexperiments, observational studies and causal claims\n\n\n\n\n\nhttps://rmorsomme.github.io/website/"
  },
  {
    "objectID": "slides/lec-27.html#exam-instructions",
    "href": "slides/lec-27.html#exam-instructions",
    "title": "Exam 3 review",
    "section": "Exam instructions",
    "text": "Exam instructions\n\nThe exam is an individual assignment. Everything in your repository is for your eyes only.\nYou may not collaborate or communicate anything about this exam to anyone except the instructor. For example, you may not communicate with other students, the TAs, or post/solicit help on the internet, email or via any other method of communication.\nThe exam is open-book, open-note, so you may use any materials from class as you take the exam.\nNo TA office hours will be held during the exam. You may not email the TAs questions about the exam.\nIf you have questions, email or Slack me."
  },
  {
    "objectID": "slides/lec-27.html#exam-coverage-and-format",
    "href": "slides/lec-27.html#exam-coverage-and-format",
    "title": "Exam 3 review",
    "section": "Exam coverage and format",
    "text": "Exam coverage and format\n\nFocuses on content Weeks 09 - 14, but can include material from previous weeks\n\nSimilar format as previous exams\n\nPart 1: Multiple choice/fill-in-the-blank questions on Sakai\nPart 2: Open-ended data analysis in GitHub and submitted on Gradescope"
  },
  {
    "objectID": "slides/lec-27.html#part-2-of-the-exam",
    "href": "slides/lec-27.html#part-2-of-the-exam",
    "title": "Exam 3 review",
    "section": "Part 2 of the exam",
    "text": "Part 2 of the exam\n\nGoal: Assess your understanding of the course material and how the methods you learned are applied to the analysis of real-world data.\n\nInclude all of your analysis steps in your exam write up, unless stated otherwise.\n\nFor example, if the exam says ‚Äúassume conditions are met,‚Äù You can reference that information in your write up but don‚Äôt have to recheck the conditions."
  },
  {
    "objectID": "slides/lec-27.html#assessment-criteria",
    "href": "slides/lec-27.html#assessment-criteria",
    "title": "Exam 3 review",
    "section": "Assessment criteria",
    "text": "Assessment criteria\n\nYou can identify the correct approach, analysis method, and/or inferential results required to answer the question.\nYou understand the correct conditions and diagnostics needed to determine whether the conclusions drawn from the model will be reliable\nYou can write results and conclusions in a meaningful way that can be understood by a general audience (think a business or research partner)\nYou can produce a report that is suitable for a professional audience (e.g., narrative is written in complete sentences, all graphs have proper titles and axis labels, there is not extraneous output, all Latex is rendered)\nYou can conduct the analysis using a reproducible data analysis workflow that incorporates version control"
  },
  {
    "objectID": "slides/lec-27.html#application-exercise",
    "href": "slides/lec-27.html#application-exercise",
    "title": "Exam 3 review",
    "section": "Application exercise",
    "text": "Application exercise\n\nüìã github.com/sta210-s22/ae-12-exam-3-review\n\n\n\n\nsta210-s22.github.io/website"
  },
  {
    "objectID": "slides/lec-28.html#remaining-deadlines-for-project",
    "href": "slides/lec-28.html#remaining-deadlines-for-project",
    "title": "Wrap up",
    "section": "Remaining deadlines for project",
    "text": "Remaining deadlines for project\n\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30\nPeer evaluations due Mon, Apr 25 + Sat, Apr 30\n\n\nAny questions related to projects?"
  },
  {
    "objectID": "slides/lec-28.html#grading",
    "href": "slides/lec-28.html#grading",
    "title": "Wrap up",
    "section": "Grading",
    "text": "Grading\n\nCheck your grades on Sakai, make sure they match Gradescope, email/Slack me if not by April 30\nWatch for new feedback released on Gradescope"
  },
  {
    "objectID": "slides/lec-28.html#evaluations",
    "href": "slides/lec-28.html#evaluations",
    "title": "Wrap up",
    "section": "Evaluations",
    "text": "Evaluations\n\nCourse evaluation\nTA evaluation"
  },
  {
    "objectID": "slides/lec-28.html#application-exercise",
    "href": "slides/lec-28.html#application-exercise",
    "title": "Wrap up",
    "section": "Application exercise",
    "text": "Application exercise\n\nüìã github.com/sta210-s22/ae-13-tale-of-two-creeks\n\n\n\n\nsta210-s22.github.io/website"
  },
  {
    "objectID": "slides/lec-3.html#announcements---oh",
    "href": "slides/lec-3.html#announcements---oh",
    "title": "Data Summary and Visualization",
    "section": "Announcements - OH",
    "text": "Announcements - OH\n\n\nOH:\n\nRaphael: Mon, Wed 10-11am (virtual)\nRoy: Wed, Fri 4:45-5:45pm (hybrid)\n\n\nThis week (exceptional):\n\nRoy: Fri 2:30-3:30pm (hybrid)\nRaphael: Sun 9:00-10:00am (virtual)"
  },
  {
    "objectID": "slides/lec-3.html#announcements---hw",
    "href": "slides/lec-3.html#announcements---hw",
    "title": "Data Summary and Visualization",
    "section": "Announcements - HW",
    "text": "Announcements - HW\n\nHW due on Sunday 9:00pm and Wednesday 9:00pm\n\nHW 1 is due Sunday, May 15 at 9:00pm"
  },
  {
    "objectID": "slides/lec-3.html#announcements---general",
    "href": "slides/lec-3.html#announcements---general",
    "title": "Data Summary and Visualization",
    "section": "Announcements - general",
    "text": "Announcements - general\n\nLectures will closely follow IMS, but\n\nsome topics will be skipped, e.g.¬†2.1.5, dot plots, etc.\nsome topics will be added, e.g.¬†AIC and BIC\n\n\nDrop/Add for Term 1 ends tomorrow (Friday, May 13)."
  },
  {
    "objectID": "slides/lec-3.html#franklin-albino-and-gillman-have-read-the-syllabus.-have-you",
    "href": "slides/lec-3.html#franklin-albino-and-gillman-have-read-the-syllabus.-have-you",
    "title": "Data Summary and Visualization",
    "section": "Franklin (albino) and Gillman have read the syllabus. Have you?",
    "text": "Franklin (albino) and Gillman have read the syllabus. Have you?"
  },
  {
    "objectID": "slides/lec-3.html#recap-of-last-lecture",
    "href": "slides/lec-3.html#recap-of-last-lecture",
    "title": "Data Summary and Visualization",
    "section": "Recap of last lecture",
    "text": "Recap of last lecture\n\n\nobservations (row) and variables (column)\npopulation parameters and sample statistics\nstatistical inference\nsampling\nfour types of variables\nexperiments, observational studies and causal claims"
  },
  {
    "objectID": "slides/lec-3.html#outline",
    "href": "slides/lec-3.html#outline",
    "title": "Data Summary and Visualization",
    "section": "Outline",
    "text": "Outline\n\nVisualization for numerical data\nSummary for numerical data\nVisualization for categorical data\nSummary for categorical data\nMore visualizations\n\n\n‚ÄúThe greatest value of a picture is when it forces us to notice what we never expected to see.‚Äù ‚Äî John Tukey"
  },
  {
    "objectID": "slides/lec-3.html#billion-are-you-typical",
    "href": "slides/lec-3.html#billion-are-you-typical",
    "title": "Data Summary and Visualization",
    "section": "7 Billion: Are You Typical?",
    "text": "7 Billion: Are You Typical?\nNational Geographic\n\n\n\n\nGroup exercise - data summaries?\n\n\n\nWhat variables are mentioned in the video?\nWhat are their types?\nHow were they summarized and/or visualized?\n\n\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lec-3.html#us-birth-data",
    "href": "slides/lec-3.html#us-birth-data",
    "title": "Data Summary and Visualization",
    "section": "US birth data",
    "text": "US birth data\n\nlibrary(fivethirtyeight) # for the USbirth dataset\nd_birth <- fivethirtyeight::US_births_2000_2014\n\nThere are 5479 observations (rows)\n\nnrow(d_birth) # number of rows\n\n[1] 5479\n\n\nand 6 variables (columns)\n\nncol(d_birth) # number of columns\n\n[1] 6"
  },
  {
    "objectID": "slides/lec-3.html#section",
    "href": "slides/lec-3.html#section",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "head(d_birth)\n\n# A tibble: 6 x 6\n   year month date_of_month date       day_of_week births\n  <int> <int>         <int> <date>     <ord>        <int>\n1  2000     1             1 2000-01-01 Sat           9083\n2  2000     1             2 2000-01-02 Sun           8006\n3  2000     1             3 2000-01-03 Mon          11363\n4  2000     1             4 2000-01-04 Tues         13032\n5  2000     1             5 2000-01-05 Wed          12558\n6  2000     1             6 2000-01-06 Thurs        12466\n\nlibrary(tidyverse)       # for data wrangling\nglimpse(d_birth)\n\nRows: 5,479\nColumns: 6\n$ year          <int> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 20~\n$ month         <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n$ date_of_month <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1~\n$ date          <date> 2000-01-01, 2000-01-02, 2000-01-03, 2000-01-04, 2000-01~\n$ day_of_week   <ord> Sat, Sun, Mon, Tues, Wed, Thurs, Fri, Sat, Sun, Mon, Tue~\n$ births        <int> 9083, 8006, 11363, 13032, 12558, 12466, 12516, 8934, 794~"
  },
  {
    "objectID": "slides/lec-3.html#histogram",
    "href": "slides/lec-3.html#histogram",
    "title": "Data Summary and Visualization",
    "section": "Histogram",
    "text": "Histogram\n\nggplot(d_birth) +\n  geom_histogram(aes(births)) +\n  labs(title = \"Daily number of natural births in the US between 2000 and 2014\")"
  },
  {
    "objectID": "slides/lec-3.html#section-1",
    "href": "slides/lec-3.html#section-1",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Higher bars indicate where the data are relatively more common\nMore days with around 8,000 births or with around 12,500 births\nFew days with less than 7,000 or more than 14,000 births.\nAlso few days with around 10,000 births\n\nWe can change the number of bins to have a rougher or more detailed histogram."
  },
  {
    "objectID": "slides/lec-3.html#section-2",
    "href": "slides/lec-3.html#section-2",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "bins = 10\nbins = 100\n\n\n\n\nggplot(d_birth) +\n  geom_histogram(aes(births), bins = 10)\n\n\n\n\n\n\n\n\n\n\nggplot(d_birth) +\n  geom_histogram(aes(births), bins = 100)"
  },
  {
    "objectID": "slides/lec-3.html#statistics-as-an-art---describing-a-distribution",
    "href": "slides/lec-3.html#statistics-as-an-art---describing-a-distribution",
    "title": "Data Summary and Visualization",
    "section": "Statistics as an art - describing a distribution",
    "text": "Statistics as an art - describing a distribution\n\n\n\n\n\n\nTip\n\n\nTo explore a numerical variable, always start with a histogram\n\n\n\nTo describe the distribution of a numerical variable, we comment on\n\nthe mode(s): unimodal, bimodal, multimodal\nthe shape of each mode: flat, bell-shape, bounded\nthe symmetry: symmetric, left skewed, right skewed\nthe outliers: presence of extreme values\nany other surprising feature.\n\n\n\n\n\n\n\nDescribing a distribution is an art\n\n\nNote that some distributions will not fit nicely in these categories."
  },
  {
    "objectID": "slides/lec-3.html#describing-the-us-birth-data",
    "href": "slides/lec-3.html#describing-the-us-birth-data",
    "title": "Data Summary and Visualization",
    "section": "Describing the US birth data",
    "text": "Describing the US birth data\nThe distribution of the daily number of births in the US is bimodal with each mode being bell-shaped and symmetric. We observe no extreme value."
  },
  {
    "objectID": "slides/lec-3.html#section-3",
    "href": "slides/lec-3.html#section-3",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Group exercise - describing a distribution\n\n\nDescribe the distributions in exercises 5.6, 5.13, 5.24 and 5.26 (only consider the histograms)\n\n\n\n\n\n\n04:00"
  },
  {
    "objectID": "slides/lec-3.html#scatterplots",
    "href": "slides/lec-3.html#scatterplots",
    "title": "Data Summary and Visualization",
    "section": "Scatterplots",
    "text": "Scatterplots\nHistograms: visualize the distribution of a single numerical variable.\n\nScatterplots: visualize the relation between two numerical variables."
  },
  {
    "objectID": "slides/lec-3.html#the-mpg-dataset",
    "href": "slides/lec-3.html#the-mpg-dataset",
    "title": "Data Summary and Visualization",
    "section": "The mpg dataset",
    "text": "The mpg dataset\n\nd_car <- ggplot2::mpg\nhead(d_car)\n\n# A tibble: 6 x 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  <chr>        <chr> <dbl> <int> <int> <chr>      <chr> <int> <int> <chr> <chr> \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa~\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa~\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa~\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa~\n5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa~\n6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa~\n\n\nWe will look at the relation between engine size (disp) and fuel efficiency (hwy)."
  },
  {
    "objectID": "slides/lec-3.html#section-4",
    "href": "slides/lec-3.html#section-4",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "ggplot(d_car) +\n  geom_point(aes(displ, hwy)) +\n  labs(title = \"Relation between fuel consumption on the highway and engine size\")"
  },
  {
    "objectID": "slides/lec-3.html#section-5",
    "href": "slides/lec-3.html#section-5",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Note\n\n\nTo add an additional variable to your visualization, you can use color or symbols."
  },
  {
    "objectID": "slides/lec-3.html#section-6",
    "href": "slides/lec-3.html#section-6",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Colored points\nSymbols\n\n\n\n\nggplot(d_car) +\n  geom_point(aes(displ, hwy, col = drv))\n\n\n\n\n\n\n\n\n\n\nggplot(d_car) +\n  geom_point(aes(displ, hwy, shape = drv))"
  },
  {
    "objectID": "slides/lec-3.html#measures-of-centrality",
    "href": "slides/lec-3.html#measures-of-centrality",
    "title": "Data Summary and Visualization",
    "section": "Measures of centrality",
    "text": "Measures of centrality\n\nThe average: \\(\\bar{x} = \\dfrac{x_1 + \\dots + x_n}{n}\\)\n\nTo compute the average age in the class, we would calculate\n\n\n\n\\[\n\\overline{\\text{age}} = \\dfrac{\\text{age}_{Hayden} + \\text{age}_{Janice} + \\text{age}_{Kenndy} + \\text{age}_{Maggie} + \\text{age}_{Melissa} + \\text{age}_{Yuanzhi}}{6}\n\\]\n\nThe median: the middle value\n\n50% of the sample is large than the median, and 50% is smaller.\n\n\n\n\n\nmean(d_birth$births)   # average\n\n[1] 11350.07\n\nmedian(d_birth$births) # median\n\n[1] 12343"
  },
  {
    "objectID": "slides/lec-3.html#percentiles",
    "href": "slides/lec-3.html#percentiles",
    "title": "Data Summary and Visualization",
    "section": "Percentiles",
    "text": "Percentiles\nPercentiles are a generalization of the median.\n\nThe value that is larger than p% of the data and smaller than the rest is called the p-th percentile.\n\n\nThe median is the 50th percentile.\n\n\nWe will soon make use of the 25th and 75th percentiles.\nLater in the course, the 95th and 97.5th percentiles will also be useful."
  },
  {
    "objectID": "slides/lec-3.html#measures-of-variation",
    "href": "slides/lec-3.html#measures-of-variation",
    "title": "Data Summary and Visualization",
    "section": "Measures of variation",
    "text": "Measures of variation\n\n\nVariance: average squared distance from the mean\n\n\nStandard deviation (sd): square root of the variance (roughly speaking, the average distance to the mean)\nMost (+- 95%) of the data is within 2 sd of the mean.\n\n\n\nInter-quartile range (IQR): distance between the 25th and the 75th percentiles.\n\n\n\nvar(d_birth$births) # variance\n\n[1] 5409444\n\nsd(d_birth$births) # sd\n\n[1] 2325.821\n\nIQR(d_birth$births) # iqr\n\n[1] 4342"
  },
  {
    "objectID": "slides/lec-3.html#robustness",
    "href": "slides/lec-3.html#robustness",
    "title": "Data Summary and Visualization",
    "section": "Robustness",
    "text": "Robustness\nReal-world data often contain extreme values\n\nmeasurement errors,\ntypos,\nextreme observations,\n‚Ä¶\n\nThe average, median, variance, sd and iqr are not equally robust to the presence of extreme values."
  },
  {
    "objectID": "slides/lec-3.html#section-7",
    "href": "slides/lec-3.html#section-7",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Let us contaminate the birth data with an extreme value of 1 billion‚Ä¶\n\nx_uncontaminated <- d_birth$births  \nx_contaminated   <- c(x_uncontaminated, 1e9) # 1e9 = 10^9 (scientific notation)\n\n\n‚Ä¶and compare the mean, median, variance, sd and iqr of these two variables."
  },
  {
    "objectID": "slides/lec-3.html#section-8",
    "href": "slides/lec-3.html#section-8",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "summary(x_uncontaminated)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5728    8740   12343   11350   13082   16081 \n\nsummary(x_contaminated)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n5.728e+03 8.740e+03 1.234e+04 1.938e+05 1.308e+04 1.000e+09 \n\n\n\n\nvar(x_uncontaminated); var(x_contaminated)\n\n[1] 5409444\n\n\n[1] 1.824776e+14\n\nsd(x_uncontaminated); sd(x_contaminated)\n\n[1] 2325.821\n\n\n[1] 13508428\n\nIQR(x_uncontaminated); IQR(x_contaminated)\n\n[1] 4342\n\n\n[1] 4342.25"
  },
  {
    "objectID": "slides/lec-3.html#section-9",
    "href": "slides/lec-3.html#section-9",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Robustness of the median and the iqr\n\n\nWhile the median and iqr are robust to the presence of extreme values, the mean, variance and sd are not."
  },
  {
    "objectID": "slides/lec-3.html#section-10",
    "href": "slides/lec-3.html#section-10",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Group exercise - summary statistics\n\n\nExercises 5.8, 5.11, 5.15 (replace part \\(c\\) by height of all adults)\nBonus: 5.17, 5.19\nNote: Q1 is first the 25th percentile (larger than one quarter of the data), Q3 is the 75th percentile.\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-3.html#frequency-table-1d",
    "href": "slides/lec-3.html#frequency-table-1d",
    "title": "Data Summary and Visualization",
    "section": "Frequency table (1d)",
    "text": "Frequency table (1d)\n\nhead(d_car)\n\n# A tibble: 6 x 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  <chr>        <chr> <dbl> <int> <int> <chr>      <chr> <int> <int> <chr> <chr> \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa~\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa~\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa~\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa~\n5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa~\n6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa~\n\n\n\ntable(d_car$drv)\n\n\n  4   f   r \n103 106  25"
  },
  {
    "objectID": "slides/lec-3.html#contigency-table-2d",
    "href": "slides/lec-3.html#contigency-table-2d",
    "title": "Data Summary and Visualization",
    "section": "Contigency table (2d)",
    "text": "Contigency table (2d)\n\ntable(d_car$class, d_car$drv)\n\n            \n              4  f  r\n  2seater     0  0  5\n  compact    12 35  0\n  midsize     3 38  0\n  minivan     0 11  0\n  pickup     33  0  0\n  subcompact  4 22  9\n  suv        51  0 11"
  },
  {
    "objectID": "slides/lec-3.html#proportion-table-2d",
    "href": "slides/lec-3.html#proportion-table-2d",
    "title": "Data Summary and Visualization",
    "section": "Proportion table (2d)",
    "text": "Proportion table (2d)\n\n\ntable proportion\nrow proportion\ncolumn proportion\n\n\n\n\ntable(d_car$class, d_car$drv) %>%\n  prop.table() %>%\n  round(2)\n\n            \n                4    f    r\n  2seater    0.00 0.00 0.02\n  compact    0.05 0.15 0.00\n  midsize    0.01 0.16 0.00\n  minivan    0.00 0.05 0.00\n  pickup     0.14 0.00 0.00\n  subcompact 0.02 0.09 0.04\n  suv        0.22 0.00 0.05\n\n\n\n\n\ntable(d_car$class, d_car$drv) %>%\n  prop.table(1) %>%\n  round(2)\n\n            \n                4    f    r\n  2seater    0.00 0.00 1.00\n  compact    0.26 0.74 0.00\n  midsize    0.07 0.93 0.00\n  minivan    0.00 1.00 0.00\n  pickup     1.00 0.00 0.00\n  subcompact 0.11 0.63 0.26\n  suv        0.82 0.00 0.18\n\n\n\n\n\ntable(d_car$class, d_car$drv) %>%\n  prop.table(2) %>%\n  round(2)\n\n            \n                4    f    r\n  2seater    0.00 0.00 0.20\n  compact    0.12 0.33 0.00\n  midsize    0.03 0.36 0.00\n  minivan    0.00 0.10 0.00\n  pickup     0.32 0.00 0.00\n  subcompact 0.04 0.21 0.36\n  suv        0.50 0.00 0.44"
  },
  {
    "objectID": "slides/lec-3.html#section-11",
    "href": "slides/lec-3.html#section-11",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Group exercise - contigency and proportion table\n\n\n\nWhat does the number \\(12\\) (2nd row, 1st column) represent in the contigency table?\nWhat does the number \\(0.05\\) (2nd row, 1st column) represent in the first proportion table?\nWhat does the number \\(0.25\\) (2nd row, 1st column) represent in the row proportion table?\n\n\n\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lec-3.html#barplot",
    "href": "slides/lec-3.html#barplot",
    "title": "Data Summary and Visualization",
    "section": "Barplot",
    "text": "Barplot\n\nggplot(d_car) +\n  geom_bar(aes(drv))\n\n\n\nWe can add a second categorical variable using colors."
  },
  {
    "objectID": "slides/lec-3.html#advanced-barplots",
    "href": "slides/lec-3.html#advanced-barplots",
    "title": "Data Summary and Visualization",
    "section": "Advanced barplots",
    "text": "Advanced barplots\n\n\nstacked\ndodged\nstandardized\n\n\n\n\nggplot(d_car) +\n  geom_bar(aes(drv, fill = class))\n\n\n\n\n\n\n\n\n\n\nggplot(d_car) +\n  geom_bar(aes(drv, fill = class), position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\nggplot(d_car) +\n  geom_bar(aes(drv, fill = class), position = \"fill\")"
  },
  {
    "objectID": "slides/lec-3.html#section-12",
    "href": "slides/lec-3.html#section-12",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Group exercise - pros and cons of barplots\n\n\nExercise 4.5\n\n\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lec-3.html#faceted-histograms",
    "href": "slides/lec-3.html#faceted-histograms",
    "title": "Data Summary and Visualization",
    "section": "Faceted histograms",
    "text": "Faceted histograms\n\nd_birth_small <- filter(d_birth, year %in% c(2000, 2004, 2009, 2014))\nggplot(d_birth_small) +\n  geom_histogram(aes(births)) + \n  facet_grid(year~.)"
  },
  {
    "objectID": "slides/lec-3.html#section-13",
    "href": "slides/lec-3.html#section-13",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Beyond 2 variables\n\n\nFaceted figures are a great way to include \\(\\ge\\) 3 variables! See exercise 1.13"
  },
  {
    "objectID": "slides/lec-3.html#mosaic-plot",
    "href": "slides/lec-3.html#mosaic-plot",
    "title": "Data Summary and Visualization",
    "section": "Mosaic plot",
    "text": "Mosaic plot\n\nggplot(d_car) +\n  geom_mosaic(aes(x = product(drv), fill = class))\n\n\n\n‚úÖ Combines the strengths of the various barplots.\nüõë Not in the tool box of every data scientist"
  },
  {
    "objectID": "slides/lec-3.html#boxplots",
    "href": "slides/lec-3.html#boxplots",
    "title": "Data Summary and Visualization",
    "section": "Boxplots",
    "text": "Boxplots\n\nFrom raw data to boxplotSource: R 4 Data Science"
  },
  {
    "objectID": "slides/lec-3.html#section-14",
    "href": "slides/lec-3.html#section-14",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "The thick line in the middle of the box indicates the median;\nthe box stretches from the 25th percentile (Q1) to the 75th percentile (Q3); it covers 50% of the data;\nthe length of the whiskers are at most 1.5 iqr;\nany observation more than 1.5 iqr away from the box is labelled as an outlier;\n\n\n\nmore compact than histograms\n\n\n\n\n\n\n\n\n\nOutliers\n\n\nOutliers have an extreme value. How to deal with an outlier depends on why the observation stands out. outliers can be\n\nremoved\ncorrected\nignored"
  },
  {
    "objectID": "slides/lec-3.html#section-15",
    "href": "slides/lec-3.html#section-15",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Group exercise - limitation of boxplots\n\n\nExercise 5.13\n\n\n\n\n\n\n01:00"
  },
  {
    "objectID": "slides/lec-3.html#section-16",
    "href": "slides/lec-3.html#section-16",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "Boxplot\nSide-by-side boxplots\n\n\n\n\nggplot(d_birth) +\n  geom_boxplot(aes(y = births))\n\n\n\n\n\n\n\n\n\n\nggplot(d_birth) +\n  geom_boxplot(aes(y=births, x=day_of_week))"
  },
  {
    "objectID": "slides/lec-3.html#figure-title",
    "href": "slides/lec-3.html#figure-title",
    "title": "Data Summary and Visualization",
    "section": "Figure title",
    "text": "Figure title\n\nggplot(d_car) +\n  geom_point(aes(displ, hwy)) +\n  labs(title = \"Fuel consumption on the highway per engine size\")"
  },
  {
    "objectID": "slides/lec-3.html#axis-labels",
    "href": "slides/lec-3.html#axis-labels",
    "title": "Data Summary and Visualization",
    "section": "Axis labels",
    "text": "Axis labels\n\nggplot(d_car) +\n  geom_point(aes(displ, hwy)) +\n  labs(\n    title = \"Fuel consumption on the highway per engine size\",\n    x = \"Engine size (engine displaced in litres)\",\n    y = \"Fuel efficiency on the highway (mpg)\"\n    )"
  },
  {
    "objectID": "slides/lec-3.html#section-17",
    "href": "slides/lec-3.html#section-17",
    "title": "Data Summary and Visualization",
    "section": "",
    "text": "theme_bw\ntheme_classic\ntheme_dark\n\n\n\n\nShow the codeggplot(d_car) +\n  geom_point(aes(displ, hwy)) +\n  labs(\n    title = \"Fuel consumption on the highway per engine size\",\n    x = \"Engine size (engine displaced in litres)\",\n    y = \"Fuel efficiency on the highway (mpg)\"\n    ) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nShow the codeggplot(d_car) +\n  geom_point(aes(displ, hwy)) +\n  labs(\n    title = \"Fuel consumption on the highway per engine size\",\n    x = \"Engine size (engine displaced in litres)\",\n    y = \"Fuel efficiency on the highway (mpg)\"\n    ) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nShow the codeggplot(d_car) +\n  geom_point(aes(displ, hwy)) +\n  labs(\n    title = \"Fuel consumption on the highway per engine size\",\n    x = \"Engine size (engine displaced in litres)\",\n    y = \"Fuel efficiency on the highway (mpg)\"\n    ) +\n  theme_dark()"
  },
  {
    "objectID": "slides/lec-3.html#editing-tables",
    "href": "slides/lec-3.html#editing-tables",
    "title": "Data Summary and Visualization",
    "section": "Editing tables",
    "text": "Editing tables\n\ntable(d_car$class, d_car$drv) %>%\n  prop.table(1) %>%\n  round(2) %>%\n  kbl(caption = \"Distribution of drive type per class of car\") %>%\n  kable_classic(full_width = FALSE, c(\"striped\", \"hover\"))\n\n\nDistribution of drive type per class of car\n \n   \n    4 \n    f \n    r \n  \n\n\n 2seater \n    0.00 \n    0.00 \n    1.00 \n  \n\n compact \n    0.26 \n    0.74 \n    0.00 \n  \n\n midsize \n    0.07 \n    0.93 \n    0.00 \n  \n\n minivan \n    0.00 \n    1.00 \n    0.00 \n  \n\n pickup \n    1.00 \n    0.00 \n    0.00 \n  \n\n subcompact \n    0.11 \n    0.63 \n    0.26 \n  \n\n suv \n    0.82 \n    0.00 \n    0.18 \n  \n\n\n\n\nüìã See this vignette for more details on editing tables"
  },
  {
    "objectID": "slides/lec-3.html#statistics-as-an-art---figures",
    "href": "slides/lec-3.html#statistics-as-an-art---figures",
    "title": "Data Summary and Visualization",
    "section": "Statistics as an art - figures",
    "text": "Statistics as an art - figures\n\nHave a purpose: is the figure necessary?\n\n\n\n\nParsimony: keep it simple and avoid distractions\n\n\n\n\nTell a story: provide context and interpret the figure\n\n\n\n\n\nAt least 3 variables as often as possible: color, shape, facets, etc.\n\n\n\n\n\nEdit your figure: title, axes, theme, etc.\n\n\n\nüìã See R for Data Science - chapters 3 and 7 for more on data visualization in R."
  },
  {
    "objectID": "slides/lec-3.html#recap-1",
    "href": "slides/lec-3.html#recap-1",
    "title": "Data Summary and Visualization",
    "section": "Recap",
    "text": "Recap\n\n\nHistogram, scatterplot, boxplot\nAverage, median, variance, sd and IQR; robustness\nFrequency, contigency and proportion tables\nBarplot, mosaic plot\nEffective communication: well-edited figures, \\(\\ge3\\) variables (symbols, colors, facets), tell a story\nR for Data Science - chapters 3 and 7\n\n\n\n\n‚ÄúThe simple graph has brought more information to the data analyst‚Äôs mind than any other device.‚Äù ‚Äî John Tukey\n\n\n\n\nhttps://rmorsomme.github.io/website/"
  },
  {
    "objectID": "slides/lec-4.html#announcements",
    "href": "slides/lec-4.html#announcements",
    "title": "Simple Linear Regression Models",
    "section": "Announcements",
    "text": "Announcements\n\nFind someone you have not worked with yet.\nHomework 1 has been released\n\nAsk us if anything is unclear\nregrade window of 48 hours.\n\n\nHomework 2 has been published\n\nDue on Wednesday (tomorrow)\nFeel free to re-use the template from HW 1\nThere should be no need for external code ‚Äì look in the lab!"
  },
  {
    "objectID": "slides/lec-4.html#recap-of-last-lecture",
    "href": "slides/lec-4.html#recap-of-last-lecture",
    "title": "Simple Linear Regression Models",
    "section": "Recap of last lecture",
    "text": "Recap of last lecture\n\n\nHistogram, scatterplot, boxplot\nAverage, median, variance, sd and IQR; robustness\nFrequency, contigency and proportion tables\nBarplot, mosaic plot\nEffective communication: well-edited figures, \\(\\ge3\\) variables (symbols, colors, facets)\nR for Data Science - chapters 3 and 7"
  },
  {
    "objectID": "slides/lec-4.html#outline",
    "href": "slides/lec-4.html#outline",
    "title": "Simple Linear Regression Models",
    "section": "Outline",
    "text": "Outline\n\nsimple linear regression model\nleast-square estimates\nmodel comparison\noutliers"
  },
  {
    "objectID": "slides/lec-4.html#regression-model",
    "href": "slides/lec-4.html#regression-model",
    "title": "Simple Linear Regression Models",
    "section": "Regression model",
    "text": "Regression model\n\nd <- ggplot2::mpg\nhead(d, n = 4)\n\n# A tibble: 4 x 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  <chr>        <chr> <dbl> <int> <int> <chr>      <chr> <int> <int> <chr> <chr> \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa~\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa~\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa~\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa~\n\n\n\nSuppose the variable hwy (fuel efficiency on highway) is very expensive to measure.\nWe decide to estimate it using the other variables. To do so, we will fit a regression model.\n\\[\n\\text{hwy} \\approx \\text{model}(\\text{other variables})\n\\]"
  },
  {
    "objectID": "slides/lec-4.html#simple-regression",
    "href": "slides/lec-4.html#simple-regression",
    "title": "Simple Linear Regression Models",
    "section": "Simple regression",
    "text": "Simple regression\nWe expect the variable cty to be a good proxy for hwy.\nAfter all, if a car is efficient in the city, we expect it to also be efficient on the highway! We will therefore consider a simple regression model\n\\[\n\\text{hwy} \\approx \\text{model}(\\text{cty})\n\\] Simple here means that we include a single predictor in the model."
  },
  {
    "objectID": "slides/lec-4.html#simple-linear-regression-1",
    "href": "slides/lec-4.html#simple-linear-regression-1",
    "title": "Simple Linear Regression Models",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nggplot(d) +\n  geom_point(aes(x = cty, y = hwy))\n\n\nThe variables cty and hwy are linearly associated.\nWe therefore opt for a simple linear regression model\n\\[\n\\text{hwy} \\approx \\beta_0 + \\beta_1 \\text{cty}\n\\]"
  },
  {
    "objectID": "slides/lec-4.html#parameters",
    "href": "slides/lec-4.html#parameters",
    "title": "Simple Linear Regression Models",
    "section": "Parameters",
    "text": "Parameters\nThe numbers \\(\\beta_0\\) and \\(\\beta_1\\) are the two parameters of the model.\n\nWe now want to find good values for these unknown parameters.\n\n\nLet us look at two sets of values:\n\\[\\begin{align*}\n\\beta_0 = 1, \\beta_1 = 1.3 \\qquad & \\Rightarrow \\qquad \\text{hwy} \\approx 1 + 1.3 \\text{cty} \\\\\n\n\\beta_0 = 15, \\beta_1 = 0.5 \\qquad & \\Rightarrow \\qquad \\text{hwy} \\approx 15 + 0.5 \\text{cty}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/lec-4.html#section",
    "href": "slides/lec-4.html#section",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Good model\nBad model\n\n\n\n\nggplot(d) +\n  geom_point(aes(x = cty, y = hwy)) +\n  geom_abline(intercept = 1, slope = 1.3)\n\n\n\n\n\n\n\n\n\n\nggplot(d) +\n  geom_point(aes(x = cty, y = hwy)) +\n  geom_abline(intercept = 15, slope = 0.5)"
  },
  {
    "objectID": "slides/lec-4.html#prediction",
    "href": "slides/lec-4.html#prediction",
    "title": "Simple Linear Regression Models",
    "section": "Prediction",
    "text": "Prediction\nWe can use our models to estimate hwy for new vehicles.\n\nImagine there is a new vehicle with \\(\\text{cty} = 30\\). Instead of measuring its hwy (expensive), we use our model to estimate it. Using the ‚Äúgood‚Äù model gives the following estimate\n\\[\n\\begin{align*}\n\\text{hwy}\n& \\approx \\beta_0 + \\beta_1 \\text{cty} \\\\\n& = 1 + 1.3 * 30\\\\\n& = 40\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/lec-4.html#section-1",
    "href": "slides/lec-4.html#section-1",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Is this the true hwy of the new vehicle? No!\n\n\nthis is only an estimate based on the value of the variable cty and our ‚Äúgood‚Äù model.\n\n\n\nCan we do better? Yes!\n\n\n\nTake additional variable into account in the model (e.g.¬†engine size, vehicle age, etc)\n\n\n\n\nUse better values for \\(\\beta_0\\) and \\(\\beta_1\\)."
  },
  {
    "objectID": "slides/lec-4.html#section-2",
    "href": "slides/lec-4.html#section-2",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Group exercise - parameters\n\n\n\nWhat is the prediction for the new vehicle (\\(\\text{cty} = 30\\)) if we use the bad model (\\(\\beta_0 = 15, \\beta_1=0.5\\))?\nCopy and paste the following piece of code and try different values for the parameters to find a good set of values.\n\n\nlibrary(tidyverse)\nd <- ggplot2::mpg\nbeta_0 <- 15\nbeta_1 <- 0.5\nggplot(d) +\n  geom_point(aes(x = cty, y = hwy)) +\n  geom_abline(intercept = beta_0, slope = beta_1)\n\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-4.html#linear-association",
    "href": "slides/lec-4.html#linear-association",
    "title": "Simple Linear Regression Models",
    "section": "Linear association",
    "text": "Linear association\nA simple linear regression model is only applicable if the relation between the predictor and the response is linear.\n\nIf the relation is not linear, the simple linear regression is not suitable.\nIn this case, we need to model the non-linearity (next lecture)."
  },
  {
    "objectID": "slides/lec-4.html#section-3",
    "href": "slides/lec-4.html#section-3",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Group exercise - linear association\n\n\nExercise 7.3\n\n\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lec-4.html#residuals",
    "href": "slides/lec-4.html#residuals",
    "title": "Simple Linear Regression Models",
    "section": "Residuals",
    "text": "Residuals\nOur predictions are only approximate.\n\nLet us represent our prediction with \\(\\widehat{\\text{hwy}}\\) and the true value with \\(\\text{hwy}\\)\n\nthe error we make is \\(\\text{hw} - \\widehat{\\text{hwy}}\\)\n\nthis is called the residual\n\n\n\\[e = \\text{hwy} - \\widehat{\\text{hwy}}\\]"
  },
  {
    "objectID": "slides/lec-4.html#visualizing-residuals",
    "href": "slides/lec-4.html#visualizing-residuals",
    "title": "Simple Linear Regression Models",
    "section": "Visualizing residuals",
    "text": "Visualizing residuals\n\n\n\n\nBlack circles: Observed values (\\(\\text{hwy}\\))\nPink solid line: Least-squares regression line\nMaroon triangles: Predicted values (\\(\\widehat{\\text{hwy}}\\))\n\nGray lines: Residuals"
  },
  {
    "objectID": "slides/lec-4.html#residual-plot",
    "href": "slides/lec-4.html#residual-plot",
    "title": "Simple Linear Regression Models",
    "section": "Residual plot",
    "text": "Residual plot\n\nd %>%\n  mutate(\n    hwy_hat = 1 + 1.3 * cty, # prediction\n    resid   = hwy - hwy_hat  # residual\n    ) %>%\n  ggplot() +\n  geom_point(aes(cty, resid)) +\n  geom_abline(intercept = 0, slope = 0, col = \"red\")"
  },
  {
    "objectID": "slides/lec-4.html#assessing-linearity-with-residual-plots",
    "href": "slides/lec-4.html#assessing-linearity-with-residual-plots",
    "title": "Simple Linear Regression Models",
    "section": "Assessing linearity with residual plots",
    "text": "Assessing linearity with residual plots\n\nSource: IMS"
  },
  {
    "objectID": "slides/lec-4.html#section-4",
    "href": "slides/lec-4.html#section-4",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Group exercise - residuals\n\n\nExercises 7.1, 7.17, 7.19\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-4.html#good-estimates",
    "href": "slides/lec-4.html#good-estimates",
    "title": "Simple Linear Regression Models",
    "section": "Good estimates",
    "text": "Good estimates\nWe want to choose estimates that give a model that fits the data well.\n\na model with a regression line that is close to the data\n\n\nWe want to minimize the residuals."
  },
  {
    "objectID": "slides/lec-4.html#minimizing-residuals",
    "href": "slides/lec-4.html#minimizing-residuals",
    "title": "Simple Linear Regression Models",
    "section": "Minimizing residuals",
    "text": "Minimizing residuals\nPerhaps the most natural thing to do is to find the values of \\(\\beta_0\\) and \\(\\beta_1\\) that minimize the sum of absolute residuals\n\\[\n|e_1|+|e_2|+\\dots+|e_n|\n\\]\n\nFor practical reasons, the sum of squared residuals (SSR) is a more common criterion\n\\[\ne_1^2+e_2^2+\\dots+e_n^2\n\\]"
  },
  {
    "objectID": "slides/lec-4.html#why-squaring-the-residuals",
    "href": "slides/lec-4.html#why-squaring-the-residuals",
    "title": "Simple Linear Regression Models",
    "section": "Why squaring the residuals?",
    "text": "Why squaring the residuals?\n\nnice mathematical properties\n\ncan work by hand (pre-computer era; first derived by Gauss in the late 1700s (Stigler, 1981))\n\n\nreflects the assumptions that being off by \\(4\\) is more than twice as bad as being off by \\(2\\)\n\nmainstream, e.g.¬†the command lm in R."
  },
  {
    "objectID": "slides/lec-4.html#least-square-estimates",
    "href": "slides/lec-4.html#least-square-estimates",
    "title": "Simple Linear Regression Models",
    "section": "Least-square estimates",
    "text": "Least-square estimates\nWe simply find the values for \\(\\beta_0\\) and \\(\\beta_1\\) that minimize the SSR with the R command lm\n\nm <- lm(hwy ~ cty, data = d) # find least-square estimates\nm\n\n\nCall:\nlm(formula = hwy ~ cty, data = d)\n\nCoefficients:\n(Intercept)          cty  \n      0.892        1.337  \n\n\nThe symbols \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) denote least-square estimates.\nIn our model, we therefore have \\[\\hat{\\beta}_0 = 0.892, \\qquad \\hat{\\beta}_1 = 1.337\\]"
  },
  {
    "objectID": "slides/lec-4.html#visualizing-the-least-square-regression-line",
    "href": "slides/lec-4.html#visualizing-the-least-square-regression-line",
    "title": "Simple Linear Regression Models",
    "section": "Visualizing the least square regression line",
    "text": "Visualizing the least square regression line\n\nggplot(d) +\n  geom_point(aes(x = cty, y = hwy)) +\n  geom_abline(intercept = 0.892, slope = 1.337, col = \"red\")"
  },
  {
    "objectID": "slides/lec-4.html#reading-r-output",
    "href": "slides/lec-4.html#reading-r-output",
    "title": "Simple Linear Regression Models",
    "section": "Reading R output",
    "text": "Reading R output\nR can provide the results of a model in different formats.\n\nm <- lm(hwy ~ cty, data = d)\n\n\n\nEstimates only\nRaw R output\nTidy R output\n\n\n\n\nm\n\n\nCall:\nlm(formula = hwy ~ cty, data = d)\n\nCoefficients:\n(Intercept)          cty  \n      0.892        1.337  \n\n\nPrinting the model itself provides the least-square estimates. This is sufficient for now.\n\n\n\nsummary(m)\n\n\nCall:\nlm(formula = hwy ~ cty, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.3408 -1.2790  0.0214  1.0338  4.0461 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.89204    0.46895   1.902   0.0584 .  \ncty          1.33746    0.02697  49.585   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.752 on 232 degrees of freedom\nMultiple R-squared:  0.9138,    Adjusted R-squared:  0.9134 \nF-statistic:  2459 on 1 and 232 DF,  p-value: < 2.2e-16\n\n\nThis format contains information that will be useful when we do inference. It is, however, difficult to read.\n\n\n\nsummary(m) %>%\n  tidy() %>%\n  kable(digits = 2)\n\n\n\n term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n\n\n (Intercept) \n    0.89 \n    0.47 \n    1.90 \n    0.06 \n  \n\n cty \n    1.34 \n    0.03 \n    49.58 \n    0.00 \n  \n\n\n\n\nThis format contains the information necessary for doing inference and is easy to read. This is the format used the textbook."
  },
  {
    "objectID": "slides/lec-4.html#exploring-the-model",
    "href": "slides/lec-4.html#exploring-the-model",
    "title": "Simple Linear Regression Models",
    "section": "Exploring the model",
    "text": "Exploring the model\nThe command augment from the R package broom gives us the residuals (.resid) and predictions (.fitted).\n\nlibrary(broom)\nm <- lm(hwy ~ cty, data = d)\naugment(m)[,1:4]\n\n# A tibble: 234 x 4\n     hwy   cty .fitted .resid\n   <int> <int>   <dbl>  <dbl>\n 1    29    18    25.0 4.03  \n 2    29    21    29.0 0.0214\n 3    31    20    27.6 3.36  \n 4    30    21    29.0 1.02  \n 5    26    16    22.3 3.71  \n 6    26    18    25.0 1.03  \n 7    27    18    25.0 2.03  \n 8    26    18    25.0 1.03  \n 9    25    16    22.3 2.71  \n10    28    20    27.6 0.359 \n# ... with 224 more rows"
  },
  {
    "objectID": "slides/lec-4.html#section-5",
    "href": "slides/lec-4.html#section-5",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Group exercise - exploring a model\n\n\nConsider the third observation in the sample. What is its\n\nvalue of cty?\npredicted value for hwy based on the model?\nactual value for hwy?\nresidual?\nDoes the model over- or under-predict?\n\n\n\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lec-4.html#intepreting-the-parameters",
    "href": "slides/lec-4.html#intepreting-the-parameters",
    "title": "Simple Linear Regression Models",
    "section": "Intepreting the parameters",
    "text": "Intepreting the parameters\n\nthe intercept estimate \\(\\hat{\\beta}_0\\) is the prediction for a car with \\(\\text{cty} = 0\\)\n\nmeaningless in our case\n\n\n\n\n\nthe slope estimate \\(\\hat{\\beta}_1\\) is the increase in a our prediction for hwy for each additional unit of cty\n\n‚Äúfor each additional unit of cty, we expect hwy to increase by 1.337‚Äù\n\n\n\n\n\n\n\n\n\n\n\nExtrapolation\n\n\n\nStick to the range of the data\n\nif you extrapolate, do so with care, not like this.\n\n\nThe intercept will not always be meaningful"
  },
  {
    "objectID": "slides/lec-4.html#section-6",
    "href": "slides/lec-4.html#section-6",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Group exercise - least-square estimates\n\n\nExercise 7.21\n\nskip part c\nstart by fitting the model in R with the following command,\n\n\nd <- openintro::coast_starlight\nm <- lm(travel_time ~ dist, data = d)\n\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-4.html#special-case-categorical-predictor",
    "href": "slides/lec-4.html#special-case-categorical-predictor",
    "title": "Simple Linear Regression Models",
    "section": "Special case: categorical predictor",
    "text": "Special case: categorical predictor\nLet us create a binary predictor indicating if the car is from \\(1999\\).\n\nd_binary <- mutate(d, year_binary = if_else(year == 1999, 1, 0))\nhead(select(d_binary, hwy, year, year_binary))\n\n# A tibble: 6 x 3\n    hwy  year year_binary\n  <int> <int>       <dbl>\n1    29  1999           1\n2    29  1999           1\n3    31  2008           0\n4    30  2008           0\n5    26  1999           1\n6    26  1999           1\n\n\nThe variable year_binary takes the value \\(1\\) if the car is from \\(1999\\) and \\(0\\) otherwise."
  },
  {
    "objectID": "slides/lec-4.html#section-7",
    "href": "slides/lec-4.html#section-7",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "m_binary <- lm(hwy ~ year_binary, data = d_binary)\nm_binary\n\n\nCall:\nlm(formula = hwy ~ year_binary, data = d_binary)\n\nCoefficients:\n(Intercept)  year_binary  \n   23.45299     -0.02564  \n\n\nThe model equation is\n\\[\n\\text{hwy} \\approx 23.46 - 0.026 \\text{year_binary}\n\\]\n\nFor a new car from \\(1999\\), the variable year_binary takes the value \\(1\\) and our prediction is\n\\[\n\\widehat{\\text{hwy}} = 23.46 - 0.026*1 = 23.46 - 0.026 = 23.434\n\\]\n\n\nWhile for a car that not from \\(1999\\), the variable year_binary takes the value \\(0\\) and our prediction is\n\\[\n\\widehat{\\text{hwy}} = 23.46 - 0.026*0 = 23.46 - 0 = 23.46\n\\]"
  },
  {
    "objectID": "slides/lec-4.html#alternative-model",
    "href": "slides/lec-4.html#alternative-model",
    "title": "Simple Linear Regression Models",
    "section": "Alternative model",
    "text": "Alternative model\nLet us fit an alternative model using engine size (disp) as a predictor\n\\[\n\\text{hwy} \\approx \\beta_0 + \\beta_1 \\text{displ}\n\\]\n\nggplot(d) +\n  geom_point(aes(displ, hwy))"
  },
  {
    "objectID": "slides/lec-4.html#section-8",
    "href": "slides/lec-4.html#section-8",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "The least-square estimates for the coefficients are\n\nlm(hwy ~ displ, data = d)\n\n\nCall:\nlm(formula = hwy ~ displ, data = d)\n\nCoefficients:\n(Intercept)        displ  \n     35.698       -3.531  \n\n\nNote that the slope coefficient is negative; which makes sense since we would expect cars with larger engines to be less efficient."
  },
  {
    "objectID": "slides/lec-4.html#section-9",
    "href": "slides/lec-4.html#section-9",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "We now have two models. Which is the best?\n\n\nWe could start by looking at the residuals"
  },
  {
    "objectID": "slides/lec-4.html#comparing-residuals",
    "href": "slides/lec-4.html#comparing-residuals",
    "title": "Simple Linear Regression Models",
    "section": "Comparing residuals",
    "text": "Comparing residuals\n\n\n\nm1 <- lm(hwy ~ cty, data = d)\nm_augment <- augment(m1)\nggplot(m_augment) +\n  geom_histogram(aes(.resid)) +\n  xlim(-15, 15)\n\n\n\n\n\n\n\n\n\nlm(hwy ~ displ, data = d) %>%\n  augment %>%\n  ggplot() +\n  geom_histogram(aes(.resid)) +\n  xlim(-15, 15)\n\n\n\n\n\n\n\n\n\n\nThe first model seems to have smaller residuals.\n\\(\\Rightarrow\\) choose the first model!"
  },
  {
    "objectID": "slides/lec-4.html#comparing-models-in-a-systematic-way",
    "href": "slides/lec-4.html#comparing-models-in-a-systematic-way",
    "title": "Simple Linear Regression Models",
    "section": "Comparing models in a systematic way",
    "text": "Comparing models in a systematic way\nBut looking at a plot can be misleading\n\nillusions\ndifficult to compare models with similar residuals\n\n\nWe need a more systematic approach for comparing models."
  },
  {
    "objectID": "slides/lec-4.html#ssr",
    "href": "slides/lec-4.html#ssr",
    "title": "Simple Linear Regression Models",
    "section": "SSR",
    "text": "SSR\nInstead of comparing histograms of residuals, we can compute the SSR (sum of squared residuals!)\n\\[\\begin{align*}\nSSR\n& = r_1^2+r_2^2+\\dots+r^2_n \\\\\n& = (y_1 - \\hat{y}_1)^2 + (y_2 - \\hat{y}_2)^2 + \\dots + (y_n - \\hat{y}_n)^2\n\\end{align*}\\]\n\nsmall residuals will give a small SSR\nlarge residuals will give a large SSR\n\n\n\\(\\Rightarrow\\) choose the model with the smaller SSR!\n\n\nüìã The textbook uses the term SSE (sum of squared errors)."
  },
  {
    "objectID": "slides/lec-4.html#section-10",
    "href": "slides/lec-4.html#section-10",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "SSR of the first model:\n\nm1 <- lm(hwy ~ cty, data = d)\nm_augment <- augment(m1)\nresid <- m_augment$.resid\nsum(resid^2)\n\n[1] 712.3599\n\n\nSSR of the second model:\n\nlm(hwy ~ displ, data = d) %>%\n  augment %>% \n  .[[\".resid\"]] %>% \n  .^2 %>% \n  sum\n\n[1] 3413.829\n\n\n\nWe opt for the first model (smaller SSR)."
  },
  {
    "objectID": "slides/lec-4.html#r2",
    "href": "slides/lec-4.html#r2",
    "title": "Simple Linear Regression Models",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nWhile the SSR is useful for comparing models, it can also be used to describe the goodness of fit of the model.\n\nThe SST (total sum of squares) is the sum of squared distance to the mean.\n\\[\nSST = (y_1 - \\bar{y})^2 + (y_2 - \\bar{y})^2 + \\dots + (y_n - \\bar{y})^2\n\\]\nIt measures the total amount of variability in the data.\n\n\nRemember the formula for SSR\n\\[\nSSR = (y_1 - \\hat{y}_1)^2 + (y_2 - \\hat{y}_2)^2 + \\dots + (y_n - \\hat{y}_n)^2\n\\]\nIt measures the amount of variability in the data left unexplained by the model.\n\n\n\\(SST - SSR\\) (total - residual) is therefore the amount of variation explained by the model:\n\\[\n\\text{data} = SST = (SST-SSR) + SSR = \\text{model} + \\text{residuals}\n\\]"
  },
  {
    "objectID": "slides/lec-4.html#section-11",
    "href": "slides/lec-4.html#section-11",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "The statistic \\(R^2\\) measures the proportion of variation in the data that is explained by the model.\n\\[\n\\begin{align*}\nR^2\n& = 1-\\dfrac{SSR}{SST}\\\\\n& = \\dfrac{SST-SSR}{SST} \\\\\n& = \\dfrac{\\text{var. explained by model}}{\\text{total var.}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/lec-4.html#section-12",
    "href": "slides/lec-4.html#section-12",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Note that \\(0\\le R^2 \\le 1\\).\n\ngood model \\(\\Rightarrow\\) small residuals \\(\\Rightarrow\\) small SSR \\(\\Rightarrow\\) large \\(R^2\\).\ngreat model \\(\\Rightarrow\\) tiny residuals \\(\\Rightarrow\\) tiny SSR \\(\\Rightarrow\\) \\(R^2\\) close to 1.\npoor model \\(\\Rightarrow\\) large residuals \\(\\Rightarrow\\) SSR almost as large as SST \\(\\Rightarrow\\) \\(R^2\\) close to 0."
  },
  {
    "objectID": "slides/lec-4.html#computing-r2-in-r",
    "href": "slides/lec-4.html#computing-r2-in-r",
    "title": "Simple Linear Regression Models",
    "section": "Computing \\(R^2\\) in R\n",
    "text": "Computing \\(R^2\\) in R\n\nTo compute \\(R^2\\) in R, simply use the command glance.\n\nm1 <- lm(hwy ~ cty, data = d)\nm_glance <- glance(m1)\nm_glance$r.squared\n\n[1] 0.9137752\n\nlm(hwy ~ displ, data = d) %>% \n  glance %>% \n  .[[\"r.squared\"]]\n\n[1] 0.5867867\n\n\nThe model with cty as a predictor has a \\(R^2\\) value of \\(0.914\\), and the model that uses displ has a \\(R^2\\) of \\(0.59\\) (worse).\n\nThe first model is better!"
  },
  {
    "objectID": "slides/lec-4.html#section-13",
    "href": "slides/lec-4.html#section-13",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Group exercise - Interpretation\n\n\n\nExercise 7.23\n\nfit the model in R; do you obtain the same estimates?\ndo parts a-d\ncompute the SST, SSR and \\(R^2\\) ‚Äúby hand‚Äù in R (do not use glance). You can use the command augment to compute the residuals.\n\n\n\n\nd <- usdata::county_2019\nm <- lm(. . .)\nm_augment <- augment(m)\nSST <- ...\n\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-4.html#section-14",
    "href": "slides/lec-4.html#section-14",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Group exercise - outlier\n\n\n\nLook at the scatterplot for the mpg data set. Are there outliers?\n\n\nggplot(d) +\n  geom_point(aes(cty, hwy))\n\n\n\nExercise 7.25\n\n\n\n\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lec-4.html#outliers-leverage-and-influential-points",
    "href": "slides/lec-4.html#outliers-leverage-and-influential-points",
    "title": "Simple Linear Regression Models",
    "section": "Outliers, leverage and influential points",
    "text": "Outliers, leverage and influential points\n\noutliers: observations that fall far from the cloud of points;\nhigh leverage points: observations that fall horizontally away from the cloud of points;\ninfluential points: observations that influence the slope of the regression line;\n\n\n\nAll influential points are high leverage points.\nAll leverage points are outliers.\n(Venn Diagram)"
  },
  {
    "objectID": "slides/lec-4.html#section-15",
    "href": "slides/lec-4.html#section-15",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Source: IMS"
  },
  {
    "objectID": "slides/lec-4.html#section-16",
    "href": "slides/lec-4.html#section-16",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "Group exercise - outlier\n\n\nExercise 7.27\n\n\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lec-4.html#least-square-estimates-are-not-robust",
    "href": "slides/lec-4.html#least-square-estimates-are-not-robust",
    "title": "Simple Linear Regression Models",
    "section": "Least-square estimates are not robust",
    "text": "Least-square estimates are not robust\nIn regression, outliers have the potential to highly influence the least-square estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\).\n\n\n\n\n\n\nWarning\n\n\nLeast-square estimates are not robust to the presence of outliers.\n\n\n\n\nEstimates that are robust include (not covered in this class)\n\nleast absolute deviation estimates, which minimize the SAR (sum of absolute residuals) instead of the SSR\n\n\\[\nSAR = |e_1| + |e_2| + \\dots + |e_n|\n\\]\n\nBayesian estimates (STA360)"
  },
  {
    "objectID": "slides/lec-4.html#impact-of-outliers",
    "href": "slides/lec-4.html#impact-of-outliers",
    "title": "Simple Linear Regression Models",
    "section": "Impact of outliers",
    "text": "Impact of outliers\nLet us contaminate the data with an outlier (cty \\(=10\\) and hwy \\(=1000\\))\n\nd_contaminated <- select(d, cty, hwy) %>%\n  add_row(cty = 40, hwy = 500) # add outlier\narrange(d_contaminated, desc(hwy)) %>% slice(1:5)\n\n# A tibble: 5 x 2\n    cty   hwy\n  <dbl> <dbl>\n1    40   500\n2    33    44\n3    35    44\n4    29    41\n5    28    37\n\n\n\n‚Ä¶and compare the two regression models.\n\nlm(hwy ~ cty, data = d)\n\n\nCall:\nlm(formula = hwy ~ cty, data = d)\n\nCoefficients:\n(Intercept)          cty  \n      0.892        1.337  \n\nlm(hwy ~ cty, data = d_contaminated)\n\n\nCall:\nlm(formula = hwy ~ cty, data = d_contaminated)\n\nCoefficients:\n(Intercept)          cty  \n    -33.841        3.498  \n\n\n\n\nThe slope estimate has almost tripled!"
  },
  {
    "objectID": "slides/lec-4.html#section-17",
    "href": "slides/lec-4.html#section-17",
    "title": "Simple Linear Regression Models",
    "section": "",
    "text": "ggplot(d_contaminated) +\n  geom_point(aes(cty, hwy)) +\n  geom_abline(intercept = -33.841, slope = 3.498, col = \"purple\")\n\n\nThe regression line not longer fits the data well."
  },
  {
    "objectID": "slides/lec-4.html#recap-1",
    "href": "slides/lec-4.html#recap-1",
    "title": "Simple Linear Regression Models",
    "section": "Recap",
    "text": "Recap\n\nsimple linear regression model\n\n\\[\n    \\text{hwy} \\approx \\beta_0 + \\beta_1 \\text{cty}\n\\]\n\nresiduals\nleast-square estimates\nparameter interpretation\nmodel comparison with \\(R^2\\)\n\noutliers\n\n\n\n\nhttps://rmorsomme.github.io/website/"
  },
  {
    "objectID": "slides/lec-5.html#announcements",
    "href": "slides/lec-5.html#announcements",
    "title": "Multiple Linear Regression Models",
    "section": "Announcements",
    "text": "Announcements\n\nassignments"
  },
  {
    "objectID": "slides/lec-5.html#recap",
    "href": "slides/lec-5.html#recap",
    "title": "Multiple Linear Regression Models",
    "section": "Recap",
    "text": "Recap\n\n\nsimple linear regression model \\[\n\\text{hwy} \\approx \\beta_0 + \\beta_1 \\text{cty}\n\\]\n\nresiduals\nleast-square estimates\nparameter interpretation\nmodel comparison with \\(R^2\\)\n\noutliers"
  },
  {
    "objectID": "slides/lec-5.html#outline",
    "href": "slides/lec-5.html#outline",
    "title": "Multiple Linear Regression Models",
    "section": "Outline",
    "text": "Outline\n\nmultiple linear regression\nfeature engineering\nmodel comparison\npredictive performance"
  },
  {
    "objectID": "slides/lec-5.html#the-mpg-data-set",
    "href": "slides/lec-5.html#the-mpg-data-set",
    "title": "Multiple Linear Regression Models",
    "section": "The mpg data set",
    "text": "The mpg data set\n\nd <- ggplot2::mpg\nhead(d, n = 4)\n\n# A tibble: 4 x 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  <chr>        <chr> <dbl> <int> <int> <chr>      <chr> <int> <int> <chr> <chr> \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa~\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa~\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa~\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa~\n\n\nInstead of fitting a model with only cty or only displ, we could fit a linear regression model with both predictors!"
  },
  {
    "objectID": "slides/lec-5.html#linear-regression-with-2-predictors",
    "href": "slides/lec-5.html#linear-regression-with-2-predictors",
    "title": "Multiple Linear Regression Models",
    "section": "Linear regression with 2 predictors",
    "text": "Linear regression with 2 predictors\nThe model equation is\n\\[\n\\text{hwy} \\approx \\beta_0 + \\beta_1 \\text{cty} + \\beta_2 \\text{displ}\n\\]\nWe can find the least-square estimates (minimizing the SSR) with the command lm\n\nlm(hwy ~ cty + displ, data = d)\n\n\nCall:\nlm(formula = hwy ~ cty + displ, data = d)\n\nCoefficients:\n(Intercept)          cty        displ  \n    1.15145      1.32914     -0.03432  \n\n\nwhich give the following regression equation\n\\[\n\\text{hwy} \\approx 1.15 + 1.33 \\text{cty} - 0.034  \\text{displ}\n\\]"
  },
  {
    "objectID": "slides/lec-5.html#interpretation",
    "href": "slides/lec-5.html#interpretation",
    "title": "Multiple Linear Regression Models",
    "section": "Interpretation",
    "text": "Interpretation\n\nInterpreting \\(\\hat{\\beta}_1 = 1.33\\):\n\n‚ÄúKeeping displ constant, for each additional unit in cty, we would expect hwy to be higher, on average, by 1.33 units.‚Äù\n\n\n\n\n\nInterpreting \\(\\hat{\\beta}_2 = -0.034\\):\n\n‚ÄúKeeping cty constant, for each additional unit in displ, we would expect hwy to be lower, on average, by 0.034 unit.‚Äù\n\n\n\n\n\n\nInterpreting \\(\\hat{\\beta}_0 = 1.15\\):\n\n‚ÄúFor a car with cty and displ equal to 0, we would expect hwy to be 1.15.‚Äù\nmeaningless in this context."
  },
  {
    "objectID": "slides/lec-5.html#special-case-categorical-predictor",
    "href": "slides/lec-5.html#special-case-categorical-predictor",
    "title": "Multiple Linear Regression Models",
    "section": "Special case: categorical predictor",
    "text": "Special case: categorical predictor\nIn a regression model, categorical predictors are represented using indicator variables.\nTo represent a categorical predictor with \\(k\\) levels (categories), we use \\((k-1)\\) indicator variables.\n(advanced topic: identifiability)"
  },
  {
    "objectID": "slides/lec-5.html#including-drv",
    "href": "slides/lec-5.html#including-drv",
    "title": "Multiple Linear Regression Models",
    "section": "Including drv\n",
    "text": "Including drv\n\nFor instance, the categorical variable drv has \\(k=3\\) levels (4, f and r), so we can represent it with \\(3-1=2\\) indicator variables with the following model equation\n\\[\n\\text{hwy} \\approx \\beta_0 + \\beta_1 \\text{drv_f} + \\beta_2 \\text{drv_r}\n\\]\n\n\n\n\n\n\n\nTip\n\n\nFor a binary variable \\(k=2\\), so we only need \\(k-1=1\\) indicator variable.\nFor instance, to include the binary variable year_binary, we only added a single indicator variable to the model."
  },
  {
    "objectID": "slides/lec-5.html#using-categorical-predictors-in-r",
    "href": "slides/lec-5.html#using-categorical-predictors-in-r",
    "title": "Multiple Linear Regression Models",
    "section": "Using categorical predictors in R\n",
    "text": "Using categorical predictors in R\n\n\nlm(hwy ~ drv, data = d)\n\n\nCall:\nlm(formula = hwy ~ drv, data = d)\n\nCoefficients:\n(Intercept)         drvf         drvr  \n     19.175        8.986        1.825  \n\n\nThe model equation with the least-square estimates is \\[\n\\text{hwy} \\approx 19.175 + 8.986 \\text{drv_f} + 1.825 \\text{drv_r}\n\\]"
  },
  {
    "objectID": "slides/lec-5.html#interpreting-the-output",
    "href": "slides/lec-5.html#interpreting-the-output",
    "title": "Multiple Linear Regression Models",
    "section": "Interpreting the output",
    "text": "Interpreting the output\n\\[\n\\text{hwy} \\approx 19.175 + 8.986 \\text{drv_f} + 1.825 \\text{drv_r}\n\\]\nIf a new vehicle has a drv that is:\n\n\n4, then the two indicator variables drv_f and drv_r take the value 0, and the prediction is \\(\\widehat{hwy} = 19.175\\)\n\n\n\n\n\nf, then the indicator variables drv_f takes the value 1 and drv_r the value 0, and the prediction is \\(\\widehat{hwy} = 19.175 + 8.986 = 28.161\\)\n\n\n\n\n\n\nr, then the indicator variables drv_f takes the value 0 and drv_r the value 1, and the prediction is \\(\\widehat{hwy} = 19.175 + 1.825 = 21\\)\n\n\n\n\nThe level 4 is called the reference level."
  },
  {
    "objectID": "slides/lec-5.html#section",
    "href": "slides/lec-5.html#section",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "Group exercise - categorical predictor\n\n\n\nExercises 8.5, 8.7\n\nIn addition\n\nidentify the baseline level of the categorical variable in each model.\n\n\nlibrary(openintro)\nd <- openintro::births14\n\n\nfit the first models in R\n\n\n\n\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-5.html#fitting-a-larger-model",
    "href": "slides/lec-5.html#fitting-a-larger-model",
    "title": "Multiple Linear Regression Models",
    "section": "Fitting a larger model",
    "text": "Fitting a larger model\nLet us fit a model with cty, drv and disp\n\nm_larger <- lm(hwy ~ cty + drv + displ, data = d)\nm_larger\n\n\nCall:\nlm(formula = hwy ~ cty + drv + displ, data = d)\n\nCoefficients:\n(Intercept)          cty         drvf         drvr        displ  \n      3.424        1.157        2.158        2.360       -0.208  \n\n\nIts \\(R^2\\) is 0.938.\n\nglance(m_larger)$r.squared\n\n[1] 0.9384357\n\n\n\nUnsurprisingly, including additional predictors makes the regression line closer to the points \\(\\Rightarrow\\) residuals are smaller \\(\\Rightarrow\\) SSR is smaller \\(\\Rightarrow\\) \\(R^2\\) is larger."
  },
  {
    "objectID": "slides/lec-5.html#section-1",
    "href": "slides/lec-5.html#section-1",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "Group exercise - computing \\(R^2\\) by hand\n\n\n\nWhat is the formula for \\(R^2\\)?\nCompute \\(R^2\\) by hand in R (do not use glance). You can use the following code.\n\n\nd <- ggplot2::mpg\nm_larger <- lm(hwy ~ cty + drv + displ, data = d)\nm_augment <- augment(m_larger)\n\n\n\n\n\n\n\n04:00"
  },
  {
    "objectID": "slides/lec-5.html#fitting-the-full-model",
    "href": "slides/lec-5.html#fitting-the-full-model",
    "title": "Multiple Linear Regression Models",
    "section": "Fitting the full1 model",
    "text": "Fitting the full1 model\n\nm_full <- lm(hwy ~ manufacturer + displ + year + cyl + trans + drv + cty + fl + class, data = d)\n\nThanks to the additional predictors, the residuals are very small, making \\(R^2\\) close to \\(1\\).\n\nglance(m_full)$r.squared\n\n[1] 0.9773386\n\n\n\nWe will see in the next lecture that this is not always a good sign.\n\nThis not exactly the full model since I do not include the variable model for the following technical reason. By including the variable model along with the other ones, we obtain perfect collinearity, making the model unidentifiable"
  },
  {
    "objectID": "slides/lec-5.html#section-2",
    "href": "slides/lec-5.html#section-2",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "Group exercise - multiple linear regression\n\n\nExercise 8.9\n\nfit the model in R\n\nidentify the type of each variable\nidentify the baseline level of the categorical predictors\ndo parts a-d\n\n\nlibrary(openintro)\nd_birth <- openintro::births14\n\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-5.html#feature-engineering",
    "href": "slides/lec-5.html#feature-engineering",
    "title": "Multiple Linear Regression Models",
    "section": "Feature engineering",
    "text": "Feature engineering\nWe saw that adding predictors to the model seems to help.\nHowever, the variables included in the data set, e.g.¬†displ, year, etc, may not be the most useful predictors for hwy.\n\nFeature engineering refers to the creation of new predictors from existing ones.\n\n\n\n\n\n\n\n\nTip\n\n\nThis is where your understanding of the data, scientific knowledge, etc, makes a big difference."
  },
  {
    "objectID": "slides/lec-5.html#transforming-a-variable",
    "href": "slides/lec-5.html#transforming-a-variable",
    "title": "Multiple Linear Regression Models",
    "section": "Transforming a variable",
    "text": "Transforming a variable\nConsider the predictor displ\n\nggplot(d) +\n  geom_point(aes(displ, hwy))\n\n\n\nThe relation bwteen displ and hwy is not exactly linear."
  },
  {
    "objectID": "slides/lec-5.html#section-3",
    "href": "slides/lec-5.html#section-3",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "Let us include the predictor \\(\\dfrac{1}{\\text{displ}}\\) to capture this nonlinear relation.\nHere is the model equation\n\\[\n\\text{hwy} \\approx \\beta_0+ \\beta_1 \\text{displ} + \\beta_2 \\dfrac{1}{\\text{displ}}\n\\]\nThe least-square coefficient estimates are\n\nd_transf <- mutate(d, displ_inv = 1/displ)\nm <- lm(hwy ~ displ + displ_inv, data = d_transf)\nm\n\n\nCall:\nlm(formula = hwy ~ displ + displ_inv, data = d_transf)\n\nCoefficients:\n(Intercept)        displ    displ_inv  \n    12.2601      -0.2332      36.1456"
  },
  {
    "objectID": "slides/lec-5.html#section-4",
    "href": "slides/lec-5.html#section-4",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "And the regression lines captures the nonlinear relation.\n\naugment(m) %>%\n  ggplot(aes(displ, hwy)) +\n  geom_point() +\n  geom_line(aes(y = .fitted))"
  },
  {
    "objectID": "slides/lec-5.html#the-trees-data-set",
    "href": "slides/lec-5.html#the-trees-data-set",
    "title": "Multiple Linear Regression Models",
    "section": "The trees data set",
    "text": "The trees data set\n\n\n\nMeasurements of the diameter, height and volume of timber in 31 felled black cherry trees.\nNote that the diameter (in inches) is erroneously labelled Girth in the data\nThe diameter (Girth) is measured at 4 ft 6 in above the ground.\nSource: Atkinson, A. C. (1985) Plots, Transformations and Regression. Oxford University Press."
  },
  {
    "objectID": "slides/lec-5.html#combining-variables",
    "href": "slides/lec-5.html#combining-variables",
    "title": "Multiple Linear Regression Models",
    "section": "Combining variables",
    "text": "Combining variables\nTransforming a variable may be helpful ‚Ä¶but we can go a step further!\n\nWe can construct new predictors by combining existing variables.\n\n\nConsider the trees dataset\n\nd_tree <- datasets::trees\nhead(d_tree, n = 4)\n\n  Girth Height Volume\n1   8.3     70   10.3\n2   8.6     65   10.3\n3   8.8     63   10.2\n4  10.5     72   16.4\n\n\nwhere Girth indicates the tree diameter (twice the radius) in inches."
  },
  {
    "objectID": "slides/lec-5.html#section-5",
    "href": "slides/lec-5.html#section-5",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "Suppose we want to estimate Volume (expensive to measure) from Girth and Height (cheap to measure).\n\nYou might decide to approximate the shape of a tree with a shape that is between a cylinder and a cone.\nFrom geometry, we know that the volume of a cylinder is\n\\[\nV = \\pi r^2 h\n\\]\nand that of a cone is\n\\[\nV = \\frac{1}{3} \\pi r^2 h\n\\]"
  },
  {
    "objectID": "slides/lec-5.html#section-6",
    "href": "slides/lec-5.html#section-6",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "This suggests approximating the volume of a tree with the following model\n\\[\n\\text{Volume} = \\beta_1 \\left[ \\left(\\dfrac{\\text{Girth}}{2}\\right)^2 * \\text{Height}\\right] = \\beta_1X\n\\]\nwhere\n\n\n\\(\\beta_1\\) is an unknown parameter that we expect to be between \\(\\pi\\) (pure cylinder) and \\(\\frac{1}{3}\\pi\\) (pure cone)\n\n\\(X = \\left(\\dfrac{\\text{Girth}}{2}\\right)^2 * \\text{Height}\\) is our predictor, which we construct from existing variables."
  },
  {
    "objectID": "slides/lec-5.html#section-7",
    "href": "slides/lec-5.html#section-7",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "To accomplish this, we simply need to create a new variable corresponding to \\(\\left(\\dfrac{\\text{Girth}}{2}\\right)^2 * \\text{Height}\\).\nBut before doing that, we have to transform Girth into feet to ensure that all variables have the same units.\n\nd_tree_comb <- d_tree %>%\n  mutate(\n    Girth_ft    = Girth / 12,\n    radius      = Girth_ft / 2,\n    r_squared   = radius^2,\n    r2h = r_squared * Height\n  )\nhead(d_tree_comb, n = 3)\n\n  Girth Height Volume  Girth_ft    radius r_squared      r2h\n1   8.3     70   10.3 0.6916667 0.3458333 0.1196007 8.372049\n2   8.6     65   10.3 0.7166667 0.3583333 0.1284028 8.346181\n3   8.8     63   10.2 0.7333333 0.3666667 0.1344444 8.470000"
  },
  {
    "objectID": "slides/lec-5.html#section-8",
    "href": "slides/lec-5.html#section-8",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "My model does not include an intercept. To exclude the intercept from the model, I use -1 in the lm command.\n\nm <- lm(Volume ~ r2h - 1, data = d_tree_comb)\nm\n\n\nCall:\nlm(formula = Volume ~ r2h - 1, data = d_tree_comb)\n\nCoefficients:\n  r2h  \n1.214  \n\n\n\nThis is between the two anticipated bounds \\(\\pi=3.14\\) and \\(\\frac{\\pi}{3}=1.047\\).\n\n\n\n\n\n\n\n\nWarning\n\n\nWhen we do not include the intercept in a model, \\(R^2\\) measures something different and should therefore not be interpreted in the usual way.\n\n\n\n\nglance(m)$r.squared\n\n[1] 0.9950219"
  },
  {
    "objectID": "slides/lec-5.html#comparison-with-the-full-model",
    "href": "slides/lec-5.html#comparison-with-the-full-model",
    "title": "Multiple Linear Regression Models",
    "section": "Comparison with the full model",
    "text": "Comparison with the full model\nAlthough \\(R^2\\) has a different meaning when there is no intercept, it can be still used for comparison1.\n\n\nm_full <- lm(Volume ~ Girth + Height -1, data = d_tree)\nglance(m_full)$r.squared\n\n[1] 0.9696913\n\n\nOur new variable \\(\\left(\\dfrac{\\text{Girth}}{2}\\right)^2 * \\text{Height}\\) improves the model!\n\n\nNote that the full model has two predictors, while our geometry-based model only has a single predictor!\n\n\n\n\n\n\nTip\n\n\nA carefully constructed predictor can do a better job than multiple raw predictors!\n\n\n\n\nas long as both models exclude the intercept"
  },
  {
    "objectID": "slides/lec-5.html#special-case-of-data-combination-interaction",
    "href": "slides/lec-5.html#special-case-of-data-combination-interaction",
    "title": "Multiple Linear Regression Models",
    "section": "Special case of data combination: interaction",
    "text": "Special case of data combination: interaction\n\n\nSuppose you are interested in predicting the average run time (duration) of amateur jogging races.\nTwo variables that impact the duration are (i) the distance of the race, and (ii) the weather.\nFor simplicity, we measure the weather as either good (nice weather) or bad (rain, heat wave, etc)."
  },
  {
    "objectID": "slides/lec-5.html#section-9",
    "href": "slides/lec-5.html#section-9",
    "title": "Multiple Linear Regression Models",
    "section": "",
    "text": "Our model is therefore\n\\[\n\\text{duration} \\approx \\beta_0 + \\beta_1 \\text{distance} + \\beta_2 \\text{weather_bad}\n\\]\nwhere \\(\\beta_1\\) indicate the effect of an additional miles on the expected duration and \\(\\beta_2\\) the effect of bad weather.\nNote that the effect of weather is fixed in this model, say ‚Äú\\(+5\\) minutes‚Äù if \\(\\hat{\\beta}_2 = 5\\).\n\nIs this reasonable? No!\n\n\n\\(\\Rightarrow\\) the effect of weather should vary with distance. For shorter races, bad weather may add only 2 or 3 minutes, while for longer races, bad weather may increase the average duration by 10 or 15 minutes."
  },
  {
    "objectID": "slides/lec-5.html#model-equation-with-interaction",
    "href": "slides/lec-5.html#model-equation-with-interaction",
    "title": "Multiple Linear Regression Models",
    "section": "Model equation with interaction",
    "text": "Model equation with interaction\nWe capture such pattern using an interaction term.\n\\[\n\\text{duration} \\approx \\beta_0 + \\beta_1 \\text{distance} + \\beta_2 \\text{weather_bad} + \\beta_3 \\text{weather_bad}*\\text{distance}\n\\]\n\nWhen the weather is good, the equation simplifies to\n\n\\[\n\\text{duration} \\approx \\beta_0 + \\beta_1 \\text{distance} + \\beta_2 0 + \\beta_3 0*\\text{distance} = \\beta_0 + \\beta_1 \\text{distance}\n\\]\n\nWhen the weather is bad, the equation simplifies to\n\n\\[\n\\text{duration} \\approx \\beta_0 + \\beta_1 \\text{distance} + \\beta_2 1 + \\beta_3 1*\\text{distance} = (\\beta_0 + \\beta_2) + (\\beta_1+\\beta_3) \\text{distance}\n\\]"
  },
  {
    "objectID": "slides/lec-5.html#interpreting-interactions",
    "href": "slides/lec-5.html#interpreting-interactions",
    "title": "Multiple Linear Regression Models",
    "section": "Interpreting interactions",
    "text": "Interpreting interactions\n\nWhen the weather is good, the slope estimate is \\(\\hat{\\beta}_1\\), meaning that the effect of an additional miles on the average duration is \\(\\hat{\\beta}_1\\).\nWhen the weather is bad, the slope estimate is \\(\\hat{\\beta}_1+\\hat{\\beta}_3\\), meaning that the effect of an additional miles on the average duration is \\(\\hat{\\beta}_1+\\hat{\\beta}_3\\) (not \\(\\hat{\\beta}_1\\)).\n\n\n\n\n\n\n\nInteractions\n\n\nThe effect of the distance depends on the weather. Similarly, the effect of the weather depends on the distance.\n\\(\\Rightarrow\\) the two variables interact."
  },
  {
    "objectID": "slides/lec-5.html#recap-2",
    "href": "slides/lec-5.html#recap-2",
    "title": "Multiple Linear Regression Models",
    "section": "Recap",
    "text": "Recap\n\n\nsimple linear regression model \\[\nY \\approx \\beta_0 + \\beta_1 X\n\\]\nmultiple linear regression model \\[\nY \\approx \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots +  + \\beta_p X_p\n\\]\n\ncategorical predictor\n\n\n\\((k-1)\\) indicator variables\n\n\n\nfeature engineering\n\ntransforming variables\ncombining variables\n\n\n\n\n\n\n\nhttps://rmorsomme.github.io/website/"
  },
  {
    "objectID": "slides/lec-6.html#announcements",
    "href": "slides/lec-6.html#announcements",
    "title": "Model Selection",
    "section": "Announcements",
    "text": "Announcements\n\nassignments"
  },
  {
    "objectID": "slides/lec-6.html#recap",
    "href": "slides/lec-6.html#recap",
    "title": "Model Selection",
    "section": "Recap",
    "text": "Recap"
  },
  {
    "objectID": "slides/lec-6.html#a-nonlinear-association",
    "href": "slides/lec-6.html#a-nonlinear-association",
    "title": "Model Selection",
    "section": "a nonlinear association?",
    "text": "a nonlinear association?\nSuppose we want to predict volume using only the variable girth.\n\nd_tree <- datasets::trees\nggplot(d_tree) +\n  geom_point(aes(Girth, Volume))\n\n\nOne could argue that there is a slight nonlinear association"
  },
  {
    "objectID": "slides/lec-6.html#r-function-to-compute-r2",
    "href": "slides/lec-6.html#r-function-to-compute-r2",
    "title": "Model Selection",
    "section": "\nR function to compute \\(R^2\\)\n",
    "text": "R function to compute \\(R^2\\)\n\n\ncompute_R2 <- function(model){\n  \n  model_glanced <- glance(model)\n  R2 <- model_glanced$r.squared\n  R2_rounded <- round(R2, 3) \n  \n  return(R2_rounded)\n  \n}"
  },
  {
    "objectID": "slides/lec-6.html#starting-simple",
    "href": "slides/lec-6.html#starting-simple",
    "title": "Model Selection",
    "section": "Starting simple‚Ä¶",
    "text": "Starting simple‚Ä¶\nWe start with the simple model\n\\[\n\\text{Volume} \\approx \\beta_0 + \\beta_1 \\text{girth}\n\\]\n\nm1 <- lm(Volume ~ Girth, data = d_tree)\ncompute_R2(m1)\n\n[1] 0.935"
  },
  {
    "objectID": "slides/lec-6.html#taking-it-up-a-notch",
    "href": "slides/lec-6.html#taking-it-up-a-notch",
    "title": "Model Selection",
    "section": "‚Ä¶taking it up a notch‚Ä¶",
    "text": "‚Ä¶taking it up a notch‚Ä¶\nTo capture the nonlinear association between Girth and Volume, we consider the predictor \\(\\text{Girth}^2\\).\n\\[\n\\text{Volume} \\approx \\beta_0 + \\beta_1 \\text{girth} + \\beta_2 \\text{girth}^2\n\\]\nThe R to fit this model is\n\nd_tree2 <- mutate(d_tree, Girth2 = Girth^2)\nm2 <- lm(Volume ~ Girth + Girth2, data = d_tree2)\ncompute_R2(m2)\n\n[1] 0.962\n\n\n\n\\(R^2\\) has increased! It went from 0.935 to 0.962."
  },
  {
    "objectID": "slides/lec-6.html#before-taking-things-to-the-extreme",
    "href": "slides/lec-6.html#before-taking-things-to-the-extreme",
    "title": "Model Selection",
    "section": "‚Ä¶before taking things to the extreme",
    "text": "‚Ä¶before taking things to the extreme\nWhat if we also include the predictors \\(\\text{Girth}^3, \\text{Girth}^4, \\dots, \\text{Girth}^{k}\\) for some larger number \\(k\\)?\nThe following R code fits such a model with \\(k=29\\), that is, \\[\n\\text{Volume} \\approx \\beta_0 + \\beta_1 \\text{girth} + \\beta_2 \\text{girth}^2 + \\dots + \\beta_{29} \\text{girth}^{29}\n\\]\n\nm_extreme <- lm(Volume ~ poly(Girth, degree = 30, raw = TRUE), data = d_tree)\ncompute_R2(m_extreme)\n\n[1] 0.975\n\n\n\\(R^2\\) has again increased! It went from 0.962 to 0.975."
  },
  {
    "objectID": "slides/lec-6.html#overfitting",
    "href": "slides/lec-6.html#overfitting",
    "title": "Model Selection",
    "section": "Overfitting",
    "text": "Overfitting\nIn fact, if we keep adding predictors, \\(R^2\\) will always increase. - additional predictors allow the regression line to be more flexible, hence to be closer to the points and reduce the residuals.\n\nIs the m_extreme model a good model? - does it accurately represent the population? - remember that we want to learn about the relation between Volume and Girth present in the population (not the sample)."
  },
  {
    "objectID": "slides/lec-6.html#section",
    "href": "slides/lec-6.html#section",
    "title": "Model Selection",
    "section": "",
    "text": "R code\nRegression line\nRegression line (zoomed)\n\n\n\n\nGirth_new <- seq(min(d_tree$Girth), max(d_tree$Girth), by = 0.01)\nnew_data <- tibble(Girth = Girth_new)\nVolume_pred <- predict(m_extreme, new_data)\nnew_data <- mutate(new_data, Volume_pred = Volume_pred)\nhead(new_data)\n\n# A tibble: 6 x 2\n  Girth Volume_pred\n  <dbl>       <dbl>\n1  8.3         10.2\n2  8.31        10.3\n3  8.32        10.4\n4  8.33        10.5\n5  8.34        10.6\n6  8.35        10.7\n\n\n\n\n\nggplot() +\n  geom_point(data = d_tree  , aes(Girth, Volume     )) +\n  geom_line (data = new_data, aes(Girth, Volume_pred))\n\n\n\n\n\n\n\n\n\n\nggplot() +\n  geom_point(data = d_tree  , aes(Girth, Volume     )) +\n  geom_line (data = new_data, aes(Girth, Volume_pred)) +\n  ylim(10, 77)"
  },
  {
    "objectID": "slides/lec-6.html#section-1",
    "href": "slides/lec-6.html#section-1",
    "title": "Model Selection",
    "section": "",
    "text": "The model m_extreme overfits the data.\nA model overfits data when it corresponds very closely to the data set and does a poor job for new data.\n\nRemember that we want to learn about the population, not the sample!"
  },
  {
    "objectID": "slides/lec-6.html#adjusted-r2",
    "href": "slides/lec-6.html#adjusted-r2",
    "title": "Model Selection",
    "section": "Adjusted-\\(R^2\\)\n",
    "text": "Adjusted-\\(R^2\\)\n\nWe saw that \\(R^2\\) keeps increasing as we add predictors.\n\\[\nR^2_{\\text{adj}} = 1 - \\dfrac{SSR}{SST}\n\\]\n\\(R^2\\) can therefore not be used to identify models that overfit the data.\n\nInstead, we use the adjusted-\\(R^2\\).\n\\[\nR^2_{\\text{adj}} = 1 - \\dfrac{SSR}{SST}\\dfrac{n-1}{n-p-1}\n\\]\nwhere \\(p\\) corresponds to the number of predictors."
  },
  {
    "objectID": "slides/lec-6.html#section-2",
    "href": "slides/lec-6.html#section-2",
    "title": "Model Selection",
    "section": "",
    "text": "The ratio \\(\\dfrac{SSR}{SST}\\) favors model that closely fit the data.\nThe ratio \\(\\dfrac{n-1}{n-k-1}\\) penalizes model with many predictors.\n\nThe model with the highest adjusted-\\(R^2\\) typically hits the sweet spot."
  },
  {
    "objectID": "slides/lec-6.html#aic-and-bic",
    "href": "slides/lec-6.html#aic-and-bic",
    "title": "Model Selection",
    "section": "AIC and BIC",
    "text": "AIC and BIC\nTwo popular criteria that balance goodness of fit (small SSR) and parsimony (small \\(p\\)) are\n\nthe Akaike Information Criterion (AIC)\nthe Bayesian Inofrmation Criterion (BIC)\n\n\nThe formula for AIC and BIC are respectively \\[\nAIC = 2p - \\text{GoF}, \\qquad BIC = \\ln(n)p- \\text{GoF}\n\\] where \\(\\text{GoF}\\) is a measure of the Goodness of fit of the model1.\n\n\nUnlike the adjusted-\\(R^2\\), smaller is better for the AIC and BIC.\n\n\nNote that the BIC penalizes the number of parameters \\(p\\) more strongly.\n\nThe exact formula for \\(\\text{GoF}\\) is beyond the scope of this class."
  },
  {
    "objectID": "slides/lec-6.html#computing-aic-and-bic",
    "href": "slides/lec-6.html#computing-aic-and-bic",
    "title": "Model Selection",
    "section": "Computing AIC and BIC",
    "text": "Computing AIC and BIC\nEasily accessible in R with the command glance. For instance,\n\nglance(m1)\n\n# A tibble: 1 x 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.935         0.933  4.25      419. 8.64e-19     1  -87.8  182.  186.\n# ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\nglance(m2)\n\n# A tibble: 1 x 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.962         0.959  3.33      350. 1.52e-20     2  -79.7  167.  173.\n# ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\nglance(m_extreme)\n\n# A tibble: 1 x 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.975         0.956  3.44      51.4 5.11e-11    13  -73.0  176.  197.\n# ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\n\n\nIn this case, all three criteria (ajudtsed-\\(R^2\\), AIC and BIC) indicate that m2 id the best model.\n\nFor AIC and BIC, smaller is better."
  },
  {
    "objectID": "slides/lec-6.html#limitations-of-the-previous-methods",
    "href": "slides/lec-6.html#limitations-of-the-previous-methods",
    "title": "Model Selection",
    "section": "Limitations of the previous methods",
    "text": "Limitations of the previous methods\nThe adjutsed-\\(R^2\\), AIC and BIC all try to balance\n\ngoodness of fit\nparsimony\n\n\nThey achieve this balance by favoring models with small SSR while penalizing models with larger \\(p\\).\n\n\nThe form of the penalty for \\(p\\) may seem somewhat arbitrary. - E.g. AIC versus BIC."
  },
  {
    "objectID": "slides/lec-6.html#predictive-performance",
    "href": "slides/lec-6.html#predictive-performance",
    "title": "Model Selection",
    "section": "Predictive performance",
    "text": "Predictive performance\nInstead, we could look for the model with the best predictions performance; that is, the model that makes predictions for new observations that are the closest to the true values."
  },
  {
    "objectID": "slides/lec-6.html#the-holdout-method",
    "href": "slides/lec-6.html#the-holdout-method",
    "title": "Model Selection",
    "section": "The holdout method",
    "text": "The holdout method\nThe holdout method is a simple method to evaluate the predictive performance of a model.\n\n\nRandomly partition your sample into two sets: a training set (typically 2/3 of the sample) and a test set.\n\n\n\n\nFit your model to the training set.\n\n\n\n\nEvaluate the prediction accuracy on the test set.\n\n\n\nNote that the test set consists of new observations for the model.\n\n\nA good model will model will have good prediction accuracy in step 3"
  },
  {
    "objectID": "slides/lec-6.html#step-1-training-and-test-sets",
    "href": "slides/lec-6.html#step-1-training-and-test-sets",
    "title": "Model Selection",
    "section": "Step 1: training and test sets",
    "text": "Step 1: training and test sets\nThe following R function splits a sample into a training and a test set\n\nconstruct_training_test <- function(sample, prop = 2/3){\n  \n  n          <- nrow(sample)\n  n_training <- round(n*prop)\n  \n  sample_random   <- slice_sample(sample, n = n)\n  sample_training <- slice(sample_random,   1:n_training )\n  sample_test     <- slice(sample_random, -(1:n_training))\n  \n  return(list(\n    training = sample_training, test = sample_test\n    ))\n  \n}"
  },
  {
    "objectID": "slides/lec-6.html#section-3",
    "href": "slides/lec-6.html#section-3",
    "title": "Model Selection",
    "section": "",
    "text": "d_car <- ggplot2::mpg\ntraining_test_sets <- construct_training_test(d_car) \ntraining_set <- training_test_sets[[\"training\"]]\ntraining_set\n\n# A tibble: 156 x 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 nissan       pathfinde~   3.3  1999     6 auto~ 4        14    17 r     suv  \n 2 dodge        durango 4~   4.7  2008     8 auto~ 4        13    17 r     suv  \n 3 pontiac      grand prix   3.8  2008     6 auto~ f        18    28 r     mids~\n 4 jeep         grand che~   4.7  2008     8 auto~ 4         9    12 e     suv  \n 5 audi         a4 quattro   2    2008     4 auto~ 4        19    27 p     comp~\n 6 dodge        caravan 2~   3.8  1999     6 auto~ f        15    22 r     mini~\n 7 toyota       camry sol~   3    1999     6 auto~ f        18    26 r     comp~\n 8 honda        civic        1.6  1999     4 manu~ f        28    33 r     subc~\n 9 honda        civic        2    2008     4 manu~ f        21    29 p     subc~\n10 dodge        durango 4~   5.7  2008     8 auto~ 4        13    18 r     suv  \n# ... with 146 more rows\n\ntest_set     <- training_test_sets[[\"test\"]]\ntest_set\n\n# A tibble: 78 x 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 ford         explorer ~   4    2008     6 auto~ 4        13    19 r     suv  \n 2 chevrolet    malibu       3.6  2008     6 auto~ f        17    26 r     mids~\n 3 mercury      mountaine~   4    1999     6 auto~ 4        14    17 r     suv  \n 4 chevrolet    k1500 tah~   5.3  2008     8 auto~ 4        11    14 e     suv  \n 5 subaru       impreza a~   2.2  1999     4 manu~ 4        19    26 r     subc~\n 6 audi         a4 quattro   3.1  2008     6 manu~ 4        15    25 p     comp~\n 7 volkswagen   jetta        2.5  2008     5 auto~ f        21    29 r     comp~\n 8 toyota       land crui~   5.7  2008     8 auto~ 4        13    18 r     suv  \n 9 nissan       pathfinde~   4    2008     6 auto~ 4        14    20 p     suv  \n10 volkswagen   new beetle   1.9  1999     4 auto~ f        29    41 d     subc~\n# ... with 68 more rows"
  },
  {
    "objectID": "slides/lec-6.html#step-2-fit-the-model-to-the-training-set",
    "href": "slides/lec-6.html#step-2-fit-the-model-to-the-training-set",
    "title": "Model Selection",
    "section": "Step 2: fit the model to the training set",
    "text": "Step 2: fit the model to the training set\nWe now fit our regression model to the training set, as we have done many times.\n\nm <- lm(hwy ~ cty, data = training_set)"
  },
  {
    "objectID": "slides/lec-6.html#step-3-evaluate-the-prediction-accuracy-on-the-test-set",
    "href": "slides/lec-6.html#step-3-evaluate-the-prediction-accuracy-on-the-test-set",
    "title": "Model Selection",
    "section": "Step 3: Evaluate the prediction accuracy on the test set",
    "text": "Step 3: Evaluate the prediction accuracy on the test set\nTo evaluate the prediction accuracy, we start by computing the predictions for the test set.\n\nhwy_hat <- predict(m, test_set)\n\n\nA good model will make predictions that are closed to the true values of the response variable.\n\n\nA common measure of prediction accuracy is the root mean of squared errors (RMSE):\n\\[\nRMSE = \\sqrt{\\dfrac{SSE}{m}} = \\sqrt{\\dfrac{(y_1 - \\hat{y}_1)^2 + (y_2 - \\hat{y}_2)^2 + \\dots + (y_m - \\hat{y}_m)^2}{m}}\n\\]\nwhere \\(m\\) corresponds to the size of the test set."
  },
  {
    "objectID": "slides/lec-6.html#selecting-a-model",
    "href": "slides/lec-6.html#selecting-a-model",
    "title": "Model Selection",
    "section": "Selecting a model",
    "text": "Selecting a model\nApply steps 2 and 3 on different models.\n\nuse the same training and test sets for the different models\n\nSimply choose the model with the lowest SSE.\nThis model has the best out-of-sample accuracy."
  },
  {
    "objectID": "slides/lec-6.html#cross-validation",
    "href": "slides/lec-6.html#cross-validation",
    "title": "Model Selection",
    "section": "Cross-validation",
    "text": "Cross-validation\nCross-validation (CV) is the same as the holdout method, but repeated many times.\n\ndrawback of the holdout method is that the test set matters a lot.\nRepeating steps 2 and 3 with a different partition from step 1 may give different results.\n\n\nIdea of CV: let each observation be in the test set once"
  },
  {
    "objectID": "slides/lec-6.html#k-fold-cv",
    "href": "slides/lec-6.html#k-fold-cv",
    "title": "Model Selection",
    "section": "\n\\(k\\)-fold CV",
    "text": "\\(k\\)-fold CV\nChoose a number of folds \\(k\\) (typically \\(5\\) or \\(10\\)).\n\n\nPartition the data into \\(k\\) folds of equal size.\n\n\n\n\nLet the test set be composed of fold \\(1\\) and the training set of the other folds.\n\n\n\n\nApply steps 2 and 3 of the holdout method.\n\n\n\n\nGo back to step 2, this time letting the next fold be the test set."
  },
  {
    "objectID": "slides/lec-6.html#section-4",
    "href": "slides/lec-6.html#section-4",
    "title": "Model Selection",
    "section": "",
    "text": "set.seed(345)\n\nn_folds <- 10\n\ncounty_2019_nc_folds <- county_2019_nc %>%\n  slice_sample(n = nrow(county_2019_nc)) %>%\n  mutate(fold = rep(1:n_folds, n_folds)) %>%\n  arrange(fold)\n\npredict_folds <- function(i) {\n  fit <- lm(uninsured ~ hs_grad, data = county_2019_nc_folds %>% filter(fold != i))\n  predict(fit, newdata = county_2019_nc_folds %>% filter(fold == i)) %>%\n    bind_cols(county_2019_nc_folds %>% filter(fold == i), .fitted = .)\n}\n\nnc_fits <- map_df(1:n_folds, predict_folds)\n\np_nc_fits <- ggplot(nc_fits, aes(x = hs_grad, y = .fitted, group = fold)) +\n  geom_line(stat = \"smooth\", method = \"lm\", se = FALSE, size = 0.3, alpha = 0.5) +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Predicted uninsurance rate in NC\",\n    subtitle = glue(\"For {n_folds} different testing datasets\")\n    )\n\np_nc_fits\n\n\nset.seed(123)\n\nn_folds <- 10\n\ncounty_2019_ny_folds <- county_2019_ny %>%\n  slice_sample(n = nrow(county_2019_ny)) %>%\n  mutate(fold = c(rep(1:n_folds, 6), 1, 2)) %>%\n  arrange(fold)\n\npredict_folds <- function(i) {\n  fit <- lm(uninsured ~ hs_grad, data = county_2019_ny_folds %>% filter(fold != i))\n  predict(fit, newdata = county_2019_ny_folds %>% filter(fold == i)) %>%\n    bind_cols(county_2019_ny_folds %>% filter(fold == i), .fitted = .)\n}\n\nny_fits <- map_df(1:n_folds, predict_folds)\n\np_ny_fits <- ggplot(ny_fits, aes(x = hs_grad, y = .fitted, group = fold)) +\n  geom_line(stat = \"smooth\", method = \"lm\", se = FALSE, size = 0.3, alpha = 0.5) +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Predicted uninsurance rate in NY\",\n    subtitle = glue(\"For {n_folds} different testing datasets\")\n    )\n\np_ny_fits"
  },
  {
    "objectID": "slides/lec-6.html#taking-things-to-the-extreme-loocv",
    "href": "slides/lec-6.html#taking-things-to-the-extreme-loocv",
    "title": "Model Selection",
    "section": "Taking things to the extreme: LOOCV",
    "text": "Taking things to the extreme: LOOCV\nSet \\(k=n\\); that is, we use \\(n\\) folds, each of size \\(1\\). The test sets will therefore consist of a single observation and the training sets of \\(n-1\\) observations."
  },
  {
    "objectID": "slides/lec-6.html#forward-selection-procedure",
    "href": "slides/lec-6.html#forward-selection-procedure",
    "title": "Model Selection",
    "section": "Forward selection procedure",
    "text": "Forward selection procedure\n\nChoose a criterion that balances model fit (smaller SSR) and parsimony (small \\(k\\)).\n\n\ne.g.¬†adjusted-\\(R^2\\), AIC or BIC\n\n\n\nStart with the empty model \\(Y \\approx \\beta_0\\), i.e.¬†the model with no predictor. This is our current model\nFit all possible models with one additional predictor.\n\n. .\n\nCompute the AIC of each of these models\n\n\nIdentify the model with the smallest AIC. This is our candidate model.\n\n\n\n\nIf the AIC of the candidate model is smaller (better) than the AIC of the current model, the candidate model becomes the current model, and we go back to step 3.\nIf the AIC of the candidate model is larger than the AIC of the current model (no new model improves on the current one), the procedure stops, and we select the current model."
  },
  {
    "objectID": "slides/lec-6.html#backward-selection-procedure",
    "href": "slides/lec-6.html#backward-selection-procedure",
    "title": "Model Selection",
    "section": "Backward selection procedure",
    "text": "Backward selection procedure\nSimilar to forward selection, except that\n\nwe start with the full model,\nremove one predictor at a time\nuntil removing any predictors makes the model worse.\n\n\nNote that forward and backward selection need not agree; they may select different models.\n\n\n\nWhat to do in that case? Nobody knows."
  },
  {
    "objectID": "slides/lec-6.html#section-5",
    "href": "slides/lec-6.html#section-5",
    "title": "Model Selection",
    "section": "",
    "text": "Group exercise - stepwise selection\n\n\n\nExercises 8.11, 8.13\nIn addition\n\n\nfit the first models in R\n\nidentify the baseline level of the categorical variable in each model.\n\n\nlibrary(openintro)\nd <- openintro::births14\n\n\n\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-6.html#recap-2",
    "href": "slides/lec-6.html#recap-2",
    "title": "Model Selection",
    "section": "Recap",
    "text": "Recap\n\n\n\nhttps://rmorsomme.github.io/website/"
  }
]