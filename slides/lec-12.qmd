---
title: "Classical inference"
subtitle: "STA 101L - Summer I 2022"
author: "Raphael Morsomme"
footer:  "[https://rmorsomme.github.io/website/](https://rmorsomme.github.io/website/)"
logo: "images/logo.jpg"
format: 
  revealjs: 
    theme: slides.scss
    transition: fade
    slide-number: true
    code-fold: false
    code-summary: "Show the code"
    scrollable: true
    link-external-newwindow: true
    history: false
editor: visual
execute:
  freeze: auto
  echo: true
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| include: false

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = 0.618,
  fig.retina = 3,
  dpi = 300,
  out.width = "80%",
  fig.align = "center"
)

# load packages
library(tidyverse)   # for data wrangling and visualization
library(countdown)   # for countdown for in-class exercises
library(openintro)   # for textbook data sets
library(kableExtra)
library(janitor)
library(patchwork)   # for combining ggplot figures
library(broom)       # for tidy model output

# set default theme and larger font size for ggplot2
theme_set(theme_minimal(base_size = 16))

options(scipen = 5)
```

# Welcome

## Announcements {.smaller}

-   Tuesday: lecture

-   Wednesday: work on project

-   Thursday: work on project (3:30-5:00pm)

-   Friday: presentations

## Recap {.smaller}

-   HT via simulation

-   CI via bootstrap

-   5 cases

    -   one proprotion

    -   two proportions

    -   one mean

    -   two means

    -   linear regression

## Outline

-   Normal approximation
-   Classical approach to statistical inference
-   Standard error

## 

::: {.callout-tip icon="false"}
## Individual exercise - warm up

Exercise [14.5](https://openintro-ims.netlify.app/decerr.html#chp14-exercises)

Exercise [17.2](https://openintro-ims.netlify.app/inference-two-props.html#chp17-exercises) -- parts a and c

Exercise [17.4](https://openintro-ims.netlify.app/inference-two-props.html#chp17-exercises) -- part c
:::

```{r, echo = F}
countdown(minutes = 3)
```

# Normal approximation

## Normal distribution

```{r}
tibble(x = seq(-5, 5, by = 0.001)) %>%
  mutate(normal = dnorm(x, mean = 0, sd = 1)) %>%
  ggplot() + 
  geom_line(aes(x, normal))
```

$\Rightarrow$ unimodal, symmetric, thin tails -- bell-shaped

## HT using a normal approximation

![](images/lec-12/p-value.png){fig-align="center"}

Source: [IMS](https://www.openintro.org/book/ims/)

## CI using a normal approximation

![](images/lec-12/3-sigma.png){fig-align="center"}

Source: [IMS](https://www.openintro.org/book/ims/)

## Normal approximation

The normal distribution describes the variability of the different statistics

-   $\hat{p}$, $\bar{x}$, $\hat{\beta}$

-   simply look at all the histograms we have constructed from simulated samples (HT) and bootstrap samples (CI)!

. . .

**Classical approach**: instead of simulating the sampling distribution via simulation (HT) or bootstrapping (CI), we approximate it with a normal distribution.

## Normal approximation for $\bar{x}$

We have seen that if a numerical variable $X$ is normally distributed

$$
X\sim N(\mu, \sigma^2)
$$

then the sample average is also normally distributed

$$
\bar{x} \sim N\left(\mu, \frac{\sigma^2}{n}\right)
$$

## Condition for the normality of $\bar{x}$ {.smaller}

In practice, we cannot assume that the variable $X$ is *exactly* normally distributed.

But as long as

1.  the sample is large, or

2.  the variable is *approximately* normal: unimodal, roughly symmetric and no serious outlier

$\bar{x}$ is well approximated by a normal distribution

$$
\bar{x} \sim N\left(\mu, \frac{\sigma^2}{n}\right)
$$

. . .

See the numerous histograms for case 3 (one mean) where the distribution of $\bar{x}$ always looks pretty normal.

## Normal approximation for $\hat{p}$ {.smaller}

If

1.  the observations are independent -- the **independence** condition

2.  $p$ is not extreme and $n$ is not small $(pn\ge 10 \text{ and } (1-p)n\ge 10)$ -- the **success-failure** condition

the distribution of $\hat{p}$ can be approximated by a normal distribution

$$
\hat{p} \sim N\left(p, \frac{p(1-p)}{n}\right)
$$

::: callout-important
## Success-failure condition for CI

For CI, we verify the success-failure condition using the sample proportion $\hat{p}$:

$$
\hat{p}n\ge 10 \text{ and } (1-\hat{p})n\ge 10
$$
:::

## Conditions are satisfied

```{r}
p <- 0.4; n <- 100 # conditions are satisfied: p*n>10 and (1-p)*n>10
results <- tibble(p_hat = numeric())
for(i in 1 : 5e3){
  sim     <- purrr::rbernoulli(n, p)
  p_hat   <- mean(sim)
  results <- results %>% add_row(p_hat)
}
ggplot(results) + geom_histogram(aes(p_hat), binwidth = 0.01)
```

## Normal approximation is good

```{r}
tibble(p_hat = seq(0.2, 0.6, by = 0.001)) %>%
  mutate(normal_approximation = dnorm(p_hat, mean = p, sd = sqrt(p*(1-p)/n))) %>%
  ggplot() +
  geom_line(aes(x = p_hat, y = normal_approximation))
```

## 

::: callout-tip
## When the conditions are satisfied

When the conditions are satisfied, the normal distribution will be a good approximation. The classical and modern (simulation, bootstrap) approaches to statistical inference will give the same results.
:::

## Conditions are *not* satisfied

```{r}
p <- 0.025; n <- 100 # conditions are not satisfied: p*n<10 
results <- tibble(p_hat = numeric())
for(i in 1 : 5e3){
  sim     <- purrr::rbernoulli(n, p)
  p_hat   <- mean(sim)
  results <- results %>% add_row(p_hat)
}
ggplot(results) + geom_histogram(aes(p_hat), binwidth = 0.01) + xlim(-0.05, 0.1)
```

## Normal approximation fails

```{r}
tibble(p_hat = seq(-0.05, 0.1, by = 0.001)) %>%
  mutate(normal_approximation = dnorm(p_hat, mean = p, sd = sqrt(p*(1-p)/n))) %>%
  ggplot() + geom_line(aes(x = p_hat, y = normal_approximation)) + xlim(-0.05, 0.1)
```

## 

::: callout-important
## When conditions are not satisfied

When the conditions are not satisfied, the normal distribution will not be a good approximation to the sampling distribution. In this case, we should not use the classical approach to statistical inference, but instead use simulation (HT) or bootstrap (CI).
:::

# The classical approach to HT and CI

## The classical approach

Step 1: we are interested in the distribution of the statistic under $H_0$.

-   **Modern approach**: *simulate* from this distribution

-   **Classical approach**: *approximate* this distribution with a normal distribution

## HT

Step 2: we want to compute the p-value

-   **Modern approach**: the p-value is the proportion of simulations with a statistic at least as extreme as that of the observed sample

-   **Classical approach**: the p-value is the *area under the curve* of the normal distribution that is at least as extreme as the observed statistic.

## What `R` does

`R` will compute the p-value for you. Here is what `R` does behind the scene:

![](images/lec-12/p-value.png){fig-align="center"}

## CI

Step 2: identify the upper and lower bounds of the CI

-   **Modern approach**: find the appropriate percentiles among the simulated values

-   **Classical approach**:find the appropriate percentiles of the normal approximation

## What `R` does

`R` will compute the upper and lower bounds for you. Here is what `R` does behind the scene:

![](images/lec-12/3-sigma.png){fig-align="center"}

## Case 1 -- one proportion

```{r}
n <- 1500 # sample size
x <- 780  # number of successes
prop.test(
  x, n,             # observed data
  p = 0.5,          # value in the null hypothesis
  conf.level = 0.99 # confidence level for CI
  )
```

## Comparison with simulation-based HT

The simulation-based HT yielded a p-value of 0.127.

::: callout-note
## A good normal approximation

When the conditions for the normal approximation are satisfied, the results based on simulations (modern) and the normal approximation (classical) will be similar.
:::

**Conditions**: independence, success-failure condition

## 

::: {.callout-tip icon="false"}
## Individual exercise - the classical approach for one proportion

Suppose you interview 2000 US adults about their political preferences and 1200 of them say that they are democrat. What is the 95% confidence interval for $p$, the proportion of US adults who are democrats? What is the length of the interval?

What 95% CI do you obtain if 6000 out of 10000 US adults say they are democrat? What is its length?

Exercise [16.19](https://openintro-ims.netlify.app/inference-one-prop.html#chp16-exercises) -- find the 95% CI. Are the conditions satisfied?

Exercise [16.21](https://openintro-ims.netlify.app/inference-one-prop.html#chp16-exercises)

Exercise [16.25](https://openintro-ims.netlify.app/inference-one-prop.html#chp16-exercises)
:::

```{r, echo = F}
countdown(minutes = 5)
```

## Case 2 -- two proportions

Consider the gender discrimination study.

```{r}
n_m <- 24; n_f <- 24 # sample sizes
x_m <- 14; x_f <- 21 # numbers of promotions
prop.test(c(x_m, x_f), c(n_m, n_f))
```

## Conditions

1.  Independence within groups (same as case 1)

2.  Independence between groups

3.  Success-failure condition for each group (10 successes and 10 failures in each group)

## Comparison with simulation-based HT

Using the simulation-based HT, we found a p-value of 0.0435.

::: callout-note
## A good normal approximation

When the conditions for the normal approximation are *not* satisfied, the results based on simulations (modern) and the normal approximation (classical) may differ.

A simulation-based HT will always give exact results. A HT based on the normal distribution will only give the same (exact) results when the conditions are satisfied.
:::

## 

::: {.callout-tip icon="false"}
## Individual exercise - the classical approach for two proportions

Exercise [17.7](https://openintro-ims.netlify.app/inference-two-props.html#chp17-exercises)

Exercise [17.13](https://openintro-ims.netlify.app/inference-two-props.html#chp17-exercises)

Exercise [17.19](https://openintro-ims.netlify.app/inference-two-props.html#chp17-exercises)
:::

```{r, echo = F}
countdown(minutes = 6)
```

## Case 3 -- one mean

```{r}
d <- ggplot2::mpg
t.test(d$hwy, mu = 25)
```

## Conditions

1.  Independence

2.  Normality -- can be relaxed for larger samples $(n\ge30)$

. . .

::: callout-tip
## Statistics as an art

The normality assumption is vague. The most important feature of the sample to verify is the presence of outliers.

Rule of thumb: if $n<30$, there should not be any clear outlier; if $n\ge30$, there should not be any extreme outlier.
:::

## 

::: {.callout-tip icon="false"}
## Individual exercise - the classical approach for one mean

Make a histogram and a boxplot of the variable. Are the conditions satisfied?

Construct a 99% CI for `hwy`.

Hint: run the command `help(t.test)` to access the help file of the function `t.test` and see what parameter determines the confidence level.
:::

```{r, echo = F}
countdown(minutes = 3)
```

## Case 4 -- two means

There are two implementation; which on is more convenient depends on the structure of the data.

::: panel-tabset
## Two vectors

```{r}
d <- ggplot2::mpg
t.test(hwy ~ year, data = d)
```

## Formula

```{r}
d <- ggplot2::mpg
t.test(d$cty, d$hwy)
```
:::

## Conditions

1.  Independence within groups

2.  Independence between groups

3.  Normality in each group (same as case 3 -- one mean)

## 

::: {.callout-tip icon="false"}
## Individual exercise - the classical approach for two means

What is the 99% CI for the difference in fuel efficiency on the highway and in the city? How long is this CI?

Are the conditions satisfied?
:::

```{r, echo = F}
countdown(minutes = 2)
```

## Case 4bis -- paired means

```{r}
d <- ggplot2::mpg
t.test(d$cty, d$hwy, paired = TRUE)
```

## Conditions

1.  Paired observations

2.  Independence between pairs

3.  Normality

## 

::: {.callout-tip icon="false"}
## Individual exercise - the classical approach for paired means

What is the 99% CI for the difference in fuel efficiency on the highway and in the city? How long is this CI?

Are the conditions satisfied?
:::

```{r, echo = F}
countdown(minutes = 2)
```

. . .

::: callout-important
## Always pair the observations

If the data can paired, you should always do it! Pairing data yields an analysis that is more *powerful*:

-   narrower CI

-   smaller p-value
:::

## Case 5 -- regression

::: panel-tabset
## simple linear regression

```{r}
m <- lm(hwy ~ cty, data = mpg)
tidy(m)
```

## multiple linear regression

```{r}
m <- lm(hwy ~ cty + displ, data = mpg)
tidy(m)
```

$H_0: \beta_1 = 0$ when `displ` is included in the model

$H_a: \beta_1 \neq 0$ when `displ` is included in the model

$H_0: \beta_2 = 0$ when `cty` is included in the model

$H_a: \beta_2 \neq 0$ when `cty` is included in the model

## logistic regression

```{r}
d <- heart_transplant %>% mutate(survived_binary = survived == "alive")
m <- glm(survived_binary ~ age + transplant, family = "binomial", data = d)
tidy(m)
```
:::

## Conditions (LINE) -- linear regression

1.  Linearity

2.  Independence

3.  Normality

4.  Equal variability (homoskedasticity)

$\Rightarrow$ verify with a residual plot!

## 

::: {.callout-tip icon="false"}
## Individual exercise - the classical approach for regression

What condition(s) are violated by each of the following data sets (see next slide)?

Exercise [24.10](https://openintro-ims.netlify.app/inf-model-slr.html#chp24-exercises)

Exercise [24.13](https://openintro-ims.netlify.app/inf-model-slr.html#chp24-exercises) -- parts a and b

Exercise [24.15](https://openintro-ims.netlify.app/inf-model-slr.html#chp24-exercises) -- part b

Exercise [25.3](https://openintro-ims.netlify.app/inf-model-mlr.html#chp25-exercises)

Exercise [25.7](https://openintro-ims.netlify.app/inf-model-mlr.html#chp25-exercises)

Exercise [26.1](https://openintro-ims.netlify.app/inf-model-logistic.html)

Exercise [26.1](https://openintro-ims.netlify.app/inf-model-logistic.html)
:::

```{r, echo = F}
countdown(minutes = 10)
```

## Data sets

![](images/lec-12/conditions.png){fig-align="center"}

# Standard error

## Standard error {.smaller}

**Standard error (SE)**: standard deviation of the normal approximation

It measures the variability of the sample statistic.

-   $SE(\hat{p})=\sqrt{\frac{p(1-p)}{n}}$

-   $SE(\hat{p}_{diff})=\sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}$

-   $SE(\bar{x}) = \sqrt{\frac{\sigma^2}{n}}$

-   $SE(\bar{x}_{diff}) = \sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}$

-   $SE(\hat{\beta})$ has a complicated form.

::: callout-note
Note the role of the sample size!
:::

## Larger samples have a smaller SE

::: callout-note
## Sample size matters

Large $n$

$\Rightarrow$ small SE

$\Rightarrow$ normal approximation with small sd

$\Rightarrow$ normal approximation is more concentrated

$\Rightarrow$ tighter CI and smaller p-values.
:::

## 

::: {.callout-tip icon="false"}
## Individual exercise - sample size and CI

Exercise [16.13](https://openintro-ims.netlify.app/inference-one-prop.html#chp16-exercises) -- part e

Exercise [16.15](https://openintro-ims.netlify.app/inference-one-prop.html#chp16-exercises) -- part b

Exercise [13.4](https://openintro-ims.netlify.app/foundations-mathematical.html#chp13-exercises) -- part d
:::

```{r, echo = F}
countdown(minutes = 2)
```

# Case 6 -- many proportions ($\chi^2$ test)

## Reproducibility

```{r}
ask <- openintro::ask %>%
  mutate(
    response = if_else(response == "disclose", "Disclose problem", "Hide problem"),
    question_class = case_when(
      question_class == "general" ~ "General",
      question_class == "neg_assumption" ~ "Negative assumption",
      question_class == "pos_assumption" ~ "Positive assumption"
    ),
    question_class = fct_relevel(question_class, "General", "Positive assumption", "Negative assumption")
  )
```

## Example -- defect iPod

```{r, echo=FALSE}
ask %>%
  count(question_class, response) %>%
  pivot_wider(names_from = response, values_from = n) %>%
  adorn_totals(where = c("row", "col")) %>%
  kbl(linesep = "", booktabs = TRUE,
      col.names = c("Question", "Disclose problem", "Hide problem", "Total")
    ) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), 
                latex_options = c("striped", "hold_position"), full_width = FALSE)
```

Source: [IMS](https://www.openintro.org/book/ims/)

## HT, no CI

$H_0$: the response is independent of the question asked

$H_a$: the response depends on the question asked

We will not quantify the differences between the three question with CIs.

## Expected counts

```{r}
ask_chi_sq <- chisq.test(ask$response, ask$question_class)
ask_chi_sq_obs <- ask_chi_sq$observed %>% 
  as_tibble() %>% 
  mutate(type = "observed")
ask_chi_sq_exp <- ask_chi_sq$expected %>%
  as.table() %>%
  as_tibble() %>% 
  mutate(type = "expected")
ask_chi_sq_tabs <- bind_rows(ask_chi_sq_obs, ask_chi_sq_exp) %>%
  rename_with(.fn = str_remove, .cols = everything(), "ask\\$")
ask_chi_sq_tabs %>%
  mutate(response_type = paste0(response, "-", type)) %>%
  select(-response, -type) %>%
  pivot_wider(names_from = response_type, values_from = n) %>%
  relocate(
    question_class,
    contains("Disclose"),
    contains("Hide")
  ) %>%
  mutate(across(contains("expected"), ~paste0("(", round(.x, 2), ")"))) %>%
  rowwise() %>%
  mutate(Total = sum(c_across(contains("observed")))) %>%
  adorn_totals(where = "row") %>%
  mutate(
    `Disclose problem-expected` = ifelse(`Disclose problem-expected` == "-", NA, `Disclose problem-expected`),
    `Hide problem-expected` = ifelse(`Hide problem-expected` == "-", NA, `Hide problem-expected`)
  ) %>%
 kbl(linesep = "", booktabs = TRUE,
   col.names = c("", "", "", "", "", "")
   ) %>%
  column_spec(1, width = "15em") %>%
  column_spec(3, color = IMSCOL["blue", "full"], italic = TRUE) %>%
  column_spec(5, color = IMSCOL["blue", "full"], italic = TRUE) %>%
  column_spec(6, width = "5em") %>%
  add_header_above(c(" ", "Disclose problem" =2, "Hide problem" = 2, "Total")) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), 
                latex_options = c("striped", "hold_position"), full_width = FALSE)
```

Source: [IMS](https://www.openintro.org/book/ims/)

## Chance or effect?

The difference between the *expected* and *observed* counts is due to

-   chance alone, or

-   the fact that the way people responded depended on the question asked

. . .

$\chi^2$ ("Kai-squared") statistics:

$$
\chi^2 = \dfrac{(O_{11} - E_{11})^2}{E_{11}} + \dfrac{(O_{21} - E_{21})^2}{E_{21}} + \dots + \dfrac{(O_{32} - E_{32})^2}{E_{32}}
$$

## Computing $\chi^2$

$$
\begin{aligned}
&\text{General formula} &&
    \frac{(\text{observed count } - \text{expected count})^2}
        {\text{expected count}} \\
&\text{Row 1, Col 1} &&
    \frac{(2 - 20.33)^2}{20.33} = 16.53 \\
&\text{Row 2, Col 1} &&
    \frac{(23 - 20.33)^2}{20.33} = 0.35 \\
& \hspace{9mm}\vdots &&
    \hspace{13mm}\vdots \\
&\text{Row 3, Col 2} &&
    \frac{(37 - 52.67)^2}{52.67} = 4.66
\end{aligned}
$$

$$\chi^2 = 16.53 + 0.35 + \dots + 4.66 = 40.13$$

Source: [IMS](https://www.openintro.org/book/ims/)

## The approximate distribution of $\chi^2$

When the conditions of

1.  independence

2.  $>5$ expected counts per cell

are satisfied, the $\chi^2$ statistic approximately follows a $\chi^2$ distribution.

## Computing the p-value

![](images/lec-12/chi-squared.png){fig-align="center"}

Source: [IMS](https://www.openintro.org/book/ims/)

## The $\chi^2$ test in `R`

```{r}
head(ask)
chisq.test(ask$response, ask$question_class)
```

## 

::: {.callout-tip icon="false"}
## Individual exercise - $\chi^2$ test

Exercise [18.15](https://openintro-ims.netlify.app/inference-tables.html#chp18-exercises)
:::

```{r, echo = F}
countdown(minutes = 1, seconds = 30)
```

## HT via simulation

When the conditions are not met, you need to conduct a HT via *simulation*.

1.  Simulate artificial samples under $H_0$ by shuffling the response variable
2.  Compute the $\chi^2$ statistic of each simulated sample
3.  Determine how extreme the $\chi^2$ statistic of the observed sample is by computing a p-value

See [Section 18.1](https://openintro-ims.netlify.app/inference-tables.html#randomization-test-of-independence) for an example.

# Case 7 -- many means (ANOVA)

## Reproducibility

```{r}
mlb_players_18 <- openintro::mlb_players_18 %>%
  filter(
    AB >= 100, 
    !position %in% c("P", "DH")
  ) %>%
  mutate(
    position = case_when(
      position %in% c("LF", "CF", "RF")       ~ "OF",
      position %in% c("1B", "2B", "3B", "SS") ~ "IF",
      TRUE                                    ~ position
    ),
    position = fct_relevel(position, "OF", "IF", "C")
  )
```

## Example -- batting performance and position

![](images/lec-12/anova-data.png){fig-align="center"}

Source: [IMS](https://www.openintro.org/book/ims/)

## HT, no CI

$H_0: \mu_{OF} = \mu_{IF} = \mu_{C}$: (the batting performance is the same across all three positions)

$H_a$: at least one mean is different

We will not quantify the differences between the three positions with CIs.

## ANOVA in `R`

```{r}
m <- aov(OBP ~ position, data = mlb_players_18)
tidy(m)
```

## Conditions

1.  Independence within

2.  Independence between

3.  Normality (sample size and outliers)

4.  constant variance

Verify assumptions 3 and 4 with histograms

## Side-by-side histograms

```{r}
ggplot(mlb_players_18) +
  geom_histogram(aes(OBP)) +
  facet_grid(position ~ .)
```


## 
::: {.callout-tip icon="false"}
## Individual exercise - ANOVA
Exercise [22.5](https://openintro-ims.netlify.app/inference-many-means.html#chp22-exercises)

Exercise [22.9](https://openintro-ims.netlify.app/inference-many-means.html#chp22-exercises) -- parts a and b

:::
```{r, echo = F}
countdown(minutes = 3)
```

## HT via simulation

When the conditions are not met, you need to conduct a HT via *simulation*.

1.  Simulate artificial samples under $H_0$ by shuffling the response variable
2.  Compute the $F$ statistic of each simulated sample (see [Section 22.2](https://openintro-ims.netlify.app/inference-many-means.html#randANOVA))
3.  Determine how extreme the $F$ statistic of the observed sample is by computing a p-value

See [Section 22.2](https://openintro-ims.netlify.app/inference-many-means.html#randANOVA) for an example.

# Recap

## Recap

-   Normal approximation
-   Classical approach to statistical inference
-   Standard error
-   Case 6 -- many proportions ($\chi^2$ test)
-   Case 7 -- many means (ANOVA)
