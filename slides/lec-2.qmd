---
title: "Introduction to Data"
subtitle: "STA 101L - Summer I 2022"
author: "Raphael Morsomme"
footer:  "[https://rmorsomme.github.io/website/](https://rmorsomme.github.io/website/)"
logo: "images/logo.jpg"
format: 
  revealjs: 
    theme: slides.scss
    transition: fade
    slide-number: true
    scrollable: true
    link-external-newwindow: true
    history: false
editor: visual
execute:
  freeze: auto
---

```{r setup}
#| include: false
library(countdown)
library(openintro)
library(tidyverse)
library(kableExtra)
library(fivethirtyeight)
library(janitor)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.618,
  fig.align = "center",
  out.width = "90%"
)
```

# Welcome

## Outline

-   Motivating example - stent and stroke
-   Principles of statistical inference
-   Types of variable
-   Experiments and observational studies

# Motivating example - stent and stroke

## Example - Stents and strokes

Stents are known to reduce the risk of an additional heart attack or death after a cardiac event.

-   Could stents have similar benefits for patients at risk of stroke?

. . .

-   If so, we should use this well-known procedure to reduce the risk of stroke!
-   If not, the procedure (surgery) should be avoided.

## Does the use of stents reduce the risk of stroke?

We have an experiment with 451 at-risk patients:

-   each volunteer patient was randomly assigned to either the treatment (stent) or the control (no stent) group
-   check with patients 30 days and 365 days later

------------------------------------------------------------------------

```{r stentStudyResultsDF}
data("stent30")
data("stent365")
stent30_renamed <- stent30 %>% rename(`30 days` = outcome)
stent365_renamed <- stent365 %>% rename(`365 days` = outcome)
stent <- stent30_renamed %>%
  select(-group) %>%
  bind_cols(stent365_renamed) %>% 
  relocate(group) %>%
  mutate(
    group        = fct_rev(group),
    `30 days`    = fct_rev(`30 days`),
    `365 days`   = fct_rev(`365 days`),
  )
stent %>%
  sample_n(5) %>% 
  arrange(group) %>%
  mutate(patient = 1:n()) %>%
  relocate(patient) %>%
  kbl(linesep = "", booktabs = TRUE, caption = "Results for five patients from the stent study.",
      align = "llll") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), 
                latex_options = c("striped", "hold_position"),
                full_width = FALSE) %>%
  column_spec(1:4, width = "8em")
```

------------------------------------------------------------------------

```{r stentStudyResultsDFsummary}
stent %>%
  mutate(group = str_to_title(group)) %>%
  pivot_longer(cols = c(`30 days`, `365 days`), 
               names_to = "stage", 
               values_to = "outcome") %>%
  count(group, stage, outcome) %>%
  pivot_wider(names_from = c(stage, outcome), values_from = n) %>%
  adorn_totals(where = "row") %>%
  kbl(linesep = "", booktabs = TRUE, caption = "Descriptive statistics for the stent study.",
      col.names = c("Group", "Stroke", "No event", "Stroke", "No event")) %>%
  add_header_above(c(" " = 1, "30 days" = 2, "365 days" = 2), extra_css = "border-bottom: 2px solid") %>%
  row_spec(1, extra_css = "border-top: 2px solid") %>%
  row_spec(3, extra_css = "border-top: 2px solid") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), 
                latex_options = c("striped", "hold_position"))
```

Contrary to expectation, we observe more strokes in the treatment group

-   Do the data show a *real* difference between the groups?
-   Or is the difference simply due to chance?

. . .

This type of questions is central in statistics.

## Dealing with Randomness

Suppose I flip a coin $100$ times and count the number of times I obtain heads.

-   I expect to observe *about* $50$ heads.

. . .

-   Imagine that I observe $85$ heads instead. That would be alarming; the coin is probably not fair.

. . .

-   If I had observed $55$ heads then I would not be alarmed; this is a plausible result with a fair coin.

## Intuition about randomness

::: {.callout-tip icon="false"}
## Group exercise - gut feeling about randomness

1.  In the coin example, what number of heads would start to make you doubt that the coin is fair?
2.  In the stent study, is the difference large enough to make you doubt that the stents have no effect? In other words, do you think that the difference we observe between the two groups is plausible if stents have no effect?
:::

```{r}
countdown(minutes = 5)
```

# Principles of Statistical Inference

## Observations and variables

```{r small_sample}
stent %>%
  sample_n(3) %>% 
  arrange(group) %>%
  mutate(patient = 1:n()) %>%
  relocate(patient) %>%
  kbl(linesep = "", booktabs = TRUE, caption = "Results for three patients from the stent study.",
      align = "llll") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), 
                latex_options = c("striped", "hold_position"),
                full_width = FALSE) %>%
  column_spec(1:4, width = "8em")
```

. . .

-   Each row represents an **observation**
-   Each column represents a **variable**

## Some examples

-   **Observational units**: individuals, families, student cohort, cities, counties, countries, cells (biology), animals, books, courses, apples

-   **Variables**: height, weight, age, size, year, latitude, longitude, type, sex, diet, number of pages, genre, level, color

## Population

We are typically interested in the relation between variables in some population.

The **population of interest** is often large, but with well-defined limits

-   e.g. patients at risk of stroke, Duke students, trees in Duke Forest, US counties
-   but not the following: people, students, patients.

## Census and sample

There are two ways to learn about the relation between variables in a given population.

. . .

1.  **Census**: collect data on the whole population
    1.  ideal

    2.  ...but typically impractical, expensive

. . .

2.  **Sample**: small fraction of the population

## Statistical inference {.smaller}

-   Population **parameter**, e.g. mean number of hours that Duke students sleep per night
    -   Greek letter: $\mu$, $\beta$, but also $p$.

. . .

-   Sample **statistic**, e.g. *observed* average number of hours Duke students sleep per night in some sample
    -   Roman letter: $\bar{x}$, $b$, $\hat{p}$

. . .

-   How to learn about the population from a sample?
    -   ...from sample statistics to population parameters
    -   **Statistical inference** provides a rigorous framework to accomplish this.

------------------------------------------------------------------------

::: {.callout-tip icon="false"}
## Group exercise - observation and variables

1.  Consider a study that investigate the effect of diet on sleep among Duke students. What is the population? What is the observational unit? Give three variables that you would want to measure in the study.
2.  Exercise 1.13 a
3.  Exercise 2.7
4.  Give an example of a study in your field. What is the population? What are the observational units? Name a few variables that are measured.
:::

```{r}
countdown(minutes = 7)
```

## Statistics as an art -- sampling

When you make soup, there is no need to drink the whole pot (population) to know if the it is seasoned enough.

-   Tasting a spoonful (sample) is sufficient.
-   If the soup is well mixed, a spoonful is a **representative** sample of the population

![](images/lec-2/soup.png){fig-alt="Illustration of a bowl of soup" fig-align="center" width="300"}

## 

::: {.callout-tip icon="false"}
## Group exercise - sampling

Back to the study on the effect of diet on sleep among Duke students. How would you obtain a sample of student for your study if you had (i) 1 hour, (ii) 1 week to collect your data?
:::

```{r, echo = F}
countdown(minutes = 3)
```

## 

Are all samples created equal? No!

. . .

What can go wrong?

-   small samples,
-   convenience sampling, e.g. students on campus,
-   blind spots, e.g. voters with no phone,
-   ...

. . .

Sampling is an art.

## Random sample

The gold standard is a **random sample**

-   but even then, we can have non-response bias

. . .

ðŸ›‘ Obtaining a *representative* sample is difficult.

. . .

âœ… But surprisingly small representative samples can do the job!

-   e.g. 1,500 voters (later in class)

# Types of variable

## Numerical variables {.smaller}

-   Takes a numerical value
-   Examples: age, height, number of children

. . .

::: callout-warning
Not all numbers are numerical variables, e.g. zip code, phone number.

Heuristic: is the average meaningful? Yes!
:::

. . .

Numerical variables are either

-   **discrete**, e.g. number of siblings
-   or **continuous**, e.g. a person's height

. . .

-   not always clear cut, e.g. GPA

## Categorical variables {.smaller}

-   Takes a level (a category)
-   Examples: eye color, place of birth, education level

::: callout-warning
Some numbers are categorical variables, e.g. zip code, phone number.

Heuristic: is the average meaningful? No!
:::

. . .

Numerical variables are either

-   **nominal**, e.g. eye color
-   or **ordinal**, e.g. education level

------------------------------------------------------------------------

```{r variables, fig.cap = "Breakdown of variables into their respective types.", fig.asp = 0.5, fig.alt = "Types of variables are broken down into numerical (which can be discrete or continuous) and categorical (which can be ordinal or nominal)."}
par_og <- par(no.readonly = TRUE) # save original par
par(mar = rep(0, 4))
plot(c(-0.15, 1.3), 0:1, type = "n", axes = FALSE)
text(0.6, 0.9, "all variables")
rect(0.4, 0.8, 0.8, 1)
text(0.25, 0.5, "numerical")
rect(0.1, 0.4, 0.4, 0.6)
arrows(0.45, 0.78, 0.34, 0.62, length = 0.08)
text(0.9, 0.5, "categorical")
rect(0.73, 0.4, 1.07, 0.6)
arrows(0.76, 0.78, 0.85, 0.62, length = 0.08)
text(0, 0.1, "discrete")
rect(-0.17, 0, 0.17, 0.2)
arrows(0.13, 0.38, 0.05, 0.22, length = 0.08)
text(0.39, 0.1, "continuous")
rect(0.25, 0, 0.53, 0.2)
arrows(0.35, 0.38, 0.4, 0.22, length = 0.08)
text(0.77, 0.105, "ordinal")
rect(0.64, 0, 0.9, 0.2)
arrows(0.82, 0.38, 0.77, 0.22, length = 0.08)
text(1.12, 0.1, "nominal")
rect(0.99, 0, 1.25, 0.2)
arrows(1.02, 0.38, 1.1, 0.22, length = 0.08)
par(par_og) # restore original par
```

Source: [IMS](https://www.openintro.org/book/ims/)

## 

::: {.callout-tip icon="false"}
## Group exercise - types of variables

1.  Exercise [1.13 b](https://openintro-ims.netlify.app/data-hello.html#chp1-exercises)
2.  Consider the study you used in the previous group exercise. Can you identify a numerical and a categorical variable? What are they?
3.  Does the study consider a variable of all four types? Can you come up with a variable of each type?
:::

```{r}
countdown(minutes = 5)
```

# Experiments and observational studies

## Relationship between variables

Two variables can either be **independent** or **associated**.

. . .

If two variables are associated, the association can be

-   linear (positive, or negative)
-   or it can take any form, e.g. U-shape, inverted-J-shape (like a square root)

## 

::: {.callout-tip icon="false"}
## Group exercise - types of associations

Provide two numerical variables which you expect to be

1.  linearly associated; is the association positive or negative?
2.  associated in a non linear way.
:::

```{r}
countdown(minutes = 2)
```

## Explanatory and response variable

-   When two variables are associated, we sometimes hypothesize that changes in one *cause* changes in the other.

. . .

-   **Explanatory** variable $\Rightarrow$ **response** variable

. . .

-   ...but association $\neq$ causation; examples:
    -   ice-cream and shark attacks; fire damage and firemen
    -   counties and kidney cancer death rate; the best classrooms are small classrooms, but so are the worst classrooms.

## Group exercise - counties and kidney cancer death rate

::: panel-tabset
## Instructions

Why are most of the shaded counties in the middle of the country?

```{r, echo = F}
countdown(minutes = 4)
```

## Group 1

![The counties of the United Sates with the highest 10% age-standardized death rates for cancer of kidney/ureter for U.S. white males, 1980--1989.](images/lec-2/kidney_highest.PNG)Source: [Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/)

## Group 2

![The counties of the United Sates with the lowest 10% age-standardized death rates for cancer of kidney/ureter for U.S. white males, 1980--1989.](images/lec-2/kidney_lowest.PNG)

Source: [Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/)

## Small sample effect

![There is more variation in small counties.](images/lec-2/kidney_pattern.PNG)

Source: [Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/)
:::

## Experiments

-   The value of the explanatory variable is **assigned** by the researcher
-   **Randomized** experiment: the value of the explanatory variable is randomly assigned
    -   removes any counfounding (lurking) variable, e.g. air temperature
-   **Blind**, or even double-blind, to avoid biases
    -   placebo
    -   can go wrong, e.g. vitamins in prison

------------------------------------------------------------------------

ðŸ›‘ we cannot always use experiments:

-   not all variables can be assigned, e.g. age
-   ethical considerations, e.g. smoking cigarette, sham surgery (placebo)
-   practical consideration, e.g. long-term consumption of red meat

. . .

âœ… But when experiments can be implement, they lead to **causal** claims and are therefore the gold standard.

## Observational Studies

-   The value of the explanatory variable is **not assigned** by the researcher
    -   there is no interference
-   Example: survey

## 

ðŸ›‘ Does not easily lead to causal claims due to the potential presence of counfounding variables

```{r sun-causes-cancer, out.width = "80%", fig.asp = 0.4, fig.alt = "Three boxes are shown in a triangle arrangement representing: sun exposure, using sunscreen, and skin cancer.  A solid arrow connects sun exposure as a causal mechanism to using sunscreen; a solid arrow also connects sun exposure as a causal mechanism to skin cancer.  A questioning arrow indicates that the causal effect of using sunscreen on skin cancer is unknown."}
par_og <- par(no.readonly = TRUE) # save original par
par(mar = rep(0, 4))
plot(c(-0.05, 1.2),
     c(0.39, 1),
     type = 'n',
     axes = FALSE)
text(0.59, 0.89, 'sun exposure', cex = 1.4)
rect(0.4, 0.8, 0.78, 1)
text(0.3, 0.49, 'use sunscreen', cex = 1.4)
rect(0.1, 0.4, 0.48, 0.6)
arrows(0.49, 0.78, 0.38, 0.62,
       length = 0.08, lwd = 1.5)
text(0.87, 0.5, 'skin cancer', cex = 1.4)
rect(0.71,0.4, 1.01, 0.6)
arrows(0.67, 0.78, 0.8, 0.62,
       length = 0.08, lwd = 1.5)
arrows(0.5, 0.5, 0.69, 0.5,
       length = 0.08, col = IMSCOL["gray", "f1"])
text(0.595, 0.565, "?",
     cex = 1.5, col = IMSCOL["gray", "full"])
par(par_og) # restore original par
```

Source: [IMS](https://www.openintro.org/book/ims/)

. . .

...but they can lead to causal claims in certain cases!

-   E.g. smoking causes cancer.

## 

::: {.callout-tip icon="false"}
## Group exercise - experiment and observational study

You want to investigate the effect of caffeine on class participation among Duke students

1.  Design an observational study.
2.  Design an experiment.
3.  Is your experiment double-blind? Can you make it double-blind?
4.  Do you have any ethical or practical concern with the experiment?

Provide an example of an observational study that you would **not** turn into an experiment due to:

1.  practical considerations
2.  ethical considerations

Exercise [2.12](https://openintro-ims.netlify.app/data-design.html#chp2-exercises)
:::

```{r}
countdown(minutes = 6)
```

# Recap

## Recap

::: incremental
-   observations (row) and variables (column)
-   population parameters and sample statistics
-   statistical inference
-   sampling
-   four types of variables
    -   numerical: continuous, discrete
    -   categorical: nominal, ordinal
-   experiments, observational studies and causal claims
:::
