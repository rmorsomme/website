{
  "hash": "958ae6c9d4843a42d541137b6825d3ec",
  "result": {
    "markdown": "---\ntitle: \"Inference for proportions\"\nsubtitle: \"STA 101L - Summer I 2022\"\nauthor: \"Raphael Morsomme\"\nfooter:  \"[https://rmorsomme.github.io/website/](https://rmorsomme.github.io/website/)\"\nlogo: \"images/logo.jpg\"\nformat: \n  revealjs: \n    theme: slides.scss\n    multiplex: true\n    transition: fade\n    slide-number: true\n    code-fold: false\n    code-summary: \"Show the code\"\n    scrollable: true\neditor: visual\nexecute:\n  freeze: auto\n  echo: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n# Welcome\n\n## Announcements\n\n-   \n\n## Recap\n\n-   One proportion\n\n    -   HT via simulation\n\n    -   CI via bootstrap\n\n-   Two proportions\n\n    -   HT via simulation\n\n    -   CI via bootstrap\n\n## Outline\n\n-   The normal distribution\n-   One mean (case 3)\n-   Two means (case 4)\n-   Paired means (case 3)\n\n# The normal distribution\n\nThe distribution of a numerical variable is often modeled with a **normal distribution**.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(x = seq(-5, 5, by = 0.01)) %>%\n  mutate(normal = dnorm(x, mean = 0, sd = 1)) %>%\n  ggplot() + \n  geom_line(aes(x, normal))\n```\n\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## Two parameters\n\nThe mean ($\\mu$) -- location\n\nThe standard deviation ($\\sigma$) -- spread\n\n$$\nN(\\mu, \\sigma)\n$$ The *standard* normal distribution $N(\\mu = 0, \\sigma = 1)$ is plotted on the previous slide.\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Individual exercise - normal distribution\n\nModify the following `R` code to plot the normal distributions\n\n-   $N(\\mu = 0, \\sigma = 0.5)$\n-   $N(\\mu = 1, \\sigma = 0.5)$\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(x = seq(-5, 5, by = 0.01)) %>%\n  mutate(normal = dnorm(x, mean = 0, sd = 1)) %>%\n  ggplot() + \n  geom_line(aes(x, normal))\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be740\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## Property I\n\nIf the variable $X\\sim N(\\mu, \\sigma)$, then for any number $a$ and $b$\n\n$$\nX + a \\sim N(\\mu+a, \\sigma),\n$$\n\n$$\nbX \\sim N(b\\mu, b \\sigma)\n$$\n\nand\n\n$$\nbX + a \\sim N(b\\mu+a, b\\sigma).\n$$\n\n## Property II\n\nIf the variables $X\\sim N(\\mu_1, \\sigma_1)$ and $Y\\sim N(\\mu_2, \\sigma_2)$ are independent, then $$\nX+Y \\sim N(\\mu_{tot} = \\mu_1 + \\mu_2, \\sigma_{tot} = \\sqrt{\\sigma_1^2 + \\sigma_2^2})\n$$\n\n## Alternative parameterization\n\n$N(\\mu, \\sigma^2)$, where $\\sigma^2$ is the variance.\n\n. . .\n\nProperty I gives\n\n$$\nbX + a \\sim N(b\\mu + a, b^2 \\sigma^2)\n$$\n\nand property II gives $$\nX+Y \\sim N(\\mu_{tot} = \\mu_1 + \\mu_2, \\sigma_{tot}^2 = \\sigma_1^2 + \\sigma_2^2)\n$$ . . .\n\nThe mean of the sum is the sum of the means.\n\nThe variance of the sum is the sum of the variances.\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Individual exercise - normal property\n\nSuppose you have a sample with $n=10$ observations in which each observation follows a standard normal distribution independently. That is, $$\nX_1 \\sim N(0,1), X_2 \\sim N(0,1), \\dots, X_{10} \\sim N(0, 1) \n$$ independently.\n\nUse the normal property to derive the distribution of the sample average\n\n$$\n\\bar{x} = \\dfrac{X_1 + X_2 + \\dots + X_{10}}{10}\n$$\n\nWhat happens to the sd/variance of $\\bar{x}$ as the sample size $n$ increases?\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be797\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Individual exercise -\n\nExercise [19.5](https://openintro-ims.netlify.app/inference-one-mean.html#chp19-exercises) -- for our purpose standard error is equivalent to standard deviation in part b.\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be6b3\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">02</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## The 68, 95, 99.7 rule\n\n![](images/lec-10/68-95-99.png){fig-align=\"center\"}\n\n# One mean\n\n## Setup\n\n**population parameter**: mean $\\mu$\n\n**Sample statistics**: sample average $\\bar{x}$\n\n. . .\n\n**Hypothesis testing**:\n\n-   $H_0:\\mu=\\mu_0$ where $\\mu_0$ is a fixed number\n\n-   $H_a:\\mu\\neq \\mu_0$\n\n**Confidence interval**: range of plausible values for $\\mu$.\n\n::: {.callout-tip icon=\"false\"}\n## Individual exercise - statistic and parameter\n\nExercise [19.1](https://openintro-ims.netlify.app/inference-one-mean.html#chp19-exercises)\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be6ee\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## Example -- car price\n\n::: columns\n::: {.column width=\"50%\"}\nWhat is the average price of a car on Awesome Car?\n\n$\\bar{x} = \\dfrac{18,300+20,100+9,600+10,700+27,000}{5}$\n:::\n\n::: {.column width=\"50%\"}\n![](images/lec-10/cars.png){fig-align=\"center\"}\n\nSource: [IMS](https://www.openintro.org/book/ims/)\n:::\n:::\n\n# Hypothesis test via simulation\n\n## Normal model\n\nLet us assume that the price of the cars follow a normal distribution with some mean $\\mu$ and sd $\\sigma$:\n\n$$\nX \\sim N(\\mu, \\sigma)\n$$\n\n$H_0:\\mu=10,000$\n\n$H_a:\\mu\\neq 10,000$\n\n. . .\n\n-   Simulate many samples under $H_0$.\n\n-   Determine if the observed data could have plausibly arisen under $H_0$.\n\n## Problem\n\nTo simulate from the normal distribution, we need to specify both the mean and sd.\n\nProblem: under $H_0$ we only know that $\\mu = 10,000$; we do not know what value to use for the sd!\n\n. . .\n\nWe cannot conduct a hypothesis test with the simulation method!\n\n# Confidence interval via bootstrap\n\n## Bootstrapping\n\nSample with repetition from the observed sample to construct many **bootstrap samples**.\n\nBootstrap samples $\\Rightarrow$ sampling distribution $\\Rightarrow$ CI\n\n## \n\n![](images/lec-10/bootstrap.png){fig-align=\"center\"}\n\nSource: [IMS](https://www.openintro.org/book/ims/)\n\n## Bootstrap in `R`\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsample_observed <- tibble(price = c(18300, 20100, 9600, 10700, 27000))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsample_bootstrap <- function(data){ # same function as before\n  n                <- nrow(data)\n  sample_bootstrap <- slice_sample(data, n = n, replace = TRUE)\n  return(sample_bootstrap)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1)\nsample_bootstrap(sample_observed)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 5 x 1\n  price\n  <dbl>\n1 18300\n2 10700\n3 18300\n4 20100\n5 27000\n```\n:::\n:::\n\n## \n\n::: {.cell layout-align=\"center\" hash='lec-10_cache/revealjs/unnamed-chunk-10_0734e37a5b343f6f4ce1934c0b82cfd5'}\n\n```{.r .cell-code}\nresults <- tibble(stat_boot = numeric())\nset.seed(0)\nfor(i in 1 : 1e3){\n  d_boot    <- sample_bootstrap(sample_observed) # bootstrap sample\n  stat_boot <- mean(d_boot$price  )              # bootstrap statistic\n  results   <- results %>% add_row(stat_boot) \n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nquantile(results$stat_boot, c(0.05 , 0.95 )) # 90% CI\n```\n\n::: {.cell-output-stdout}\n```\n   5%   95% \n12220 22360 \n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nquantile(results$stat_boot, c(0.025, 0.975)) # 95% CI (wider)\n```\n\n::: {.cell-output-stdout}\n```\n 2.5% 97.5% \n11780 23520 \n```\n:::\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(results) + \n  geom_histogram(aes(stat_boot), binwidth = 1350) + \n  geom_vline(xintercept = quantile(results$stat_boot, c(0.05 , 0.95 )), col = \"gold1\", size = 2) + # 90% CI \n  geom_vline(xintercept = quantile(results$stat_boot, c(0.025, 0.975)), col = \"maroon\", size = 2) # 95% CI\n```\n\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Group exercise - Bootstrap CI\n\nExercises [19.11](https://openintro-ims.netlify.app/inference-one-mean.html#chp19-exercises) and [19.13](https://openintro-ims.netlify.app/inference-one-mean.html#chp19-exercises)\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be94d\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## CI for the standard deviation $\\sigma$\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|5|\"}\nresults <- tibble(stat_boot = numeric())\nset.seed(0)\nfor(i in 1 : 1e3){\n  d_boot    <- sample_bootstrap(sample_observed)\n  stat_boot <- sd(d_boot$price  )              # sd instead of mean\n  results   <- results %>% add_row(stat_boot) \n}\n```\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(results) + \n  geom_histogram(aes(stat_boot)) + \n  geom_vline(xintercept = quantile(results$stat_boot, c(0.05 , 0.95 )), col = \"gold1\", size = 2) + # 90% CI \n  geom_vline(xintercept = quantile(results$stat_boot, c(0.01, 0.99)), col = \"maroon\", size = 2) # 98% CI\n```\n\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## \n\n::: callout-note\n## The quality of the sample matters!\n\nYour analysis can only be as good as the sample you. Here, a sample of $5$ cars contains limited information about the population; it would be better to have a larger sample.\n:::\n\n# Two means\n\n## Setup\n\nA **population** divided in two groups.\n\n**Population parameter**: difference in mean\n\n$$\n\\mu_{diff}=\\mu_1-\\mu_2\n$$\n\n**Sample statistics**: difference in proportion in the sample\n\n$$\n\\bar{x}_{diff}=\\bar{x}_1-\\bar{x}_2\n$$\n\n. . .\n\n$H_0:\\mu_{diff}=0$ (no difference between the two groups)\n\n$H_a:\\mu_{diff}\\neq0$\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Individual exercise -\n\nExercise [20.1](https://openintro-ims.netlify.app/inference-two-means.html#chp20-exercises)\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be7c0\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">30</span></code>\n</div>\n```\n:::\n:::\n\n## Example -- two class exams\n\nAre the two exams equally difficult?\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd <- openintro::classdata %>% \n  filter(lecture %in% c(\"a\", \"b\")) %>%\n  rename(score = m1, exam = lecture)\nd\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 113 x 2\n   score exam \n   <dbl> <fct>\n 1    67 a    \n 2    59 a    \n 3   100 a    \n 4    81 a    \n 5    80 a    \n 6    63 a    \n 7   100 a    \n 8    44 a    \n 9    82 a    \n10    67 a    \n# ... with 103 more rows\n```\n:::\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(d, aes(score, exam, col = exam)) + \n  geom_boxplot() +\n  geom_jitter(width = 0, height = 0.1)\n```\n\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-19-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Group exercise - two proportions\n\nCompute are $\\bar{x}_a$, $\\bar{x}_b$ and $\\bar{x}_{diff}$? Do you *intuitively feel* that the data provide convincing evidence that the two exams are not equally difficult?\n\nHint: use the command `summarize`.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd <- openintro::classdata %>% \n  filter(lecture %in% c(\"a\", \"b\")) %>%\n  rename(score = m1, exam = lecture)\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be90e\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n# Hypothesis test via simulation\n\n## \n\n$H_0:\\mu_{diff}=0$\n\n$H_a:\\mu_{diff}\\neq 0$\n\n. . .\n\n-   Simulate many samples under $H_0$ (no difference)\n\n-   Determine if the observed data could have plausibly arisen under $H_0$\n\n## Simulating under $H_0$\n\nUnder $H_0$, there is no difference between the two exams\n\n$\\Rightarrow$ the score is independent of the type of exam\n\n$\\Rightarrow$ randomly re-assign the scores independently of the exam type.\n\n. . .\n\n::: callout-tip\nThis is very similar to the procedure for two proportions.\n:::\n\n## \n\n![](images/lec-10/simulation.png) Source: [IMS](https://www.openintro.org/book/ims/)\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_sim <- d %>% mutate(score = sample(score)) # shuffle the scores\nd_sim\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 113 x 2\n   score exam \n   <dbl> <fct>\n 1    67 a    \n 2    93 a    \n 3    82 a    \n 4    82 a    \n 5    70 a    \n 6    82 a    \n 7    66 a    \n 8    84 a    \n 9    50 a    \n10    64 a    \n# ... with 103 more rows\n```\n:::\n:::\n\n## Function for computing the test statistic\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3,4|5|\"}\ncompute_x_diff <- function(data){\n  x_bar <- data %>%\n    group_by(exam) %>%\n    summarize(x_bar = mean(score))\n  x_diff_bar <- x_bar$x_bar[1] - x_bar$x_bar[2]\n  return(x_diff_bar)\n}\ncompute_x_diff(d_sim)\n```\n\n::: {.cell-output-stdout}\n```\n[1] -0.437931\n```\n:::\n:::\n\n## For-loop for simulating under $H_0$\n\n::: {.cell layout-align=\"center\" hash='lec-10_cache/revealjs/unnamed-chunk-24_e7ab0167af650fa82eb2c8b8081f5808'}\n\n```{.r .cell-code}\n# Setup\nresults   <- tibble(x_diff_bar = numeric())\n\n# Simulations\nset.seed(0)\nfor(i in 1 : 1e3){\n  d_sim <- d %>% mutate(score = sample(score)) # simulate under H0\n  x_diff_bar <- compute_x_diff(d_sim) # test statistic\n  results <- results %>% add_row(x_diff_bar)\n}\n```\n:::\n\n## Sampling distribution\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx_diff_obs <- compute_x_diff(d)\nx_diff_obs\n```\n\n::: {.cell-output-stdout}\n```\n[1] 3.139812\n```\n:::\n\n```{.r .cell-code}\nggplot(results) + \n  geom_histogram(aes(x_diff_bar)) +\n  geom_vline(xintercept = x_diff_obs, col = \"maroon\", size = 2)\n```\n\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-25-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## p-value\n\n-   the probability that $\\bar{x}_{diff}^{sim}\\ge$ 3.1 or $\\bar{x}_{diff}^{sim}\\le$ -3.1.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresults %>%\n  mutate(is_more_extreme = x_diff_bar >= x_diff_obs | x_diff_bar <= -x_diff_obs) %>%\n  summarize(p_value = mean(is_more_extreme))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 1 x 1\n  p_value\n    <dbl>\n1   0.227\n```\n:::\n:::\n\n## Conclusion\n\nUsing the usual significance level $\\alpha = 0.05$, we **fail to reject** the null hypothesis\n\n-   it is plausible that the observed difference in scores is due to random luck\n-   the difference is **not statistically significant**.\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Group exercise - HT\n:::\n\nExercises [20.3](https://openintro-ims.netlify.app/inference-two-means.html#chp20-exercises) and [20.7](https://openintro-ims.netlify.app/inference-two-means.html#chp20-exercises)\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be9ce\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">04</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n# Confidence interval via bootstrap\n\n## Bootstrap CI\n\nSame idea as before: sample with repetition from the observed data to construct many **bootstrap samples**.\n\nBootstrap samples $\\Rightarrow$ sampling distribution $\\Rightarrow$ CI\n\n## \n\n![](images/lec-10/bootstrap2.png)\n\nSource: [IMS](https://www.openintro.org/book/ims/)\n\n## Bootstrap in `R`\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsample_observed_a <- d %>% filter(exam == \"a\")\nsample_observed_b <- d %>% filter(exam == \"b\")\n\nset.seed(0)\nsample_bootstrap(sample_observed_a) # bootstrap sample\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 58 x 2\n   score exam \n   <dbl> <fct>\n 1    58 a    \n 2    59 a    \n 3    81 a    \n 4    71 a    \n 5    67 a    \n 6    58 a    \n 7    80 a    \n 8    72 a    \n 9    58 a    \n10    72 a    \n# ... with 48 more rows\n```\n:::\n\n```{.r .cell-code}\nsample_bootstrap(sample_observed_b) # bootstrap sample\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 55 x 2\n   score exam \n   <dbl> <fct>\n 1    61 b    \n 2    83 b    \n 3    68 b    \n 4    71 b    \n 5    82 b    \n 6    46 b    \n 7    78 b    \n 8    72 b    \n 9    64 b    \n10    83 b    \n# ... with 45 more rows\n```\n:::\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3,4|5|\"}\nresults <- tibble(x_diff_bar = numeric())\nfor(i in 1 : 1e3){\n  d_boot_a   <- sample_bootstrap(sample_observed_a) # bootstrap sample\n  d_boot_b   <- sample_bootstrap(sample_observed_b) # bootstrap sample\n  x_diff_bar <- compute_x_diff(rbind(d_boot_a, d_boot_b)) # bootstrap statistic\n  results    <- results %>% add_row(x_diff_bar)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nquantile(results$x_diff_bar, c(0.05 , 0.95 )) %>% signif(2) # 90% CI\n```\n\n::: {.cell-output-stdout}\n```\n  5%  95% \n-1.2  7.4 \n```\n:::\n\n```{.r .cell-code}\nquantile(results$x_diff_bar, c(0.025, 0.975)) %>% signif(2) # 95% CI\n```\n\n::: {.cell-output-stdout}\n```\n 2.5% 97.5% \n -2.0   8.3 \n```\n:::\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(results) +\n  geom_histogram(aes(x_diff_bar))  + \n  geom_vline(xintercept = quantile(results$x_diff_bar, c(0.05 , 0.95 )), col = \"gold1\", size = 2) + # 90% CI \n  geom_vline(xintercept = quantile(results$x_diff_bar, c(0.025, 0.975)), col = \"maroon\", size = 2) # 95% CI\n```\n\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-31-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## CT and HT\n\n::: callout-note\n## Two sides of the same coin\n\nThe two CIs include 0. This indicates that 0 is a plausible value for the difference in mean in the population. This is exactly what the HT concluded.\n:::\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Group exercises - CI\n\nExercise [20.5](https://openintro-ims.netlify.app/inference-two-means.html#chp20-exercises) part a only\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be7b0\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n# Paired means\n\n## Paired data\n\n**Paired data**: two groups in which each observation in one group has exactly one corresponding observation in the other\n\nExample: pre/post evaluations; supermarket items; batteries and electronic devices; tires and cars\n\n. . .\n\nSimilar to the one mean case (case 3)\n\n## Example\n\nCompare the longevity of two brands of tires. The response variable is tire tread after 1000 miles.\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1)\nbias <- runif(25, -0.01, 0.01)\nbrandA <- rnorm(25, bias + 0.310, 0.003)\nbrandB <- rnorm(25, bias + 0.308, 0.003)\ncar <- c(paste(\"car\", 1:25))\nminy <- min(brandA, brandB) - .003\nmaxy <- max(brandA, brandB) + .003\ntires <- tibble(\n  tread = c(brandA, brandB),\n  car = rep(car, 2),\n  brand = c(rep(\"Smooth Turn\", 25), rep(\"Quick Spin\", 25))\n) %>%\n  arrange(car)\nhead(tires)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 6 x 3\n  tread car    brand      \n  <dbl> <chr>  <chr>      \n1 0.304 car 1  Smooth Turn\n2 0.307 car 1  Quick Spin \n3 0.302 car 10 Smooth Turn\n4 0.303 car 10 Quick Spin \n5 0.307 car 11 Smooth Turn\n6 0.305 car 11 Quick Spin \n```\n:::\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-33-1.png){fig-align='center' width=80%}\n:::\n:::\n\nSource: [IMS](https://www.openintro.org/book/ims/)\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Individual exercise - paired data\n\nExercises [21.1](https://openintro-ims.netlify.app/inference-paired-means.html#chp21-exercises), [21.3](https://openintro-ims.netlify.app/inference-paired-means.html#chp21-exercises) and [21.5](https://openintro-ims.netlify.app/inference-paired-means.html#chp21-exercises)\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be69d\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## CI via booststrap\n\nExactly the same as for one mean (case 3).\n\n. . .\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntires_diff <- tires %>% \n  pivot_wider(names_from = brand, values_from = tread) %>%\n  mutate(tread_diff = `Smooth Turn` - `Quick Spin`) %>%\n  select(car, tread_diff)\nhead(tires_diff)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 6 x 2\n  car    tread_diff\n  <chr>       <dbl>\n1 car 1    -0.00258\n2 car 10   -0.00107\n3 car 11    0.00192\n4 car 12    0.00251\n5 car 13    0.00271\n6 car 14    0.00639\n```\n:::\n:::\n\n. . .\n\nSimply construct a CI for `tread_diff` with bootstrap samples.\n\n## HT via simulation\n\n$H_0:\\mu_{diff}=0$\n\n$H_a:\\mu_{diff}\\neq 0$\n\n. . .\n\n-   Simulate many samples under $H_0$ (no difference)\n\n-   Determine if the observed data could have plausibly arisen under $H_0$\n\n## Simulating under $H_0$\n\nUnder $H_0$, there is no difference between the two tire brands\n\n$\\Rightarrow$ the tire tread is independent of the tire brand\n\n$\\Rightarrow$ randomly re-assign the tire tread independently of the tire brand.\n\n::: callout-note\n## Re-assign *within*\n\nThe re-assignment happens *within* a car; either switch the two values or or keep the original allocation.\n:::\n\n## Re-assigning two cars\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-36-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## Re-assigning all cars\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-37-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Individual exercise - simulated difference\n\nExercise [21.9](https://openintro-ims.netlify.app/inference-paired-means.html#chp21-exercises)\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be829\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">02</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## `R` function to shuffle data\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nshuffle_data <- function(data){\n  tires %>%\n  group_by(car) %>%\n  mutate(tread = sample(tread))\n}\n\nset.seed(0)\ntires_shuffled <- shuffle_data(tires)\nhead(tires)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 6 x 3\n  tread car    brand      \n  <dbl> <chr>  <chr>      \n1 0.304 car 1  Smooth Turn\n2 0.307 car 1  Quick Spin \n3 0.302 car 10 Smooth Turn\n4 0.303 car 10 Quick Spin \n5 0.307 car 11 Smooth Turn\n6 0.305 car 11 Quick Spin \n```\n:::\n\n```{.r .cell-code}\nhead(tires_shuffled)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 6 x 3\n# Groups:   car [3]\n  tread car    brand      \n  <dbl> <chr>  <chr>      \n1 0.307 car 1  Smooth Turn\n2 0.304 car 1  Quick Spin \n3 0.303 car 10 Smooth Turn\n4 0.302 car 10 Quick Spin \n5 0.307 car 11 Smooth Turn\n6 0.305 car 11 Quick Spin \n```\n:::\n:::\n\n## `R` function for computing the test statistic\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompute_stat <- function(data){\n  \n  data %>% \n    pivot_wider(names_from = brand, values_from = tread) %>%\n    mutate(tread_diff = `Smooth Turn` - `Quick Spin`) %>%\n    ungroup() %>%\n    summarise(x_diff_bar = mean(tread_diff)) %>%\n    pull(x_diff_bar)\n  \n}\ncompute_stat(tires_shuffled)\n```\n\n::: {.cell-output-stdout}\n```\n[1] -0.001036578\n```\n:::\n:::\n\n## For-loop for simulating under $H_0$\n\n::: {.cell layout-align=\"center\" hash='lec-10_cache/revealjs/unnamed-chunk-41_a2d06e923f2c5078b7d8295343f60180'}\n\n```{.r .cell-code}\n# Setup\nresults   <- tibble(x_diff_bar = numeric())\n\n# Simulations\nset.seed(0)\nfor(i in 1 : 1e3){\n  d_sim <- shuffle_data(tires) # simulate under H0\n  x_diff_bar <- compute_stat(d_sim) # test statistic\n  results <- results %>% add_row(x_diff_bar)\n}\n```\n:::\n\n## Sampling distribution\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx_diff_obs <- compute_stat(tires)\nx_diff_obs\n```\n\n::: {.cell-output-stdout}\n```\n[1] 0.0020934\n```\n:::\n\n```{.r .cell-code}\nggplot(results) + \n  geom_histogram(aes(x_diff_bar)) +\n  geom_vline(xintercept = x_diff_obs, col = \"maroon\", size = 2)\n```\n\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-42-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## p-value and conclusion\n\n-   the probability that $\\bar{x}_{diff}^{sim}\\ge$ 0.0021 or $\\bar{x}_{diff}^{sim}\\le$ -0.0021.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresults %>%\n  mutate(is_more_extreme = x_diff_bar >= x_diff_obs | x_diff_bar <= -x_diff_obs) %>%\n  summarize(p_value = mean(is_more_extreme))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 1 x 1\n  p_value\n    <dbl>\n1   0.012\n```\n:::\n:::\n\nUsing the usual significance level $\\alpha = 0.05$, we **reject** $H_0$.\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Individual exercise - HT\n\nExercise [21.11](https://openintro-ims.netlify.app/inference-paired-means.html#chp21-exercises)\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629be9ce\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">02</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n# To pair or not to pair?\n\n## \n\n::: callout-important\n## Always pair\n\nIf the data can paired, you should always do so!\n\nPairing data gives an analysis that is more *powerful*\n\n-   narrower CI\n\n-   smaller p-values\n:::\n\n## Two-mean HT (case 4)\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompute_x_diff <- function(data){\n  x_bar <- data %>%\n    group_by(brand) %>%\n    summarize(x_bar = mean(tread))\n  x_diff_bar <- x_bar$x_bar[1] - x_bar$x_bar[2]\n  return(x_diff_bar)\n}\ncompute_x_diff(tires)\n```\n\n::: {.cell-output-stdout}\n```\n[1] -0.0020934\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='lec-10_cache/revealjs/unnamed-chunk-46_3df0c5f7a0cfbf521a6042f807a528c3'}\n\n```{.r .cell-code}\nresults   <- tibble(x_diff_bar = numeric())\nset.seed(0)\nfor(i in 1 : 1e3){\n  d_sim <- tires %>% mutate(tread = sample(tread)) # simulate under H0\n  x_diff_bar <- compute_x_diff(d_sim) # test statistic\n  results <- results %>% add_row(x_diff_bar)\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx_diff_obs <- compute_x_diff(tires)\nresults %>%\n  mutate(is_more_extreme = x_diff_bar >= abs(x_diff_obs) | x_diff_bar <= -abs(x_diff_obs)) %>%\n  summarize(p_value = mean(is_more_extreme))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 1 x 1\n  p_value\n    <dbl>\n1   0.229\n```\n:::\n:::\n\nWe fail to reject the null.\n\n## Larger p-value\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(results) + \n  geom_histogram(aes(x_diff_bar)) +\n  geom_vline(xintercept = x_diff_obs, col = \"maroon\", size = 2)\n```\n\n::: {.cell-output-display}\n![](lec-10_files/figure-revealjs/unnamed-chunk-48-1.png){fig-align='center' width=80%}\n:::\n:::\n\n# Recap\n\n## Recap\n\n-   The normal distribution\n-   One mean (case 3)\n-   Two means (case 4)\n-   Paired means (case 3)",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"..\\site_libs/countdown-0.3.5/countdown.css\" rel=\"stylesheet\" />\r\n<script src=\"..\\site_libs/countdown-0.3.5/countdown.js\"></script>\r\n"
      ],
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}