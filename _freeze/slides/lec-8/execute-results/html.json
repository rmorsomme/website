{
  "hash": "2f0d27ec061ab6257fa8616c91cdec99",
  "result": {
    "markdown": "---\ntitle: \"Principles of Inference\"\nsubtitle: \"STA 101L - Summer I 2022\"\nauthor: \"Raphael Morsomme\"\nfooter:  \"[https://rmorsomme.github.io/website/](https://rmorsomme.github.io/website/)\"\nlogo: \"images/logo.jpg\"\nformat: \n  revealjs: \n    theme: slides.scss\n    multiplex: true\n    transition: fade\n    slide-number: true\n    code-fold: false\n    code-summary: \"Show the code\"\n    scrollable: true\neditor: visual\nexecute:\n  freeze: auto\n  echo: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n# Welcome\n\n## Announcements\n\n-   Homework 5 due on Sunday\n\n## Recap\n\n-   Types of data\n\n-   Visualization and numerical summaries\n\n-   Regression models\n\n    -   linear rm\n\n    -   logistic rm\n\n    -   model selection\n\n## Types of data\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Breakdown of variables into their respective types.](lec-8_files/figure-revealjs/variables-1.png){fig-align='center' fig-alt='Types of variables are broken down into numerical (which can be discrete or continuous) and categorical (which can be ordinal or nominal).' width=80%}\n:::\n:::\n\nSource: [IMS](https://www.openintro.org/book/ims/)\n\n## Outline\n\n-   Statistical inference\n\n-   Five cases\n\n-   Hypothesis test\n\n-   Confidence interval\n\n-   A first glimpse of modern statistics\n\n# Statistical inference\n\n## Population parameters\n\nWe want to learn about some (unknown) **parameter** of some **population** of interest from a (small) **sample** of observations\n\n. . .\n\n-   Examples of parameters: proportion of vegetarian among Duke students, average weight gained by Duke students during the Covid-19 pandemic, etc.\n\n. . .\n\n-   In the remainder of the course, we will always assume that we have a *random* sample\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Group exercise - identify the parameter\n\nExercise [11.1](https://openintro-ims.netlify.app/foundations-randomization.html#chp11-exercises)\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629258b9\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## Statistical inference\n\n**Inference**: to estimate the population parameter from the sample.\n\n**Statistical inference**: to estimate the population parameter from the sample and rigorously quantify our *certainty* in the estimate.\n\n## Statistic\n\n**Statistic**: any function of some data. E.g., average, median, iqr, maximum, etc\n\n**sample statistic**: a statistic computed on the sample\n\n**summary statistic**: a statistic used to summarize a sample\n\n**test statistic**: statistic used for statistical inference\n\n## Estimating a parameter \n\nTo estimate a population parameter, we can simply\n\n-   collect data on a representative sample, and\n\n-   use the corresponding sample statistic as an estimate\n    -   to estimate the median age of Duke students, simply compute the median of your sample.\n\n## Certainty matters\n\nA single point (the sample statistic) does not indicate how confident we are in our estimate.\n\n-   If we have a *large* sample, then we can be pretty confident that our estimates will be close to the true value of the parameter,\n\n-   if we have a *small* sample, then we know that our estimate may be far from the truth.\n\n-   e.g. Duke students, basketball free throws.\n\n## Statistical inference\n\nFramework to make rigorous statements about uncertainty in our estimates\n\n-   confidence intervals\n\n    -   range of plausible values for the population parameter\n\n-   hypothesis tests\n\n    -   evaluate competing claims using data\n\n# Five cases\n\n## Case 1 -- Single proportion {.smaller}\n\n::: columns\n::: {.column width=\"55%\"}\nWhat is the proportion of vegetarian among Duke students?\n\n**Population parameter**: proportion of vegetarian among Duke students $(p)$\n\n**Sample statistic**: proportion of vegetarian in the sample $(\\hat{p})$\n:::\n\n::: {.column width=\"40%\"}\n![](images/lec-8/vegetarian.jpg)\n:::\n:::\n\n. . .\n\n**Confidence interval**: a range a plausible values for the population parameter $p$\n\n-   $(0.31, 0.43)$\n\n. . .\n\n**Hypothesis test**: is the proportion of vegetarian among Duke students $0.5$?\n\n-   $H_0:p=0.5, \\qquad    H_a:p\\neq0.5$\n\n## Case 2 -- Difference between two proportions {.smaller}\n\nIs the proportion of vegetarian the same among Duke undergraduate and graduate students?\n\n**Population parameter**: difference between the proportion of vegetarian among Duke undergraduate and graduate students $(p_{diff} = p_{undergrad}-p_{grad})$\n\n**Sample statistic**: difference in proportion of vegetarian in the sample $(\\hat{p}_{diff} = \\hat{p}_{undergrad} - \\hat{p}_{grad})$\n\n. . .\n\n**Confidence interval** for $p_{diff}$: $(-0.05, 0.08)$\n\n. . .\n\n**Hypothesis test**: is the proportion of vegetarian the same among Duke undergraduate and graduate students?\n\n-   $H_0:p_{diff}=0, \\qquad H_a:p_{diff}\\neq0$\n\n\n## Case 3 -- Single mean {.smaller}\n\n::: columns\n::: {.column width=\"60%\"}\nHow much time do Duke students sleep on average per night?\n\n**Population parameter**: mean amount of time that Duke students sleep per night $(\\mu)$\n\n**Sample statistic**: average amount of time in the sample $(\\bar{x})$\n\n:::\n\n::: {.column width=\"40%\"}\n![](images/lec-8/sleep.jpg)\n:::\n:::\n\n. . .\n\n**Confidence interval** for $\\mu$: $(5.5, 7.5)$\n\n. . .\n\n**Hypothesis test**: Do Duke students sleep on average $8$ hours per night? \n\n-   $H_0:\\mu=8, H_a:\\mu\\neq8$\n\n## Case 4 -- Difference between two proportions {.smaller}\n\nDo Duke undergraduate and graduate students sleep on average the same amount of time per night?\n\n. . .\n\n**Population parameter**: difference between the mean amount of time that Duke undergraduate and graduate students sleep per night $(\\mu_{diff} = \\mu_{undergrad}-\\mu_{grad})$\n\n**Sample statistic**: difference between the two sample averages $(\\bar{x}_{diff} = \\bar{x}_{undergrad} - \\bar{x}_{grad})$\n\n. . .\n\n**Confidence interval** for $\\mu_{diff}$ : $(-0.5, 1)$\n\n. . .\n\n**Hypothesis test**: Do Duke undergraduate and graduate students sleep on average the same amount of time per night?\n\n-   $H_0:\\mu_{diff}=0, H_a:\\mu_{diff}\\neq0$\n\n## Case 5 -- Linear regression {.smaller}\n\nWhat is the relation between fuel consumption in the city and on the highway?\n\n. . .\n\n**Population parameter**: the coefficient $\\beta_1$ is the equation $\\text{hwy} \\approx \\beta_0 + \\beta_1 \\text{cty}$.\n\n**Sample statistic**: the least-square estimate $\\hat{\\beta}_1$.\n\n. . .\n\n**Confidence interval** for $\\beta_1$: $(1.05, 1.2)$\n\n. . .\n\n**Hypothesis test**: are the variables $\\text{cty}$ and $\\text{hwy}$ independent?\n\n-   $H_0:\\beta_1=0, H_a:\\beta_1\\neq0$\n\n# Hypothesis tests\n\n## The null hypothesis and the alternative hypothesis\n\nA HT considers two competing hypotheses:\n\n-   the **null hypothesis** $H_0$\n    -   \"nothing is going on\": there is no effect, no difference\n-   the **alternative hypothesis** $H_a$\n    -   \"something is going on\": there is an effect, there is a difference\n    \n## Example {.smaller}\n\nConsider the 2nd case (difference in proportion of vegetarians between undergrad and grad students).\n\n-   $H_0:$ the proportion of vegetarian is the same among undergraduate and graduate students (\"nothing is going on\")\n$$\nH_0: p_{diff}=p_{undegrad}-p_{grad}=0\n$$\n$$\nH_0: p_{undegrad}=p_{grad}\n$$\n\n-   $H_a:$ the proportion of vegetarians among undergraduate and graduate students is not the same (\"something is going on\").\n$$\nH_0: p_{diff}=p_{undegrad}-p_{grad}\\neq0\n$$\n$$\nH_0: p_{undegrad}\\neq p_{grad}\n$$\n\n## More examples {.smaller}\n\n-   Are the Covid-19 vaccines equally effective?\n    -   $H_0:$ all the vaccines are equally effective; $H_a:$ the vaccines are not all equally effective\n\n-   Does caffeine consumption affect student participation in class\n    -   $H_0:$ caffeine consumption does not affect student participation; $H_a:$ caffeine consumption affects student participation\n\n-   Are men and women paid equally in the workplace?\n    -   $H_0:$ men and women are paid equally; $H_a:$ men and women are not paid equally\n\n-   Have Duke students gained weight since the start of the Covid-19 pandemic?\n    -   $H_0:$ Duke student have not gained weight; $H_a:$ Duke students have gained weight.\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Group exercise - hypotheses\n\nExercises [11.3](https://openintro-ims.netlify.app/foundations-randomization.html#chp11-exercises), [11.5](https://openintro-ims.netlify.app/foundations-randomization.html#chp11-exercises)\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_6292559d\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## Natural variability\n\nGo back to the 2nd case and suppose that $H_0$ is true.\n\n-   We'll probably still observe a small difference in the sample.\n\n. . .\n\nNow suppose that $H_a$ is true.\n\n-   We'll probably observed a larger difference in the sample,\n-   but we might also observe no difference at all,\n-   or observe a different in the wrong direction!\n\n## Natural variability and hypothesis tests\n\n::: callout-warning\n## We'll always observe a difference\n\nObserving a difference in the sample is not sufficient to reject $H_0$. When we collect a sample, there will always be some natural variability inherent to the data.\n\nDetermining whether the observed difference is due to natural variation or provides **convincing evidence** of a true difference between the two groups is at the heart of hypothesis tests.\n:::\n\n## \n\n::: {.callout-tip icon=\"false\"}\n## Group exercise - convincing evidence\n\nSuppose we have a sample with the same number of undergrad and grad students and $\\hat{p}_{diff} = \\hat{p}_{undergrad} - \\hat{p}_{grad} = 0.6 - 0.4 = 0.2$. For what sample sizes $n$ do you *intuitively feel* that the observed difference provides **convincing evidence** that the two groups are different?\n\n-   $n=10$ (5 undergrad and 5 grad students)\n-   $n=20$ (10 undergrad and 10 grad students)\n-   $n=50$ (...)\n-   $n=100$\n-   $n=250$\n-   $n=500$\n-   $n=1000$\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_62925870\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">04</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n# Confidence interval\n\n## Confidence interval\n\n**CI**: range of plausible values for the population parameter.\n\nThere always is natural variability in the data.\n\n-   If we draw a second sample from the population, the two sample statistic will probably differ.\n\n-   There is thus no reason to believe that the sample statistic in the first sample is exactly equal to the population parameter.\n\n## Examples\n\n-   What is the approval rate of the US president?\n\n-   What proportion of Duke students is vegetarian?\n\n-   How much weight have Duke students gained since the start of the Covid-19 pandemic?\n\n# Modern statistics\n\n## Classical and modern approaches\n\nWe will learn two approaches to statistical inference\n\n-   **classical** \n    -   pen and paper, pre-computer era\n    -   based on simple mathematical formula \n    -   requires the data to satisfy certain conditions \n    -   \n-   **modern** (computer-intensive)\n    -   we model the variability in the data by repeating a procedure many times (for-loop)\n    -   always applicable\n\n# A first glimpse of modern statistics for HT\n\n##\n\n::: {.callout-tip icon=\"false\"}\n## Individual exercise -- simulation\n\nSuppose you flip a coin 100 times and count the number of heads. In the first lecture, you were asked to identify what number of heads would make you doubt that the coin is fair.\n\nWe will run an experiment together to see if your gut feeling was correct.\n\nUse the following commands to simulate 100 flips of a coin and count the number of heads. Repeat the experiment 5 times, keeping track of the number of heads.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(0) # change the seed for each run\nflips <- rbernoulli(100, p = 0.5) # 100 flips - TRUE is heads and FALSE is tails\nsum(flips) # number of heads (number of TRUEs)\n```\n\n::: {.cell-output-stdout}\n```\n[1] 48\n```\n:::\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_629258b9\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## For-loop\n\nThe following for-loop does the previous experiment more efficiently!\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(0)\nresults <- tibble(n_heads = numeric()) # empty data frame to collect the results\nfor(i in 1 : 1e3){ # repeat the experiment 1,000 times\n  flips   <- rbernoulli(100, p = 0.5)\n  n_heads <- sum(flips)\n  results <- results %>% add_row(n_heads)\n}\n```\n:::\n\n##\n\nHere is the distribution of the sample statistic $\\hat{p}$ when $H_0$ is true.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(results) +\n  geom_histogram(aes(n_heads), binwidth = 1) # set the binwidth to 1 to ensure that each bin corresponds to exactly one integer.\n```\n\n::: {.cell-output-display}\n![](lec-8_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## Population and parameter\n\n::: callout-tip\n## Population and parameter first\n\nAlways start by defining the population and the parameter of interest.\n\n**Population**: flips of the coin\n\n**Parameter**: probability that a flip is head\n:::\n\n## Null and alternative hypotheses\n\n-   $H_0:p=0.5$ (the coin is fair)\n\n-   $H_0:p\\neq0.5$ (the coin is not fair)\n\n## Like jurors in the justice system {.smaller}\n\n-   $H_0:$ innocent (the coin is fair)\n\n-   $H_0:$ guilty (the coin is not fair)\n\nQuestion: do the facts (data sample) provide sufficient evidence to reject the claim that the defendant is innocent (that the coin is fair)?\n\n-   If so, we **reject** $H_0$\n\n-   Otherwise, we **fail to reject** $H_0$.\n\n::: callout-note\n## Never accept the null hypothesis\n\nWe **never** accept the null hypothesis! We only *reject* of *fail to reject* it.\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(results) + geom_histogram(aes(n_heads), binwidth = 1)\n```\n\n::: {.cell-output-display}\n![](lec-8_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## Two outcomes {.smaller}\n\nSuppose you observe the following sample: out of 100 flips, you get **55 heads**\n\n$\\Rightarrow$ the sample is plausible under $H_0$; the observed data do not provide strong evidence against the null hypothesis; we fail to reject the claim that the coin is fair\n\n-   The coin might be unfair, but the data do not provide strong evidence against fairness.\n\n. . .\n\nNow suppose that out of 100 flips, you observe **65 heads**.\n\n$\\Rightarrow$ this result is extremely unlikely under $H_0$; the observed data provide strong evidence against the null hypothesis; we reject the claim that the coin is fair.\n\n-   The coin might be fair, but a fair coin could not have plausibly given $65$ heads out of $100$ flips.\n\n# A first glimpse of modern statistics for CI\n\n## Natural variability\n\nDue to the natural variability of the data, each sample is different.\n\n. . .\n\nIn practice we only get to observe a single sample. But if we could observe other samples,\n\n-   they would all be a bit different\n-   our estimates (based on the samples) would also be different.\n\n## Sample-to-sample variability\n\nIf the samples are very different\n\n-   we say that the sample-to-sample variability is large.\n-   we would not be very confident in our estimate\n\nIf the samples are all similar\n\n-   we say that the sample-to-sample variability is small\n-   we would be confident that our estimate is close to the truth\n\n## From a single sample to bootstrap samples\n\nProblem: we only get to observe a single sample!\n\n. . .\n\nSolution: Use the sample to approximate the population and take repeated samples from the estimated population to simulate many samples.\n\n-   Equivalent to **sampling with repetition** from the sample.\n\n## \n\n![](images/lec-8/bootstrap.png)\n\n\nSource: [IMS](https://www.openintro.org/book/ims/)\n\n## From bootstrap samples to CI\n\nComputing the sample statistic of each bootstrap sample provides its **sampling distribution**.\n\nTo construct a 90% CI, we simply identify the 5th and 95th percentiles of the sampling distribution.\n\n. . .\n\n\"We are 90% confident that the interval captures the true value of the population parameter\".\n\n## Little variability $\\Rightarrow$ narrow CI\n\n**Little variability** in the data \n\n$\\Rightarrow$ little sample-to-sample variability\n\n$\\Rightarrow$ little variability between bootstrap samples\n\n$\\Rightarrow$ sampling distribution of mean/proportion is concentrated \n\n$\\Rightarrow$ **CI is narrow**.\n\n## Much variability $\\Rightarrow$ large CI\n\nMuch variability in the data \n\n$\\Rightarrow$ much sample-to-sample variability \n\n$\\Rightarrow$ much variability between bootstrap samples \n\n$\\Rightarrow$ sampling distribution of mean/proportion is diffuse \n\n$\\Rightarrow$ **CI is large**.\n\n## `sample_bootstrap`\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsample_bootstrap <- function(data){\n  n       <- nrow(data)\n  indices <- sample(1:n, size = n, replace = TRUE)\n  sample_bootstrap <- data[indices,]\n  return(sample_bootstrap)\n}\n```\n:::\n\n## Computing bootstrap CI\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"2|4|5|\"}\nd <- ggplot2::mpg\nresults <- tibble(mean = numeric(), sd = numeric())\nfor(i in 1 : 1e3){\n  d_boot <- sample_bootstrap(d)\n  results <- results %>% \n    add_row(mean = mean(d_boot$cty), sd = sd(d_boot$cty))\n}\n```\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(results) +\n  geom_histogram(aes(mean))\n```\n\n::: {.cell-output-display}\n![](lec-8_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(results) +\n  geom_histogram(aes(sd))\n```\n\n::: {.cell-output-display}\n![](lec-8_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 90% bootstrap CI for the mean cty in the population\nquantile(results$mean, c(0.05, 0.95))\n```\n\n::: {.cell-output-stdout}\n```\n      5%      95% \n16.41880 17.32051 \n```\n:::\n\n```{.r .cell-code}\n# 90% bootstrap CI for the sd of cty in the population\nquantile(results$sd  , c(0.05, 0.95))\n```\n\n::: {.cell-output-stdout}\n```\n      5%      95% \n3.839925 4.673212 \n```\n:::\n:::\n\n\n## \n::: {.callout-tip icon=\"false\"}\n## Group exercise - bootstrap CI\nExercises [12.1](https://openintro-ims.netlify.app/foundations-bootstrapping.html#chp12-exercises), [12.3](https://openintro-ims.netlify.app/foundations-bootstrapping.html#chp12-exercises), [12.7](https://openintro-ims.netlify.app/foundations-bootstrapping.html#chp12-exercises)\n:::\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_6292569d\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">06</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## \n::: {.callout-tip icon=\"false\"}\n## Group exercise - bootstrap CI\nRe-use the code from the previous slide to compute a 90% bootstrap CI of the variance of `cty` in the population. \n:::\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_6292593b\" style=\"right:0;bottom:0;\" data-warnwhen=\"0\">\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n# Recap\n\n## Recap {.smaller}\n\n::: incremental\n\n-   Statistical inference\n\n-   Five cases\n\n    -   single proportion\n\n    -   difference between two portions\n\n    -   single mean\n\n    -   difference between two means\n\n    -   regression parameters\n\n-   Hypothesis test\n\n-   Confidence interval\n\n-   A first glimpse of modern statistics\n\n    -   HT\n    \n    -   CI\n\n:::",
    "supporting": [
      "lec-8_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"..\\site_libs/countdown-0.3.5/countdown.css\" rel=\"stylesheet\" />\r\n<script src=\"..\\site_libs/countdown-0.3.5/countdown.js\"></script>\r\n"
      ],
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}