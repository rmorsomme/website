{
  "hash": "4e36430fd4b97cf1b5c165d0b82772e4",
  "result": {
    "markdown": "---\ntitle: \"HW 4 - Multiple linear regression\"\nsubtitle: \"Due Thursday, May 26, 9:00pm on Gradescope\"\n---\n\nThis assignment needs to be completed with RMarkdown and submitted as a PDF on [Gradescope](https://www.gradescope.com/courses/394638). Feel free to re-use the template provided for HW1.\n\nWhen submitting your work on Gradescope, please assign a page for each question.\n\n## Problem set and applied exercises (20 points)\n\n-   8.6 (2 points)\n-   8.10 (11 points)\n    1.  Read in the data in `R` with the following command. How many observations and variables are there?\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        d <- palmerpenguins::penguins\n        ```\n        :::\n\n    2.  Identify the type of each variable.\n\n    3.  Fit the model in `R` using the `lm` command. You should obtain the same estimates as in the book.\n\n    4.  Identify the baseline level of the categorical predictors.\n\n    5.  Do parts a-d.\n\n    6.  Compute $R^2$ by hand (do not use `glance`). Hint: compute SSR and SST.\n-   8.12 (1 points)\n-   8.14 (3 points)\n    -   Fit the candidate model in `R` and compute its adjusted-$R^2$ value. You should obtain the same value as in the book.\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        d <- palmerpenguins::penguins\n        ```\n        :::\n\n    -   Do the exercise.\n-   25.10 (3 points)\n\n## Lab exercises - **Grading the professor** (15 points)\n\nYou can find the lab [here](http://openintrostat.github.io/oilabs-tidy/09_multiple_regression/multiple_regression.html)\n\n-   Exercise 1 (2 points)\n-   Exercise 2 (2 points)\n-   Exercise 3 (1 points)\n\nSkip exercises 4, 5, 6, 7, 8\n\n-   Exercise 9 (2 points)\n-   Exercise 10 (2 points)\n\nSkip exercises 11, 12\n\n-   Exercise 13 (1 point)\n\n-   Exercise 14 (5 point)\n\n    -   Drop one variable at a time and peek at the adjusted $R^2$. Removing which variable increases adjusted $R^2$ the most?\n\n    -   skip the rest of the question.\n\nSkip the remaining exercises.\n\n## Function, for-loop and cross-validation in `R` (15 points)\n\n-   **Function** -- Write a function that compute the average $\\bar{x}$ of numerical variable from scratch (do not use the command `mean`. Your function should be called `my_mean`, take a vector of numbers as input and output its average. Show that your function works by applying in on the variable `cty` of the `ggplot2::mpg` data. You should obtain the same value of the command `mean`. (5 points)\n\n-   **For-loop** -- Write a for-loop that computes the first 20 [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number). The first few Fibonacci numbers are $0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, â€¦$. These numbers follow the following rule: each is the sum of the previous two; that is,\n\n    $$\n    x_n = x_{n-1}+x_{n-2},\n    $$\n\n    and the first two numbers are $x_1=0$ and $x_2=1$. For instance, the third number is $1 = x_3 = x_2 + x_1 = 1 + 0$ and the seventh number is $8 = x_7 = x_6 + x_5 = 5 + 3$ (5 points).\n\n-   **Cross-validation** -- Use the code from lecture to implement $5$-fold cross-validation to compare the simple regression model with `gestation_week` as the predictor and the full model with all 15 raw predictors. (5 points)",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}